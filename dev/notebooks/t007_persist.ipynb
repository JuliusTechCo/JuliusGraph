{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 7: ML Experiment Tracking and Persisting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to use this tutorial\n",
    "\n",
    "  * Select \"run all cells\" on this notebook from the Run menu in Jupyter notebook or Jupyter\n",
    "    lab. This step will produce the intermediate data output and charts. You can also run\n",
    "    individual cells by selecting that cell and pressing `Shift+Enter` key.\n",
    "  * Some cells print out a url, which you can click on and bring up an interactive web UI to\n",
    "    visualize the graph data.\n",
    "  * Time Limits: please be aware of the following time limits to conserve CPU and memory:\n",
    "    * 15 min: Some tutorials use local clusters consisting of multiple processes to mimic\n",
    "      the effects of graph distribution over a remote cluster. By default, these local clusters\n",
    "      automatically stop after idling for 15 minutes.\n",
    "      If you see an 504 gateway timeout error in the web UI, it is most likely your local cluster has stopped.\n",
    "      In that case, you will need to rerun the entire notebook by selecting \"Restart Kernel and Run All Cells\".\n",
    "    * 1 hour: notebook kernels will terminate after no user activity for 1 hour, the kernel\n",
    "      status on the right upper corner will show \"No Kernel\" afterwards. You can select\n",
    "      \"Restart Kernel and Run All Cells\" from the Kernel menu, to restart the kernel and re-run\n",
    "      the notebook.\n",
    "    * 2 hours: you will be logged out if no user activity for 2 hours. Afterwards you need\n",
    "      to login to Julius dev environment again by going to [https://juliusgraph.com](https://juliusgraph.com)\n",
    "  * Additional resources (video demos & blogs) are available at http://juliustech.co.\n",
    "  * To report bugs or request new features, please raise an issue\n",
    "    [here](https://github.com/JuliusTechCo/JuliusGraph/issues).\n",
    "    To schedule a live demo, please go to [http://juliustech.co](http://juliustech.co).\n",
    "    Please email us at info@juliustech.co for other general inquiries."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\n",
    "ML model experiment tracking is a common challenge for data scientists and engineers. We hear\n",
    "the following story too often:\n",
    "\n",
    "â€My team spent months training a massive ML model and we got excellent results at some\n",
    "point. But unfortunately we can't reproduce it any more because a number of things have\n",
    "changed, the data, the underlying python library versions and hyperparameters, etc. We are\n",
    "just not sure which combination have worked ...\".\n",
    "\n",
    "This highlights the serious issues around ML experiment tracking. In order to reproduce a\n",
    "past ML run exactly, three things have to be persisted and recovered,\n",
    "1. the runtime environment, including hardware, OS, software libraries etc\n",
    "2. the input data\n",
    "3. the entire code, parameters and configurations, to be able to re-build the entire\n",
    "   data/analytical pipeline\n",
    "\n",
    "Experiment tracking becomes much more challenging if the model runs on a distributed\n",
    "environment. To guarantee reproducibility, each ML experiment should run from a fresh\n",
    "environment, otherwise the data, setting or environment could change between runs. For\n",
    "example, some data files could be added or modified as part of the runs. However, a complete\n",
    "refresh of a complex distributed data and analytical pipeline is often out of the question,\n",
    "as it consists of many software components, parameters and configurations. This is why most\n",
    "existing experiment tracking solutions only persist the parts of the pipeline that are most\n",
    "relevant for the ML models. The downside of this approach is that the stored ML runs can\n",
    "often fail to recover the exact results.\n",
    "\n",
    "Leveraging its distributed graph computing engine, Julius offers an experiment tracking\n",
    "solution that can persist and recover an entire distributed data and analytical pipeline, as\n",
    "well as the full runtime data and environment. Julius is the only solution on the market\n",
    "with such capabilities.\n",
    "\n",
    "Julius persists the model experiment with its entire data & analytical pipeline using the\n",
    "following simple steps:\n",
    "1. spin up a fresh virtual distributed environment, which only takes a few seconds\n",
    "2. run the ML experiment and then record the entire session on the Julius server side, and\n",
    "    persist the recorded session onto long term storage. The recorded session contains the\n",
    "    step by step instructions to recreate the entire runtime environment, including the\n",
    "    entire data and distributed pipeline to recover the exact state of the experiment.\n",
    "3. the recorded ML experiment can be easily recovered by replaying it in another fresh\n",
    "    environment.\n",
    "\n",
    "In this notebook, we follow a typical workflow of a data scientist to show Julius'\n",
    "experiment tracking capabilities. We use an ML fraud detection model from a previous\n",
    "tutorial as an example. Readers are referred to the \"Distributed Machine Learning pipeline\"\n",
    "tutorial for more details on the model itself.\n",
    "\n",
    "## 1. Model Development & Experiment\n",
    "\n",
    "Data scientists usually develop ML models by running experiments interactively in a Jupyter\n",
    "notebook. This section shows the definition and pipeline of a distributed ML model."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using GraphEngine: RuleDSL, GraphVM\n",
    "using AtomExt\n",
    "using DataFrames, DataScience, StatsBase, Random\n",
    "\n",
    "newfunctions = quote\n",
    "    function downsample(ycol::Symbol, frac::Float64, df::DataFrame)\n",
    "        positive = DataFrames.filter(row -> isequal(row[ycol], true), df)\n",
    "        negative =  DataFrames.filter(row -> isequal(row[ycol], false), df)\n",
    "        dspositive = positive[sample(1:nrow(positive), round(Int, frac * nrow(positive)), replace=true), :]\n",
    "        dsnegative = negative[sample(1:nrow(negative), round(Int, frac * nrow(negative)), replace=true), :]\n",
    "        merged = vcat(dspositive, dsnegative)\n",
    "        merged[shuffle(1:nrow(merged)), :]\n",
    "    end\n",
    "\n",
    "    function valcat(xs::Vector...)\n",
    "        agg = DataFrame()\n",
    "        for (k, v) in vcat(xs...)\n",
    "            agg = vcat(agg, v)\n",
    "        end\n",
    "        agg\n",
    "    end\n",
    "\n",
    "    function dfmean(dfs::DataFrame...)\n",
    "        df = reduce(.+, dfs)\n",
    "        df ./ (length(dfs))\n",
    "    end\n",
    "end\n",
    "\n",
    "newrules = quote\n",
    "    select(ref::RuleDSL.NodeRef, cols::Any; label=\"$(isa(cols, InvertedIndex) ? \"col != $(cols.skip)\" : \"col == $(cols)\")\") =\n",
    "        DataScience.ApplyFn[x::DataFrame->DataFrames.select(x, cols; copycols=false)](ref...)\n",
    "\n",
    "    classifiertrain(model::Val{:ExtraTreesClassifier}, options::Dict, trainxs::RuleDSL.NodeRef, trainy::RuleDSL.NodeRef; label=\"$model train\")=DataScience.PyTrain[\"sklearn.ensemble.ExtraTreesClassifier\", options](trainxs..., trainy...)\n",
    "    classify(train_data::RuleDSL.NodeRef, target::Symbol, model::Val, options::Dict, testx::RuleDSL.NodeRef; label=\"$model inference\")=begin\n",
    "        train_data_X = RuleDSL.@ref ml.select(train_data, Not(target))\n",
    "        train_data_y = RuleDSL.@ref ml.select(train_data, target)\n",
    "        trained = RuleDSL.@ref ml.classifiertrain(model, options,  train_data_X, train_data_y )\n",
    "        DataScience.PyPredict(trained..., testx...)\n",
    "    end\n",
    "\n",
    "    classifyprob(train_data::RuleDSL.NodeRef, target::Symbol, model::Val, options::Dict, test_data::RuleDSL.NodeRef; label=\"prob\")=begin\n",
    "        testx = RuleDSL.@ref ml.select(test_data, Not(target))\n",
    "        DataScience.ApplyFn[x::DataFrame->DataFrames.select(x, :proba; copycols=false)](classify(train_data, target, model, options, testx))\n",
    "    end\n",
    "\n",
    "    score(realized::RuleDSL.NodeRef, probs::RuleDSL.NodeRef)=DataScience.PyScore(realized..., probs...)\n",
    "\n",
    "    downsample(raw::RuleDSL.NodeRef, ycol::Symbol, frac::Float64)=DataScience.ApplyFn[Main.downsample, ycol, frac](raw...)\n",
    "\n",
    "    bagpred(test::RuleDSL.NodeRef, model::Val, options::Dict, train_batches::Vector{RuleDSL.NodeRef}, target::Symbol) =\n",
    "        DataScience.ApplyFn[dfmean](RuleDSL.@ref((ml.classifyprob(b, target, model, options, test) for b = train_batches))...)\n",
    "\n",
    "    batchpred(test::RuleDSL.NodeRef, model::Val, options::Dict, train_batches::Vector{RuleDSL.NodeRef}, target::Symbol) =\n",
    "        DataScience.ApplyFn[(ind, prob)->[hash(test) => hcat(ind, prob)]](select(test, target), bagpred(test, model, options, train_batches, target))\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "we use existing rules in the ds namespace to read CSV files from a shared drive"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_data_file = joinpath(@__DIR__, \"../data/train_fraud.csv\")\n",
    "test_data_file = joinpath(@__DIR__, \"../data/test_fraud.csv\")\n",
    "train_data = RuleDSL.@ref ds.csvsrc(train_data_file, true; label=\"train data\")\n",
    "test_data  = RuleDSL.@ref ds.csvsrc(test_data_file, true; label=\"test data\")\n",
    "\n",
    "target = :isFraud\n",
    "model = Val(:ExtraTreesClassifier)\n",
    "options = Dict(:n_estimators => 10, :min_samples_leaf => 10)\n",
    "\n",
    "test_data_y = RuleDSL.@ref ml.select(test_data, target)\n",
    "\n",
    "sampleratio = 0.05\n",
    "train_ddf = DataScience.DDataFrame(train_data_file, blocksize=\"5 MB\")\n",
    "train_batches = train_ddf.chunks\n",
    "down_batches = RuleDSL.@ref(ml.downsample(b, target, sampleratio) for b in train_batches)\n",
    "\n",
    "test_ddf = DataScience.DDataFrame(test_data_file, blocksize=\"2.5 MB\")\n",
    "test_batches = test_ddf.chunks\n",
    "\n",
    "mapper = RuleDSL.@ref ml.batchpred(model, options, down_batches, target)\n",
    "shuffler = RuleDSL.@ref mr.shuffler(first, 4)\n",
    "reducer = RuleDSL.@ref mr.reducer(vcat)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model now runs with good results on a cluster for model development, as shown below:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using GraphEngine: RuleDSL, GraphVM\n",
    "\n",
    "config = RuleDSL.newconfig(RuleDSL.Config(), :project => \"MapReduce\")\n",
    "balancer = GraphVM.GlobalUnique()\n",
    "my_domain = GraphVM.mydomain()\n",
    "remoteport = GraphVM.drawdataport();"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "GraphVM.startlocalmasterservice(remoteport, 4)\n",
    "gs = GraphVM.RemoteGraphProxy(config, my_domain => remoteport, balancer, GraphVM.GenericData())\n",
    "GraphVM.wait4clusterinit(gs)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "GraphVM.@remote_eval gs begin\n",
    "    using GraphEngine: RuleDSL, GraphVM\n",
    "    using AtomExt, GraphIO\n",
    "    using DataFrames, DataScience, StatsBase, Random\n",
    "end\n",
    "\n",
    "GraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\n",
    "\n",
    "GraphVM.@remote_eval gs $newfunctions\n",
    "GraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\n",
    "\n",
    "GraphVM.@addrules gs ml $newrules\n",
    "\n",
    "mrpred = RuleDSL.@ref mr.mapreduce(test_batches, mapper, shuffler, reducer, Main.valcat)\n",
    "mrscore = RuleDSL.@ref ml.score(RuleDSL.@ref(ml.select(mrpred, :isFraud)), RuleDSL.@ref(ml.select(mrpred, :proba)))\n",
    "\n",
    "alljobs, ds = RuleDSL.jobdeps(config, [mrscore], Set([:classifiertrain, :splitbykey, :reducer]));\n",
    "\n",
    "GraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\n",
    "GraphVM.initgraph!(gs)\n",
    "GraphVM.dispatchjobs!(gs, alljobs; nocopy=Set([:splitbykey]));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using GraphIO\n",
    "\n",
    "GraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\n",
    "svg = GraphIO.postremotegraph(gs, remoteport);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "display(\"image/svg+xml\", svg)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Record a ML Experiment\n",
    "\n",
    "Now that the data scientists are happy with the results, they will want to persist the\n",
    "experiment so that it can be reproduced later. They have made a number of choices in this ML\n",
    "model run including data sources, configurations, choice of model, and hyper parameters\n",
    "etc. Some experiment tracking tools are based on saving notebooks, but that is not an\n",
    "adequate and reliable solution, as some data or variables were not captured by the code in\n",
    "the notebook. For example, the developer might have read data from a local file, or rely\n",
    "upon the state or data of a remote server. Under those circumstances, just saving the\n",
    "notebook is not adequate to recover the ML run.\n",
    "\n",
    "Julius takes a different approach. Instead of saving the notebook on the client side, we\n",
    "persist the entire state on the server side. This server side persisting process is easy and\n",
    "seamless. We first start a fresh virtual cluster at a new port, using the same docker image\n",
    "used by the development environment."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "remoteport2 = GraphVM.drawdataport()\n",
    "\n",
    "GraphVM.startlocalmasterservice(remoteport2, 4)\n",
    "gs2 = GraphVM.RemoteGraphProxy(config, my_domain => remoteport2, balancer, GraphVM.GenericData())\n",
    "GraphVM.wait4clusterinit(gs2)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following line enables recording on this new cluster, all the subsequent actions will\n",
    "be recorded on the server side."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "GraphVM.rpccall(gs2, :clearrecording!)\n",
    "GraphVM.rpccall(gs2, :setrecording!, true);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now re-run the same ML model on this fresh server, where the existing local variables can\n",
    "be re-used to recreate the same data/analytics pipeline on the server. Only a\n",
    "few lines of codes are needed for server side recording, as shown below:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "GraphVM.@remote_eval gs2 begin\n",
    "    using GraphEngine: RuleDSL, GraphVM\n",
    "    using AtomExt, GraphIO\n",
    "    using DataFrames, DataScience, StatsBase, Random\n",
    "end\n",
    "\n",
    "GraphVM.waitcheckstatus(gs2, RuleDSL.getconfig(config, :project));\n",
    "\n",
    "GraphVM.@remote_eval gs2 $newfunctions\n",
    "GraphVM.waitcheckstatus(gs2, RuleDSL.getconfig(config, :project));\n",
    "\n",
    "GraphVM.@addrules gs2 ml $newrules\n",
    "\n",
    "GraphVM.waitcheckstatus(gs2, RuleDSL.getconfig(config, :project));\n",
    "GraphVM.initgraph!(gs2)\n",
    "GraphVM.dispatchjobs!(gs2, alljobs; nocopy=Set([:splitbykey]));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can retrieve the recording saved on the server side for this ML run. This an\n",
    "extremely compact representation of the entire run, including all the data and analytical\n",
    "logic to recreate the distributed pipeline. This recording can be persisted on long term\n",
    "storage like AWS S3. The version of the docker container being used can also be persisted\n",
    "along with the recording. The docker container captures the exact and complete run time\n",
    "environment."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "GraphVM.waitcheckstatus(gs2, RuleDSL.getconfig(config, :project));\n",
    "records = GraphVM.rpccall(gs2, :getrecording);\n",
    "\n",
    "# terminate the recording cluster\n",
    "GraphVM.rpccall(gs2, :endcluster);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Reproduce a ML Experiment\n",
    "From the recording, the entire distributed pipeline can be easily recreated at a later time.\n",
    "To do so, we first spin up a fresh cluster using the same version of docker container, and\n",
    "then replay the recording on this new server. It only takes a single line of code to recover\n",
    "the stored pipeline:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "remoteport3 = GraphVM.drawdataport()\n",
    "GraphVM.startlocalmasterservice(remoteport3, 4)\n",
    "gs3 = GraphVM.RemoteGraphProxy(config, my_domain => remoteport3, balancer, GraphVM.GenericData())\n",
    "GraphVM.wait4clusterinit(gs3)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "GraphVM.rpccall(gs3, :replayrecording, records)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the results are ready to be inspected:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "GraphVM.waitcheckstatus(gs3, RuleDSL.getconfig(config, :project));\n",
    "svg = GraphIO.postremotegraph(gs3, remoteport3);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "display(\"image/svg+xml\", svg)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
