{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 8: Graph Creation Benchmark"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\n",
    "In enterprise systems, the entire analytical logic and data flow can be so complex that\n",
    "the resulting computational DAG (directed acyclic graph) is extremely large, for example,\n",
    "with hundreds of millions of nodes. It is extremely time-consuming to create such large\n",
    "computational DAGs. Often the time it takes to create these large DAGs is much longer than\n",
    "the time to execute them. Therefore, it is crucial for a graph computing solution to be\n",
    "able to create large DAGs quickly, otherwise it won't be a viable solution for\n",
    "complex enterprise use cases.\n",
    "\n",
    "Julius Graph Engine features a low-code domain specific language, RuleDSL, which is\n",
    "designed specifically for creating DAGs. RuleDSL not only makes it easy for developers to\n",
    "write complex business logic, but also enables fast and efficient creations of large\n",
    "computational DAGs.\n",
    "\n",
    "In this study, we compare the performance of DAG creation between\n",
    "[Julius](http://juliustech.co) and a few other well-known graph computing packages,\n",
    "such as [Dask](http://dask.org), [Dagger.jl](https://github.com/JuliaParallel/Dagger.jl) and\n",
    "[Tensorflow](http://tensorflow.org). The comparison is performed on a single computer without\n",
    "distribution, because even though all solutions supports parallel execution of computational\n",
    "DAGs, only Julius supports parallelism for DAG creation.\n",
    "\n",
    "## Benchmark Setup\n",
    "\n",
    "The problem we used for benchmarking is to compute the value of a simple Fibonancci like\n",
    "sequence of:\n",
    "\n",
    "$y_n = .7  y_{n-1} + .3 y_{n-2}$\n",
    "\n",
    "where any $y_i$ is a vector of length 10. The initial terms $y_0$ and $y_1$ are\n",
    "random vectors of length 10.\n",
    "\n",
    "The methodology of the benchmarking is straightforward: we simply create and run the\n",
    "computational DAGs using different graph computing solutions, then record their wall clock\n",
    "time. Python time is measured by `%time`, and Julia time is measured by `@time`. Since the\n",
    "numerical computation of the sequence is trivial, the time recorded is almost 100%\n",
    "on the creation of computational DAG.\n",
    "\n",
    "We want to emphasize that this benchmarking exercise is only for the speed of\n",
    "DAG creation. We are not testing any other features in these software packages. However,\n",
    "given the graph creation is often the most time-consuming step for running large systems\n",
    "as DAGs, it is of great practical interests to understand its performance characteristics.\n",
    "\n",
    "The source code for the benchmarking is listed in the appendix.\n",
    "\n",
    "## Results\n",
    "\n",
    "The hardware for running the benchmark is a single laptop with a 6-core intel i-7 CPU and\n",
    "64 GB of memory. The term $n$ is chosen to be 20, 1,000, 10,000, 100,000, 500,000. The\n",
    "following is the results of the benchmark, all timing numbers are reported in seconds.\n",
    "Fail indicates that the run does not complete within 12 hours, which is too long for any\n",
    "practical usage.\n",
    "\n",
    "| n | Dask | Dagger.jl | Tensorflow | Julius |\n",
    "| :---: | :---: | :---: | :---: | :---: |\n",
    "| 20 | 0.004 | 0.08 | 0.001 | 0.0007 |\n",
    "| 1,000 | 1.35 | fail | 2.19 | 0.026 |\n",
    "| 10,000 | 17 | fail | 23 | 0.3 |\n",
    "| 100,000 | 3029 | fail | 317 | 5 |\n",
    "| 500,000 | fail | fail | 1554 | 64 |\n",
    "\n",
    "It seems the current version of Dagger.jl (v0.14.3) has a bug that prevents the benchmark\n",
    "from completing for even small n, the issue has been reported to Dagger.jl developers.\n",
    "Another way to look at the results is to estimate the maximum size of a DAG that can be\n",
    "supported on a single computer, assuming 6 hours is the practical upper limit for DAG\n",
    "creation:\n",
    "\n",
    "| Solutions | Dask | Dagger.jl | Tensorflow | Julius |\n",
    "| :---: | :---: | :---: | :---:| :---: |\n",
    "|Max Graph Size | < 500K | < 1K | 10 MM | 300 MM |\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The graph creation benchmark clearly showed that Julius has a huge speed advantage for\n",
    "creating large graphs, thanks to its RuleDSL.\n",
    "\n",
    "Julius can create DAGs with hundreds of millions of nodes using a single computer, which\n",
    "is sufficient to cover even the most complex enterprise use cases. In addition, Julius'\n",
    "graph construction can be easily parallelized thanks to the simple syntax of RuleDSL,\n",
    "thus extending Julius' upper limit to billions of nodes, if such needs ever arise in\n",
    "practice.\n",
    "\n",
    "In comparison, Dask, Dagger.jl and Tensorflow do not support parallelism for DAG creation.\n",
    "Therefore, the DAG creation is much more likely to become a bottleneck for enterprise\n",
    "problems using these solutions.\n",
    "\n",
    "\n",
    "## Appendix: Source Code\n",
    "\n",
    "All the code below are directly runnable once the dependent packages are installed.\n",
    "\n",
    "The cleanest way to implement this sequence is via recursion. However, Dask,\n",
    "Dagger.jl and Tensorflow does not yet support recursive functions, therefore we have\n",
    "to write an explicit loop in their implementation. Julius' RuleDSL does support recursive\n",
    "definitions, which is used below for defining the sequence in Julius implementation.\n",
    "\n",
    "#### **Dask implementation**\n",
    "\n",
    "```python\n",
    "import dask\n",
    "import numpy as np\n",
    "\n",
    "@dask.delayed\n",
    "def fib0(n) :\n",
    "        return np.random.rand(10)\n",
    "\n",
    "@dask.delayed\n",
    "def wsum(a, b) :\n",
    "    return  (.3*a + .7*b)\n",
    "\n",
    "%%time\n",
    "# %%time is a magic command, only works in Jupyter notebook\n",
    "\n",
    "f0 = fib0(0)\n",
    "f1 = fib0(1)\n",
    "\n",
    "for i in range(0, 10000) :\n",
    "    f2 = wsum(f0, f1)\n",
    "    f0, f1 = f1, f2\n",
    "```\n",
    "\n",
    "#### **Dagger.jl implementation**\n",
    "\n",
    "```julia\n",
    "\n",
    "using Dagger\n",
    "fibsum(a, b)=.3 .* a .+ .7 .* b\n",
    "\n",
    "f0 = Dagger.@spawn rand(10)\n",
    "f1 = Dagger.@spawn rand(10)\n",
    "f2 = 0 # final result will be held here\n",
    "\n",
    "@time for i in 1:20\n",
    "    f2 = Dagger.@spawn fibsum(f0, f1)\n",
    "    f0, f1 = f1, f2\n",
    "end\n",
    "\n",
    "```\n",
    "\n",
    "#### **Tensorflow implementation**\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "a = tf.Variable(np.random.rand(10))\n",
    "b = tf.Variable(np.random.rand(10))\n",
    "\n",
    "@tf.function\n",
    "def wsum(a, b) :\n",
    "    return a*.3 + b*.7\n",
    "\n",
    "# have to wrap the top level call by @tf.function, otherwise\n",
    "# TF2 does not create the computational graph\n",
    "@tf.function\n",
    "def fib(n, f0, f1) :\n",
    "    # not using tf.range() because Tensorflow automatically\n",
    "    # optimizes tf.range() into a single loop node instead of\n",
    "    # creating n number of nodes in the graph\n",
    "    for i in range(0, n) :\n",
    "        f2 = wsum(f0, f1)\n",
    "        f0, f1 = f1, f2\n",
    "    return f2\n",
    "\n",
    "%%time\n",
    "# %%time is magic command, only works in Jupyter notebook\n",
    "\n",
    "fib(1000, a, b)\n",
    "```\n",
    "\n",
    "#### **Julius implementation**\n",
    "\n",
    "To learn more about JuliusDSL and its implementation, please refer to the quickstart\n",
    "tutorial. The `ApplyFn` is a convenient Atom that allows arbitrary Julia function to\n",
    "be used in `RuleDSL`, please refer to the mapreduce tutorial for the details on `ApplyFn`.\n",
    "\n",
    "```julia\n",
    "using GraphEngine: RuleDSL, GraphVM\n",
    "using DataScience: ApplyFn\n",
    "\n",
    "# ApplyFn is a generic Atom allows arbitrary julia function to be called\n",
    "RuleDSL.@addrules seq begin\n",
    "    fib(n::Int) = RuleDSL.Alias(fib(n, Val(n <= 1)))\n",
    "    fib(n::Int, isend::Val{false}) =\n",
    "        ApplyFn[(a, b)-> (.7 .* a .+ .3 .* b)](\n",
    "            fib(n - 1, Val(n <= 2)), fib(n - 2, Val(n <= 3))\n",
    "        )\n",
    "    fib(n::Int, isend::Val{true}) = ApplyFn[()->rand(10)]()\n",
    "end\n",
    "\n",
    "ref = RuleDSL.@ref seq.fib(10000)\n",
    "gs = GraphVM.createlocalgraph(RuleDSL.Config(), RuleDSL.GenericData());\n",
    "@time GraphVM.calcfwd!(gs, Set([ref]));\n",
    "\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
