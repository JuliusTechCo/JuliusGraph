<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>7 Graph Computing Benchmark · Julius GraphEngine Tutorials</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/theme.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Julius GraphEngine Tutorials</span></div><form class="docs-search" action="../search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Introduction</a></li><li><a class="tocitem" href="t001_quickstart.html">1 Quick Start</a></li><li><a class="tocitem" href="t002_machinelearning.html">2 Machine Learning</a></li><li><a class="tocitem" href="t003_mapreduce.html">3 MapReduce</a></li><li><a class="tocitem" href="t004_distributedml.html">4 Distributed Machine Learning</a></li><li><a class="tocitem" href="t005_aad.html">5 Adjoint Algorithmic Differentiation (AAD)</a></li><li><a class="tocitem" href="t006_persist.html">6 ML Experiment Tracking and Persisting</a></li><li class="is-active"><a class="tocitem" href="t007_benchmark.html">7 Graph Computing Benchmark</a><ul class="internal"><li><a class="tocitem" href="#How-to-use-this-tutorial-1"><span>How to use this tutorial</span></a></li><li><a class="tocitem" href="#Introduction-1"><span>Introduction</span></a></li><li><a class="tocitem" href="#Benchmark-Setup-1"><span>Benchmark Setup</span></a></li><li><a class="tocitem" href="#Results-1"><span>Results</span></a></li><li><a class="tocitem" href="#Conclusion-1"><span>Conclusion</span></a></li><li><a class="tocitem" href="#Appendix:-Source-Code-1"><span>Appendix: Source Code</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="t007_benchmark.html">7 Graph Computing Benchmark</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="t007_benchmark.html">7 Graph Computing Benchmark</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliusTechCo/Tutorials/blob/main/src/benchmark.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Tutorial-7:-Graph-Computing-Benchmark-1"><a class="docs-heading-anchor" href="#Tutorial-7:-Graph-Computing-Benchmark-1">Tutorial 7: Graph Computing Benchmark</a><a class="docs-heading-anchor-permalink" href="#Tutorial-7:-Graph-Computing-Benchmark-1" title="Permalink"></a></h1><h2 id="How-to-use-this-tutorial-1"><a class="docs-heading-anchor" href="#How-to-use-this-tutorial-1">How to use this tutorial</a><a class="docs-heading-anchor-permalink" href="#How-to-use-this-tutorial-1" title="Permalink"></a></h2><ul><li>This tutorial is also available in Jupyter notebook format. To access and run the Jupyter notebook version of the tutorial, please sign up for free developer access by following instructions at <a href="https://github.com/juliustechco/juliusgraph">https://github.com/juliustechco/juliusgraph</a>.</li><li>Additional resources (video demos &amp; blogs) are available at <a href="http://juliustech.co">http://juliustech.co</a>.</li><li>To report bugs or request new features, please raise an issue <a href="https://github.com/JuliusTechCo/JuliusGraph/issues">here</a>. To schedule a live demo, please go to <a href="http://juliustech.co">http://juliustech.co</a>. Please check out this <a href="https://github.com/JuliusTechCo/JuliusGraph/blob/main/FAQ.md">FAQ</a> page or email us at info@juliustech.co for other general inquiries.</li></ul><h2 id="Introduction-1"><a class="docs-heading-anchor" href="#Introduction-1">Introduction</a><a class="docs-heading-anchor-permalink" href="#Introduction-1" title="Permalink"></a></h2><p>Julius Graph Engine features a low-code domain specific language, RuleDSL, which not only makes it easy for developers to write complex business logic, but also enables efficient creation and orchestration of a computational DAG. By orchestration, we mean all the runtime organization and house-keeping so that the nodes in the DAG are executed in the right order with correct data feeds among them.</p><p>In enterprise systems, the entire analytical logic and data flow can be so complex that the resulting computational DAG (directed acyclic graph) is extremely large. Running pricing and risk for a bank&#39;s trading portfolio is one situation where the resulting graph can grow to tens of millions of nodes. It is very challenging to create and orchestrate the execution of such large DAGs in practice, which is often the main performance and scalability bottleneck of a graph computing solution.</p><p>In this study, we compare the performance of DAG creation and orchestration between <a href="http://juliustech.co">Julius</a> and a few other well-known graph computing packages such as <a href="http://dask.org">Dask</a>, <a href="https://github.com/JuliaParallel/Dagger.jl">Dagger.jl</a> and <a href="http://tensorflow.org">Tensorflow</a>. Even though all the solutions support parallel execution of computational DAGs, only Julius supports parallel DAG creation. So to be fair, this comparison is only performed on a single computer without distribution.</p><h2 id="Benchmark-Setup-1"><a class="docs-heading-anchor" href="#Benchmark-Setup-1">Benchmark Setup</a><a class="docs-heading-anchor-permalink" href="#Benchmark-Setup-1" title="Permalink"></a></h2><p>The problem we used for benchmarking is to compute the sum of all the even terms of a Fibonacci-like sequence:</p><div>\[y_n = .7  y_{n-1} + .3 y_{n-2}\]</div><div>\[s_n = \sum_{k=0}^{n/2} y_{2k}\]</div><p>All <span>$y_i$</span> and <span>$s_k$</span> here are vector of length 10, with the initial terms <span>$y_0$</span> and <span>$y_1$</span> being random vectors of length 10. The benchmark problem is so designed that the resulting computational DAG is both deep (<span>$y_n$</span> has very long chain of dependencies) and wide (the <span>$s_n$</span> has many dependencies), in order to be representative of the wide variety of computational DAGs in the real world. The following images shows the computational DAGs for both <span>$y_{10}$</span> and <span>$s_{10}$</span>.</p><table><tr><th style="text-align: center">Deep DAG (<span>$y_n$</span>)</th><th style="text-align: center">Deep &amp; Wide DAG (<span>$s_n$</span>)</th></tr><tr><td style="text-align: center"><img src="../assets/deepgraph.png" alt/></td><td style="text-align: center"><img src="../assets/widegraph.png" alt/></td></tr></table><p>The methodology of the benchmarking is straightforward: we simply create and run the computational DAGs using different graph solutions, then record their wall clock time. Python time is measured by <code>%time</code>, and Julia time is measured by <code>@time</code>. Since the numerical computation of the sequence is trivial, the time recorded is almost 100% spent on the creation of the computational DAGs, and the orchestration of its execution.</p><p>We want to emphasize that this benchmarking study is only focused on the speed of DAG creation and orchestration. We are not testing any other features of the respective software packages. However, given that graph creation and orchestration is often the most time-consuming part of running large computational DAGs, it is of great practical interest to understand its performance characteristics.</p><p>The source code for the benchmarking is listed in the appendix.</p><h2 id="Results-1"><a class="docs-heading-anchor" href="#Results-1">Results</a><a class="docs-heading-anchor-permalink" href="#Results-1" title="Permalink"></a></h2><p>The hardware for running the benchmark is a single laptop with a 6-core intel i-7 CPU and 64 GB of memory. The following table shows the results of the benchmark for <span>$s_n$</span> of different <span>$n$</span>, where all timing numbers are reported in seconds. The benchmark run is stopped if it did not finish under 6 hours, which is too long for practical use. Dask runs for large <span>$n$</span> end up in an exception of running out of memory before the 6 hours time limit.</p><table><tr><th style="text-align: center"><span>$s_n$</span></th><th style="text-align: center">Dask</th><th style="text-align: center">Dagger.jl</th><th style="text-align: center">Tensorflow</th><th style="text-align: center">Julius</th></tr><tr><td style="text-align: center">1,000</td><td style="text-align: center">.03</td><td style="text-align: center">5</td><td style="text-align: center">2.28</td><td style="text-align: center">0.02</td></tr><tr><td style="text-align: center">5,000</td><td style="text-align: center">4</td><td style="text-align: center">158</td><td style="text-align: center">15.2</td><td style="text-align: center">0.15</td></tr><tr><td style="text-align: center">10,000</td><td style="text-align: center">20</td><td style="text-align: center">762</td><td style="text-align: center">33.8</td><td style="text-align: center">0.22</td></tr><tr><td style="text-align: center">100,000</td><td style="text-align: center">error</td><td style="text-align: center">&gt; 6hr</td><td style="text-align: center">2093</td><td style="text-align: center">2.6</td></tr><tr><td style="text-align: center">200,000</td><td style="text-align: center">error</td><td style="text-align: center">&gt; 6hr</td><td style="text-align: center">10023</td><td style="text-align: center">4.3</td></tr><tr><td style="text-align: center">500,000</td><td style="text-align: center">error</td><td style="text-align: center">&gt; 6hr</td><td style="text-align: center">&gt; 6hr</td><td style="text-align: center">15</td></tr></table><p>Only Julius is able to complete the <span>$s_n$</span> benchmark run for <span>$n$</span> = 500,000 within the 6 hour limit (it only took Julius 15 seconds). In order to understand how Dask, Dagger.jl and Tensorflow failed, we also benchmarked an easier problem of computing the <span>$y_n$</span>, whose computational graph is deep but not wide, the results are:</p><table><tr><th style="text-align: center"><span>$y_n$</span></th><th style="text-align: center">Dask</th><th style="text-align: center">Dagger.jl</th><th style="text-align: center">Tensorflow</th><th style="text-align: center">Julius</th></tr><tr><td style="text-align: center">1,000</td><td style="text-align: center">.03</td><td style="text-align: center">5</td><td style="text-align: center">2.19</td><td style="text-align: center">0.02</td></tr><tr><td style="text-align: center">5,000</td><td style="text-align: center">4</td><td style="text-align: center">123</td><td style="text-align: center">11</td><td style="text-align: center">0.11</td></tr><tr><td style="text-align: center">10,000</td><td style="text-align: center">17</td><td style="text-align: center">462</td><td style="text-align: center">23</td><td style="text-align: center">0.2</td></tr><tr><td style="text-align: center">100,000</td><td style="text-align: center">3029</td><td style="text-align: center">&gt;6hr</td><td style="text-align: center">280</td><td style="text-align: center">2.5</td></tr><tr><td style="text-align: center">200,000</td><td style="text-align: center">11736</td><td style="text-align: center">&gt;6hr</td><td style="text-align: center">570</td><td style="text-align: center">3.6</td></tr><tr><td style="text-align: center">500,000</td><td style="text-align: center">&gt;6hr</td><td style="text-align: center">&gt;6hr</td><td style="text-align: center">1491</td><td style="text-align: center">13</td></tr></table><p>For <span>$y_n$</span>, Dask, Dagger.jl and Tensorflow all performed considerably better than the case of <span>$s_n$</span>. It suggests that a wide computational DAG poses difficulties to these solutions, causing big performance degradation, often more than 10 times. In contrast, Julius performed extremely well in both cases, with little difference in its overall timing.</p><p>It is revealing to show the maximum computational DAG size that can be created and orchestrated from a single computer, assuming 6 hours is a practical time limit. The Julius results below is based on an actual run of <span>$s_n$</span> for <span>$n$</span> = 50MM, which took less than 5 hours. The Julius performance for <span>$n$</span> = 50MM is bounded by the 64GB RAM on the laptop as heavy disk swaps ocurred during the run. Julius could handle even bigger DAGs with more RAM.</p><table><tr><th style="text-align: center">Solutions</th><th style="text-align: center">Dask</th><th style="text-align: center">Dagger.jl</th><th style="text-align: center">Tensorflow</th><th style="text-align: center">Julius</th></tr><tr><td style="text-align: center">Max DAG Size</td><td style="text-align: center">&lt; 100K</td><td style="text-align: center">&lt; 100K</td><td style="text-align: center">&lt; 500K</td><td style="text-align: center">&gt; 50MM</td></tr></table><p>In practice, a wide computational DAG with 500K nodes is not uncommon in practice, the above result suggests that Dask, Dagger.jl and Tensorflow could run into difficulties for such problems. In comparison, Julius can comfortably create and execute computational DAGs of at least 50MM nodes from a single computer, regardless of its shape, making it a suitable solution for large enterprise problems.</p><h2 id="Conclusion-1"><a class="docs-heading-anchor" href="#Conclusion-1">Conclusion</a><a class="docs-heading-anchor-permalink" href="#Conclusion-1" title="Permalink"></a></h2><p>This benchmark clearly demonstrates Julius&#39; huge advantage in speed and scalability. Julius can create and orchestrate DAGs with tens of millions of nodes from a single computer. Moreover, Julius&#39; graph construction can be easily parallelized thanks to the simple syntax of RuleDSL, extending Julius&#39; upper limit to billions of nodes if necessary.</p><p>In comparison, Dask, Dagger.jl and Tensorflow are much slower in graph creation and orchestration; neither do they support parallel DAG creation. It is therefore important for developers to consider the scalability implications of different solutions for real world problems.</p><h2 id="Appendix:-Source-Code-1"><a class="docs-heading-anchor" href="#Appendix:-Source-Code-1">Appendix: Source Code</a><a class="docs-heading-anchor-permalink" href="#Appendix:-Source-Code-1" title="Permalink"></a></h2><p>All of the code below is directly runnable once the dependent packages are installed.</p><p>The cleanest way to implement the <span>$y_n$</span> sequence is via recursion. However, Dask, Dagger.jl and Tensorflow do not yet support recursive functions, so we have to write an explicit loop in their implementations. Julius&#39; RuleDSL does support recursive definitions, which is used in the Julius implementation.</p><h4 id="**Dask-implementation**-1"><a class="docs-heading-anchor" href="#**Dask-implementation**-1"><strong>Dask implementation</strong></a><a class="docs-heading-anchor-permalink" href="#**Dask-implementation**-1" title="Permalink"></a></h4><pre><code class="language-python">import dask
import numpy as np

@dask.delayed
def fib0(n) :
        return np.random.rand(10)

@dask.delayed
def wsum(a, b) :
    return  (.3*a + .7*b)

%%time
# %%time is a magic command, only works in Jupyter notebook
# compute s_n

f0 = fib0(1)
f1 = fib0(2)
even = [f0]

for i in range(0, 10000) :
    f2 = wsum(f0, f1)
    f0, f1 = f1, f2

    if (i%2 == 1) :
        even.append(f2)

v = dask.delayed(sum)(even)

%%time
# compute y_n only

f0 = fib0(1)
f1 = fib0(2)

for i in range(0, 10000) :
    f2 = wsum(f0, f1)
    f0, f1 = f1, f2</code></pre><h4 id="**Dagger.jl-implementation**-1"><a class="docs-heading-anchor" href="#**Dagger.jl-implementation**-1"><strong>Dagger.jl implementation</strong></a><a class="docs-heading-anchor-permalink" href="#**Dagger.jl-implementation**-1" title="Permalink"></a></h4><pre><code class="language-julia">
using Dagger
fibsum(a, b)=.3 .* a .+ .7 .* b
combine(a...) = sum(a)

# compute s_n
f0 = Dagger.@spawn rand(10)
f1 = Dagger.@spawn rand(10)
s = 0. # result held here

@time begin
    even = [f0]
    for i in 1:1000
        f2 = Dagger.@spawn fibsum(f0, f1)
        f0, f1 = f1, f2

        if i%2 == 0
            push!(even, f2)
        end
    end

    s = Dagger.@spawn combine(even...)
end

# compute y_n
f0 = Dagger.@spawn rand(10)
f1 = Dagger.@spawn rand(10)
f2 = 0. # results here

@time begin
    for i in 1:1000
        f2 = Dagger.@spawn fibsum(f0, f1)
        f0, f1 = f1, f2
    end
end

</code></pre><h4 id="**Tensorflow-implementation**-1"><a class="docs-heading-anchor" href="#**Tensorflow-implementation**-1"><strong>Tensorflow implementation</strong></a><a class="docs-heading-anchor-permalink" href="#**Tensorflow-implementation**-1" title="Permalink"></a></h4><pre><code class="language-python">@tf.function
def wsum(a, b) :
    return a*.3 + b*.7

# have to wrap the top level call by @tf.function, otherwise
# Tensorflow does not create the computational graph
@tf.function
def sumeven(n, f0, f1) :
    even = [f0]
    # not using tf.range() because Tensorflow automatically
    # optimizes tf.range() into a single loop node instead of
    # creating n number of nodes in the graph, the latter is
    # the case we want to benchmark
    for i in range(0, n) :
        f2 = wsum(f0, f1)
        f0, f1 = f1, f2

        if i % 2 == 1 :
            even.append(f2)

    return tf.add_n(even)

@tf.function
def fib(n, f0, f1) :
    for i in range(0, n) :
        f2 = wsum(f0, f1)
        f0, f1 = f1, f2

    return f2

%%time
# %%time is magic command, only works in Jupyter notebook
# compute s_n

n = 1000
sn = sumeven(n, np.random.rand(10), np.random.rand(10))

%%time
# %%time is magic command, only works in Jupyter notebook
# compute y_n
yn = fib(n, np.random.rand(10), np.random.rand(10))</code></pre><h4 id="**Julius-implementation**-1"><a class="docs-heading-anchor" href="#**Julius-implementation**-1"><strong>Julius implementation</strong></a><a class="docs-heading-anchor-permalink" href="#**Julius-implementation**-1" title="Permalink"></a></h4><p>To learn more about <code>RuleDSL</code> syntax and the concept of Atoms, please refer to the quickstart tutorial. The <code>ApplyFn</code> is a convenient Atom that allows arbitrary Julia functions to be used in <code>RuleDSL</code>, please refer to the mapreduce tutorial for more information on <code>ApplyFn</code>.</p><pre><code class="language-julia">using GraphEngine: RuleDSL, GraphVM
using DataScience: ApplyFn

RuleDSL.@addrules seq begin
    # Val(n&lt;=1) takes value of either Val(true) or Val(false), indicating
    # whether the term n is the initial two terms (n=0, n=1) of the sequence.
    # Base on this, its dependency fib(n, Val(n &lt;= 1)) is pattern
    # matched to the correct rule below.
    # Alias is a special Atom that simply invokes another rule.
    fib(n::Int) = RuleDSL.Alias(fib(n, Val(n &lt;= 1)))

    # the -&gt; is a lambda syntax in julia to declare anonymous functions
    # this rule defines the recursion of the sequence for non-initial terms.
    # ApplyFn is a generic Atom allows arbitrary julia function to be used
    fib(n::Int, isinitialterm::Val{false}) =
        ApplyFn[(a, b)-&gt; (.7 .* a .+ .3 .* b)](
            fib(n - 1, Val(n &lt;= 2)), fib(n - 2, Val(n &lt;= 3))
        )

    # for initial terms, simply return a random vector
    # () means the anonymous function does not have any arguments
    fib(n::Int, isinitialterm::Val{true}) = ApplyFn[()-&gt;rand(10)]()

    # (x...) catches all input vectors
    sumeven(n::Int) =
        ApplyFn[(x...)-&gt;reduce(.+, x)](RuleDSL.@ref(fib(i, Val(i &lt;= 1)) for i in 0:2:n)...)
end

n = 100000
yn = RuleDSL.@ref seq.fib(n)
sn = RuleDSL.@ref seq.sumeven(n)
config = RuleDSL.Config();

# to compute s_n
gs = GraphVM.createlocalgraph(RuleDSL.Config(), RuleDSL.GenericData());
@time GraphVM.calcfwd!(gs, Set([sn]));

# to compute y_n
gs = GraphVM.createlocalgraph(RuleDSL.Config(), RuleDSL.GenericData());
@time GraphVM.calcfwd!(gs, Set([yn]));

</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="t006_persist.html">« 6 ML Experiment Tracking and Persisting</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 20 April 2022 20:05">Wednesday 20 April 2022</span>. Using Julia version 1.6.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
