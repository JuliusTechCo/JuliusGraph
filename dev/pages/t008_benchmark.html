<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>8 Graph Creation Benchmark · Julius GraphEngine Tutorials</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/theme.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Julius GraphEngine Tutorials</span></div><form class="docs-search" action="../search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Introduction</a></li><li><a class="tocitem" href="t001_quickstart.html">1 Quick Start</a></li><li><a class="tocitem" href="t002_machinelearning.html">2 Machine Learning</a></li><li><a class="tocitem" href="t003_mapreduce.html">3 MapReduce</a></li><li><a class="tocitem" href="t004_distributedml.html">4 Distributed Machine Learning</a></li><li><a class="tocitem" href="t005_aad.html">5 Adjoint Algorithmic Differentiation (AAD)</a></li><li><a class="tocitem" href="t006_advanced.html">6 Advanced Features</a></li><li><a class="tocitem" href="t007_persist.html">7 ML Experiment Tracking and Persisting</a></li><li class="is-active"><a class="tocitem" href="t008_benchmark.html">8 Graph Creation Benchmark</a><ul class="internal"><li><a class="tocitem" href="#How-to-use-this-tutorial-1"><span>How to use this tutorial</span></a></li><li><a class="tocitem" href="#Introduction-1"><span>Introduction</span></a></li><li><a class="tocitem" href="#Benchmark-Setup-1"><span>Benchmark Setup</span></a></li><li><a class="tocitem" href="#Results-1"><span>Results</span></a></li><li><a class="tocitem" href="#Conclusion-1"><span>Conclusion</span></a></li><li><a class="tocitem" href="#Appendix:-Source-Code-1"><span>Appendix: Source Code</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="t008_benchmark.html">8 Graph Creation Benchmark</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="t008_benchmark.html">8 Graph Creation Benchmark</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliusTechCo/Tutorials/blob/main/src/benchmark.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Tutorial-8:-Graph-Creation-Benchmark-1"><a class="docs-heading-anchor" href="#Tutorial-8:-Graph-Creation-Benchmark-1">Tutorial 8: Graph Creation Benchmark</a><a class="docs-heading-anchor-permalink" href="#Tutorial-8:-Graph-Creation-Benchmark-1" title="Permalink"></a></h1><h2 id="How-to-use-this-tutorial-1"><a class="docs-heading-anchor" href="#How-to-use-this-tutorial-1">How to use this tutorial</a><a class="docs-heading-anchor-permalink" href="#How-to-use-this-tutorial-1" title="Permalink"></a></h2><ul><li>This tutorial is also available in Jupyter notebook format. To access and run the Jupyter notebook version of the tutorial, please sign up for free developer access at <a href="https://juliusgraph.com/user/signup">https://juliusgraph.com/user/signup</a>, then go to Julius&#39; developer environment at <a href="https://juliusgraph.com">https://juliusgraph.com</a>.</li><li>Additional resources (video demos &amp; blogs) are available at <a href="http://juliustech.co">http://juliustech.co</a>.</li><li>To report bugs or request new features, please raise an issue <a href="https://github.com/JuliusTechCo/JuliusGraph/issues">here</a>. To schedule a live demo, please go to <a href="http://juliustech.co">http://juliustech.co</a>. Please email us at info@juliustech.co for other general inquiries.</li></ul><h2 id="Introduction-1"><a class="docs-heading-anchor" href="#Introduction-1">Introduction</a><a class="docs-heading-anchor-permalink" href="#Introduction-1" title="Permalink"></a></h2><p>In enterprise systems, the entire analytical logic and data flow can be so complex that the resulting computational DAG (directed acyclic graph) is extremely large. Pricing and hedging a large derivative portfolio for a bank&#39;s trading desk is one of such examples that the resulting computational graph can be as large as tens of millions of nodes. It is time-consuming to create such large computational DAGs. Often the time it takes to create these large DAGs is much longer than the time to execute them. Therefore, it is crucial for a graph computing solution to be able to create large DAGs quickly, otherwise it won&#39;t be viable for large and complex enterprise use cases.</p><p>Julius Graph Engine features a low-code domain specific language, RuleDSL, which is designed specifically for creating DAGs. RuleDSL not only makes it easy for developers to write complex business logic, but also enables fast and efficient creations of large computational DAGs.</p><p>In this study, we compare the performance of DAG creation between <a href="http://juliustech.co">Julius</a> and a few other well-known graph computing packages, such as <a href="http://dask.org">Dask</a>, <a href="https://github.com/JuliaParallel/Dagger.jl">Dagger.jl</a> and <a href="http://tensorflow.org">Tensorflow</a>. The comparison is performed on a single computer without distribution, because even though all solutions supports parallel execution of computational DAGs, only Julius supports parallelism for DAG creation.</p><h2 id="Benchmark-Setup-1"><a class="docs-heading-anchor" href="#Benchmark-Setup-1">Benchmark Setup</a><a class="docs-heading-anchor-permalink" href="#Benchmark-Setup-1" title="Permalink"></a></h2><p>The problem we used for benchmarking is to compute the value of a simple Fibonancci like sequence of:</p><div>\[y_n = .7  y_{n-1} + .3 y_{n-2}\]</div><p>where any <span>$y_i$</span> is a vector of length 10. The initial terms <span>$y_0$</span> and <span>$y_1$</span> are random vectors of length 10.</p><p>The methodology of the benchmarking is straightforward: we simply create and run the computational DAGs using different graph computing solutions, then record their wall clock time. Python time is measured by <code>%time</code>, and Julia time is measured by <code>@time</code>. Since the numerical computation of the sequence is trivial, the time recorded is almost 100% on the creation of computational DAG.</p><p>We want to emphasize that this benchmarking exercise is only for the speed of DAG creation. We are not testing any other features in these software packages. However, given the graph creation is often the most time-consuming step for running large systems as DAGs, it is of great practical interests to understand its performance characteristics.</p><p>The source code for the benchmarking is listed in the appendix.</p><h2 id="Results-1"><a class="docs-heading-anchor" href="#Results-1">Results</a><a class="docs-heading-anchor-permalink" href="#Results-1" title="Permalink"></a></h2><p>The hardware for running the benchmark is a single laptop with a 6-core intel i-7 CPU and 64 GB of memory. The term <span>$n$</span> is chosen to be 20, 1,000, 10,000, 100,000, 500,000. The following is the results of the benchmark, all timing numbers are reported in seconds. Fail indicates that the run does not complete within 12 hours, which is too long for any practical usage.</p><table><tr><th style="text-align: center">n</th><th style="text-align: center">Dask</th><th style="text-align: center">Dagger.jl</th><th style="text-align: center">Tensorflow</th><th style="text-align: center">Julius</th></tr><tr><td style="text-align: center">20</td><td style="text-align: center">0.004</td><td style="text-align: center">0.08</td><td style="text-align: center">0.001</td><td style="text-align: center">0.0007</td></tr><tr><td style="text-align: center">1,000</td><td style="text-align: center">1.35</td><td style="text-align: center">fail</td><td style="text-align: center">2.19</td><td style="text-align: center">0.026</td></tr><tr><td style="text-align: center">10,000</td><td style="text-align: center">17</td><td style="text-align: center">fail</td><td style="text-align: center">23</td><td style="text-align: center">0.3</td></tr><tr><td style="text-align: center">100,000</td><td style="text-align: center">3029</td><td style="text-align: center">fail</td><td style="text-align: center">280</td><td style="text-align: center">5</td></tr><tr><td style="text-align: center">500,000</td><td style="text-align: center">fail</td><td style="text-align: center">fail</td><td style="text-align: center">1491</td><td style="text-align: center">62</td></tr></table><p>It seems the current version of Dagger.jl (v0.14.3) has a bug that prevents the benchmark from completing for even small <span>$n$</span>, the issue has been reported to Dagger.jl developers.</p><p>Another way to look at the results is to estimate the maximum size of a DAG that can be supported by various solutions on a single computer, assuming 6 hours is the practical upper limit for DAG creation:</p><table><tr><th style="text-align: center">Solutions</th><th style="text-align: center">Dask</th><th style="text-align: center">Dagger.jl</th><th style="text-align: center">Tensorflow</th><th style="text-align: center">Julius</th></tr><tr><td style="text-align: center">Max Graph Size</td><td style="text-align: center">&lt; 500K</td><td style="text-align: center">&lt; 1K</td><td style="text-align: center">7 MM</td><td style="text-align: center">170 MM</td></tr></table><h2 id="Conclusion-1"><a class="docs-heading-anchor" href="#Conclusion-1">Conclusion</a><a class="docs-heading-anchor-permalink" href="#Conclusion-1" title="Permalink"></a></h2><p>The graph creation benchmark clearly showed that Julius has a huge speed advantage for creating large graphs, thanks to its RuleDSL. As a result, Julius can handle much bigger enterprise problems in practice.</p><p>Julius can create DAGs with hundreds of millions of nodes from a single computer, which is sufficient to cover even the most complex enterprise use cases. In addition, Julius&#39; graph construction can be easily parallelized thanks to the simple syntax of RuleDSL, thus extending Julius&#39; upper limit to billions of nodes, if such needs ever arise in practice.</p><p>In comparison, Dask, Dagger.jl and Tensorflow are much slower in graph creation and they do not support parallelism for DAG creation. Therefore, the computational DAG creation is much more likely to become a bottleneck for large enterprise problems using these solutions.</p><h2 id="Appendix:-Source-Code-1"><a class="docs-heading-anchor" href="#Appendix:-Source-Code-1">Appendix: Source Code</a><a class="docs-heading-anchor-permalink" href="#Appendix:-Source-Code-1" title="Permalink"></a></h2><p>All the code below are directly runnable once the dependent packages are installed.</p><p>The cleanest way to implement this sequence is via recursion. However, Dask, Dagger.jl and Tensorflow does not yet support recursive functions, therefore we have to write an explicit loop in their implementation. Julius&#39; RuleDSL does support recursive definitions, which is used below for defining the sequence in Julius implementation.</p><h4 id="**Dask-implementation**-1"><a class="docs-heading-anchor" href="#**Dask-implementation**-1"><strong>Dask implementation</strong></a><a class="docs-heading-anchor-permalink" href="#**Dask-implementation**-1" title="Permalink"></a></h4><pre><code class="language-python">import dask
import numpy as np

@dask.delayed
def fib0(n) :
        return np.random.rand(10)

@dask.delayed
def wsum(a, b) :
    return  (.3*a + .7*b)

%%time
# %%time is a magic command, only works in Jupyter notebook

f0 = fib0(0)
f1 = fib0(1)

for i in range(0, 10000) :
    f2 = wsum(f0, f1)
    f0, f1 = f1, f2</code></pre><h4 id="**Dagger.jl-implementation**-1"><a class="docs-heading-anchor" href="#**Dagger.jl-implementation**-1"><strong>Dagger.jl implementation</strong></a><a class="docs-heading-anchor-permalink" href="#**Dagger.jl-implementation**-1" title="Permalink"></a></h4><pre><code class="language-julia">
using Dagger
fibsum(a, b)=.3 .* a .+ .7 .* b

f0 = Dagger.@spawn rand(10)
f1 = Dagger.@spawn rand(10)
f2 = 0 # final result will be held here

@time for i in 1:20
    f2 = Dagger.@spawn fibsum(f0, f1)
    f0, f1 = f1, f2
end
</code></pre><h4 id="**Tensorflow-implementation**-1"><a class="docs-heading-anchor" href="#**Tensorflow-implementation**-1"><strong>Tensorflow implementation</strong></a><a class="docs-heading-anchor-permalink" href="#**Tensorflow-implementation**-1" title="Permalink"></a></h4><pre><code class="language-python">import tensorflow as tf
import numpy as np

@tf.function
def wsum(a, b) :
    return a*.3 + b*.7

# have to wrap the top level call by @tf.function, otherwise
# Tensorflow does not create the computational graph
@tf.function
def fib(n, f0, f1) :
    # not using tf.range() because Tensorflow automatically
    # optimizes tf.range() into a single loop node instead of
    # creating n number of nodes in the graph, the latter is
    # the case we want to benchmark
    for i in range(0, n) :
        f2 = wsum(f0, f1)
        f0, f1 = f1, f2
    return f2

%%time
# %%time is magic command, only works in Jupyter notebook

f2 = fib(10000, np.random.rand(10), np.random.rand(10))</code></pre><h4 id="**Julius-implementation**-1"><a class="docs-heading-anchor" href="#**Julius-implementation**-1"><strong>Julius implementation</strong></a><a class="docs-heading-anchor-permalink" href="#**Julius-implementation**-1" title="Permalink"></a></h4><p>To learn more about <code>RuleDSL</code> syntax and the concept of Atoms, please refer to the quickstart tutorial. The <code>ApplyFn</code> is a convenient Atom that allows arbitrary Julia function to be used in <code>RuleDSL</code>, please refer to the mapreduce tutorial for more information on <code>ApplyFn</code>.</p><pre><code class="language-julia">using GraphEngine: RuleDSL, GraphVM
using DataScience: ApplyFn

RuleDSL.@addrules seq begin
    # Val(n&lt;=1) takes value of either Val(true) or Val(false), indicating
    # whether the term n is the initial two terms (n=0, n=1) of the sequence.
    # Base on this, its dependency fib(n, Val(n &lt;= 1)) is pattern
    # matched to the correct rule below.
    # Alias is a special Atom that simply invokes another rule.
    fib(n::Int) = RuleDSL.Alias(fib(n, Val(n &lt;= 1)))

    # the -&gt; is a lambda syntax in julia to declare anonymous functions
    # this rule defines the recursion of the sequence for non-initial terms.
    # ApplyFn is a generic Atom allows arbitrary julia function to be used
    fib(n::Int, isinitialterm::Val{false}) =
        ApplyFn[(a, b)-&gt; (.7 .* a .+ .3 .* b)](
            fib(n - 1, Val(n &lt;= 2)), fib(n - 2, Val(n &lt;= 3))
        )

    # for initial terms, simply return a random vector
    # () means the anonymous function does not have any arguments
    fib(n::Int, isinitialterm::Val{true}) = ApplyFn[()-&gt;rand(10)]()
end

ref = RuleDSL.@ref seq.fib(10000)
gs = GraphVM.createlocalgraph(RuleDSL.Config(), RuleDSL.GenericData());

# graph creation and execution all happens within this call
@time GraphVM.calcfwd!(gs, Set([ref]));
</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="t007_persist.html">« 7 ML Experiment Tracking and Persisting</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 13 April 2022 12:08">Wednesday 13 April 2022</span>. Using Julia version 1.6.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
