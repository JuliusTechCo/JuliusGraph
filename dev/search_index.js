var documenterSearchIndex = {"docs":
[{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"EditURL = \"https://github.com/JuliusTechCo/Tutorials/blob/main/src/bagging.jl\"","category":"page"},{"location":"pages/t004_bagging.html#Tutorial-4:-Distributed-Machine-Learning-Pipeline-1","page":"4 Distributed Machine Learning Pipeline","title":"Tutorial 4: Distributed Machine Learning Pipeline","text":"","category":"section"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"In this tutorial, we use Julius GraphEngine and its Domain Specific Language (RuleDSL) to build a distributed Machine Learning (ML) pipeline that can process a large volume of data in parallel for model training and inference.","category":"page"},{"location":"pages/t004_bagging.html#.-Introduction-1","page":"4 Distributed Machine Learning Pipeline","title":"0. Introduction","text":"","category":"section"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"In real world ML problems, the training or inference data can be too large to fit into the memory of a single computer. It is a common challenge that ML engineers often face when productionizing a ML model. There is a popular blog post, Training models when data doesn't fit in memory, describing how to use Dask, a popular python distribution package, to build distributed ML pipelines that can process large training and inference data in batches, in order to handle data size greater than a computer's memory.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"In this tutorial, we are going to replicate the functionality described in the blog post using Julius GraphEngine instead of using Dask or Dagger.jl, which is a Julia package inspired by Dask. We will show how to achieve similar or better results as in the original Dask blog with much fewer lines of code. Here, we will re-use the generic MapReduce pipeline developed in a previous tutorial. At the end of this tutorial, we will compare Julius with Dask, and summarize their key differences.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"We use the same fraud detection dataset as the Dask blog, which is originated from Kaggle. The realization of fraud is indicated by the column isFraud, which is the outcome the ML model tries to predict.","category":"page"},{"location":"pages/t004_bagging.html#.-Simple-ML-Pipeline-1","page":"4 Distributed Machine Learning Pipeline","title":"1. Simple ML Pipeline","text":"","category":"section"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"As a baseline solution, we first build a simple ML pipeline in Julius without batching or distribution. We will then describe step by step how to adapt it to support batching and distribution. This is enlightening as it matches a typical ML model development workflow, where a data scientist first build a ML model using a simple data pipeline, then a data engineer parallelizes the implementation to handle a large volume of data. To productionize a ML model, it often takes multiple iterations between data scientists and data engineers, which is one of the most time-consuming and costly step of a ML model's life cycle. By repeating the exact process in this tutorial, we illustrate how easy it is to move a ML pipeline from development to production using Julius.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"In order to match the numbers in the original Dask blog, we chose to use the same Python ML models in sklearn. Julius can interop and integrate with any major programming languages such as Python, C/C++, Java, R, .Net, Julia, etc.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The fraud detection ML pipeline, as described in the Dask blog, consists of the following steps:","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"read datasets,\nseparate the features from target variable from the data,\ntrain a ML model (ExtraTreesClassifier in the Dask blog),\ninfer using test data,\ncompute AUC score.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"We now proceed to the implementation. First, we import the required Julia and Julius packages:","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"using GraphEngine: RuleDSL, GraphVM\nusing DataFrames, DataScience, StatsBase\nusing AtomExt","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The following are the few rules to define the entire ML pipeline, which are quite self-explanatory and roughly follow the steps mentioned above.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"RuleDSL.@addrules ml begin\n\n    # selects columns `cols` from a DataFrame\n    select(\n        ref::RuleDSL.NodeRef, cols::Any;\n        label=\"$(isa(cols, InvertedIndex) ? \"col != $(cols.skip)\" : \"col == $(cols)\")\"\n    ) = begin\n        DataScience.ApplyFn[x::DataFrame -> DataFrames.select(x, cols; copycols=false)](ref...)\n    end\n\n    # any `sklearn` ML model can be easily handled by overloading the `classifiertrain`\n    # rule, as follows\n    classifiertrain(\n        model::Val{:ExtraTreesClassifier},\n        options::Dict,\n        trainxs::RuleDSL.NodeRef,\n        trainy::RuleDSL.NodeRef;\n        label=\"$model train\"\n    ) = begin\n        DataScience.PyTrain[\"sklearn.ensemble.ExtraTreesClassifier\", options](trainxs..., trainy...)\n    end\n\n    # this rule makes the predictions\n    classify(\n        train_data::RuleDSL.NodeRef, target::Symbol, model::Val, options::Dict, testx::RuleDSL.NodeRef;\n        label=\"$model inference\"\n    ) = begin\n        train_data_X = RuleDSL.@ref ml.select(train_data, Not(target))\n        train_data_y = RuleDSL.@ref ml.select(train_data, target)\n        trained = RuleDSL.@ref ml.classifiertrain(model, options,  train_data_X, train_data_y )\n        DataScience.PyPredict(trained..., testx...)\n    end\n\n    # makes predictions and selects the `:proba` column for the resulting DataFrame\n    classifyprob(\n        train_data::RuleDSL.NodeRef,\n        target::Symbol,\n        model::Val,\n        options::Dict,\n        test_data::RuleDSL.NodeRef;\n        label=\"prob\"\n    ) = begin\n        testx = RuleDSL.@ref ml.select(test_data, Not(target))\n        DataScience.ApplyFn[\n            x::DataFrame -> DataFrames.select(x, :proba; copycols=false)\n        ](classify(train_data, target, model, options, testx))\n    end\n\n    # computes the AUC score\n    score(realized::RuleDSL.NodeRef, probs::RuleDSL.NodeRef) = begin\n        DataScience.PyScore(realized..., probs...)\n    end\n end","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The PyTrain, PyPredict, PyScore are three useful atoms provided by the DataScience package that wraps up the training, inference and roc_auc_score method from the sklearn Python package. The PyTrain atom is generic, it can instantiate any Python ML model using its name and parameters, as shown at the ml.classifiertrain rule. Using this set of rules, we can create a simple ML pipeline as:","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"# we use existing rules in ds namespace to read CSV files from a shared drive\ntrain_data_file = joinpath(@__DIR__, \"..\", \"data/train_fraud.csv\")\ntest_data_file = joinpath(@__DIR__, \"..\", \"data/test_fraud.csv\")\ntrain_data = RuleDSL.@ref ds.csvsrc(train_data_file, true; label=\"train data\")\ntest_data  = RuleDSL.@ref ds.csvsrc(test_data_file, true; label=\"test data\")\n\ntarget = :isFraud\nmodel = Val(:ExtraTreesClassifier)\noptions = Dict(:n_estimators => 10, :min_samples_leaf => 10)\n\npred = RuleDSL.@ref ml.classifyprob(train_data, target, model, options, test_data)\ntest_data_y = RuleDSL.@ref ml.select(test_data, target)\nmlscore = RuleDSL.@ref ml.score(test_data_y, pred)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"ml:score/ml:select/ds:csvsrc/test data","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"config = RuleDSL.Config()\ngs1 = GraphVM.createlocalgraph(config, RuleDSL.GenericData())\nGraphVM.calcfwd!(gs1, Set([mlscore]))","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"0","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"We have now created a simple ML training and inference pipeline without using batching or distribution. Julius provides an easy-to-use web UI for users to navigate and visualize the resulting data and logic in the computation graph. The following code block starts a local server for the web UI so that we can retrieve the resulting graph data.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"using GraphIO\n\n# a container of graphs\ngss = Dict{String,RuleDSL.AbstractGraphState}()\n\n# used for WebUI display purposes\nport = GraphVM.drawdataport()\n@async GraphVM.startresponder(gss, port);","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The Julius package GraphIO provides several convenience functions for retrieving and displaying graphs in SVG format. User can also view the graph data interactively by clicking on the url below to bring up the full web UI.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"svg = GraphIO.postlocalgraph(gss, gs1, port; key=\"single\");\nGraphIO.postsvg(svg, \"ml_pipeline_1.svg\")","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7239_single\n","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"<p align = \"center\">\n<img src=\"../assets/ml_pipeline_1.svg\" alt=\"\" title=\"simple pipeline\"/>\n</p>\n<p align = \"center\">\nFigure 1 - Simple ML Pipeline.\n</p>","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Then, the AUC score value obtained using the complete dataset is:","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"RuleDSL.getdata(gs1, mlscore, 1)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"0.9882558929901634","category":"page"},{"location":"pages/t004_bagging.html#.1-Down-Sampling-1","page":"4 Distributed Machine Learning Pipeline","title":"1.1 Down Sampling","text":"","category":"section"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Downsampling is a common technique to reduce the training data size so that the training can run faster with a large amount of data. The Dask blog implemented a 5% downsampling while maintaining a constant fraction of real fraud. We replicate the same downsampling scheme using a single Julia function and a single rule in Julius:","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"using Random\nusing StatsBase\n\nfunction downsample(ycol::Symbol, frac::Float64, df::DataFrame)\n    # get filtered DataFrames with true/false cases for isFraud\n    positive = DataFrames.filter(row -> isequal(row[ycol], true), df)\n    negative = DataFrames.filter(row -> isequal(row[ycol], false), df)\n\n    # sample without replacement each DataFrame\n    dspositive = positive[sample(1:nrow(positive), round(Int, frac * nrow(positive)), replace=false), :]\n    dsnegative = negative[sample(1:nrow(negative), round(Int, frac * nrow(negative)), replace=false), :]\n\n    # concatenate both sampled DataFrames\n    merged = vcat(dspositive, dsnegative)\n\n    # shuffle rows before returning\n    return merged[shuffle(1:nrow(merged)), :]\nend\n\n@addrules ml begin\n    downsample(\n        raw::RuleDSL.NodeRef, ycol::Symbol, frac::Float64\n    ) = begin\n        DataScience.ApplyFn[downsample, ycol, frac](raw...)\n    end\nend","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Let's test the downsampling:","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"sampleratio = 0.05\ndownsamples = RuleDSL.@ref ml.downsample(train_data, target, sampleratio)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"ml:downsample/ds:csvsrc/train data","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"gs2 = GraphVM.createlocalgraph(config, RuleDSL.GenericData())\nGraphVM.calcfwd!(gs2, Set([downsamples]))\n\nsvg = GraphIO.postlocalgraph(gss, gs2, port; key=\"downsample\");\nGraphIO.postsvg(svg, \"ml_pipeline_2.svg\")","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7239_downsample\n","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"<p align = \"center\">\n<img src=\"../assets/ml_pipeline_2.svg\" alt=\"\" title=\"ml training tutorial\"/>\n</p>\n<p align = \"center\">\nFigure 2 - Down Sample\n</p>","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"We can verify that the fraud frequency remains unchanged, the minor remaining difference is due to rounding.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"sample_df = RuleDSL.getdata(gs2, downsamples, 1)\nsum(sample_df.isFraud) / size(sample_df, 1) * 100","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"0.12966091705630425","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"# use full data set to verify\nusing CSV\ndf = CSV.read(train_data_file, DataFrames.DataFrame)\nsum(df.isFraud) / size(df, 1) * 100","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"0.12828849784581414","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"It is easy to modify the existing ML pipeline to include downsampling, we just replace the train_data with downsamples:","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"downproba = RuleDSL.@ref ml.classifyprob(downsamples, target, model, options, test_data)\ndownscore = RuleDSL.@ref ml.score(test_data_y, downproba)\n\ngs3 = GraphVM.createlocalgraph(config, RuleDSL.GenericData())\nGraphVM.calcfwd!(gs3, Set([downscore]))\n\nsvg = GraphIO.postlocalgraph(gss, gs3, port; key=\"downscore\");\nGraphIO.postsvg(svg, \"ml_pipeline_3.svg\")","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7239_downscore\n","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"<p align = \"center\">\n<img src=\"../assets/ml_pipeline_3.svg\" alt=\"\" title=\"ml training tutorial\"/>\n</p>\n<p align = \"center\">\nFigure 3 - ML with Down Sample\n</p>","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Then, the AUC score obtained using downsampling is slightly less than training with the full data, as expected.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"RuleDSL.getdata(gs3, downscore, 1)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"0.987927346704317","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"We now have built the baseline ML pipeline where the entire training and inference data is processed all at once. A obvious downside of this implementation is that it can't handle large training or inference data, if they don't fit into the computer's memory. Now let's proceed to productionize the pipeline by adding batching and distribution.","category":"page"},{"location":"pages/t004_bagging.html#.-ML-Pipeline-with-Batching-1","page":"4 Distributed Machine Learning Pipeline","title":"2. ML Pipeline with Batching","text":"","category":"section"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"It is a common strategy to break the training data into multiple batches and train a separate ML model for each batch. Once we have multiple trained ML models, we can average their inferences for better accuracy. This strategy of boosting accuracy from multiple trained models is commonly called \"bagging\". Batching and bagging are often used together to allow large training data to be split across multiple machines, and be processed in parallel.","category":"page"},{"location":"pages/t004_bagging.html#.1-Training-Data-Batching-1","page":"4 Distributed Machine Learning Pipeline","title":"2.1 Training Data Batching","text":"","category":"section"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"We use a convenience type DataScience.DDataFrame provided by Julius DataScience package to create a vector of RuleDSL.NodeRef that represents roughly equal-sized chunks from the large input CSV file.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"train_ddf = DataScience.DDataFrame(train_data_file, blocksize=\"5 MB\")\ntrain_batches = train_ddf.chunks\ndown_batches = RuleDSL.@ref(ml.downsample(b, target, sampleratio) for b in train_batches)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"8-element Vector{NodeRef}:\n ml:downsample/dd:read_csv_blocks//home/runner/work/Tutorials/Tutorials/docs/../data/train_fraud.csv\n ml:downsample/dd:read_csv_blocks//home/runner/work/Tutorials/Tutorials/docs/../data/train_fraud.csv\n ml:downsample/dd:read_csv_blocks//home/runner/work/Tutorials/Tutorials/docs/../data/train_fraud.csv\n ml:downsample/dd:read_csv_blocks//home/runner/work/Tutorials/Tutorials/docs/../data/train_fraud.csv\n ml:downsample/dd:read_csv_blocks//home/runner/work/Tutorials/Tutorials/docs/../data/train_fraud.csv\n ml:downsample/dd:read_csv_blocks//home/runner/work/Tutorials/Tutorials/docs/../data/train_fraud.csv\n ml:downsample/dd:read_csv_blocks//home/runner/work/Tutorials/Tutorials/docs/../data/train_fraud.csv\n ml:downsample/dd:read_csv_blocks//home/runner/work/Tutorials/Tutorials/docs/../data/train_fraud.csv","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Training data batching and bagging can be easily implemented using the following single rule, which just re-uses the previous ml.classifyprob for each input batch and average their output.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"# compute the average of multiple dataframes\nfunction dfmean(dfs::DataFrame...)\n    df = reduce(.+, dfs)\n    df ./ (length(dfs))\nend\n\nRuleDSL.@addrules ml begin\n    bagpred(\n        test::RuleDSL.NodeRef,\n        model::Val,\n        options::Dict,\n        train_batches::Vector{RuleDSL.NodeRef},\n        target::Symbol\n    ) = begin\n        refs = RuleDSL.@ref((ml.classifyprob(b, target, model, options, test) for b in train_batches))\n        DataScience.ApplyFn[dfmean](refs...)\n    end\nend\n\nbagpred = RuleDSL.@ref ml.bagpred(test_data, model, options, down_batches, target)\nbagscore = RuleDSL.@ref ml.score(test_data_y, bagpred)\n\ngs4 = GraphVM.createlocalgraph(config, RuleDSL.GenericData())\nGraphVM.calcfwd!(gs4, Set([bagscore]))\n\nsvg = GraphIO.postlocalgraph(gss, gs4, port; key=\"ml\");\nGraphIO.postsvg(svg, \"ml_pipeline_4.svg\")","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7239_ml\n","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"<p align = \"center\">\n<img src=\"../assets/ml_pipeline_4.svg\" alt=\"\" title=\"ml training tutorial\"/>\n</p>\n<p align = \"center\">\nFigure 4 - Batching & Bagging in Training Data\n</p>","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The AUC score obtained using multiple samples of the data is:","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"RuleDSL.getdata(gs4, bagscore, 1)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"0.9814905420636669","category":"page"},{"location":"pages/t004_bagging.html#.2-Batching-both-Training-and-Prediction-Data-1","page":"4 Distributed Machine Learning Pipeline","title":"2.2 Batching both Training and Prediction Data","text":"","category":"section"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"In the previous implementation, the training data is batched but not the inference data. In practice, the inference data could also be too large to fit into the memory of a single machine. In that case, we will also need to batch the inference data. It is a much more complex pipeline to batch both training and inference data. However, in Julius, we can leverage the generic MapReduce pattern to easily define this complicated pipeline with very little coding.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"We first use DataScience.DDataFrame to create a vector of NodeRef.RuleDSL for the inference data.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"test_ddf = DataScience.DDataFrame(test_data_file, blocksize=\"3.5 MB\")\ntest_batches = test_ddf.chunks","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"3-element Vector{NodeRef}:\n dd:read_csv_blocks//home/runner/work/Tutorials/Tutorials/docs/../data/test_fraud.csv\n dd:read_csv_blocks//home/runner/work/Tutorials/Tutorials/docs/../data/test_fraud.csv\n dd:read_csv_blocks//home/runner/work/Tutorials/Tutorials/docs/../data/test_fraud.csv","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The doubly batched training and inference ML pipeline naturally maps to a MapReduce pipeline as following:","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"mapper: compute the bagged inference of a single test batch from multiple trained models, this stage already includes training data batching,\nshuffler/reducer: move the individual batch inference and concatenate them to form the entire inference.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The following batchpred rule extracts the realization and inference from the same test batch file in a DataFrame, and assign a unique key using the hash of the batch file's NodeRef.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"RuleDSL.@addrules ml begin\n    # extract both realization and prob predictions\n    batchpred(\n        test::RuleDSL.NodeRef,\n        model::Val,\n        options::Dict,\n        train_batches::Vector{RuleDSL.NodeRef},\n        target::Symbol\n    ) = begin\n        DataScience.ApplyFn[\n            (ind, prob)->[hash(test) => hcat(ind, prob)]\n        ](select(test, target), bagpred(test, model, options, train_batches, target))\n    end\nend\n\n# extracts the DataFrames from `batchpred` from all batches and concatenates them\nfunction valcat(xs::Vector...)\n    agg = DataFrame()\n    for (_, v) in vcat(xs...)\n        agg = vcat(agg, v)\n    end\n    return agg\nend","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"valcat (generic function with 1 method)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The following is the entire definintion of the doubly batched ML pipeline using the MapReduce pattern:","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"mapper = RuleDSL.@ref ml.batchpred(model, options, down_batches, target)\n\n# map all batches to 3 pipelines before reducing\nshuffler = RuleDSL.@ref mr.shuffler(first, 3)\n\n# simply concatenates all the vectors in a given pipeline\nreducer = RuleDSL.@ref mr.reducer(vcat)\n\n# valcat extracts the DataFrame from each batch, and concatenate them together\nmrpred = RuleDSL.@ref mr.mapreduce(test_batches, mapper, shuffler, reducer, valcat)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"mr:mapreduce/NodeRef[3]","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The last step in MapReduce is to aggregate the results from the mapper/shuffler results of individual test batches. The generic mr.mapreduce rule can take an optional function as the last parameter to customize this aggregation. The function valcat is used for the aggregation, which concatenates individual batchs' fraud realization and inference into a single DataFrame.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"mrscore = RuleDSL.@ref ml.score(RuleDSL.@ref(ml.select(mrpred, :isFraud)), RuleDSL.@ref(ml.select(mrpred, :proba)))\n\ngs5 = GraphVM.createlocalgraph(config, RuleDSL.GenericData())\nGraphVM.calcfwd!(gs5, Set([mrscore]))\n\nsvg = GraphIO.postlocalgraph(gss, gs5, port; key=\"mapred\");\nGraphIO.postsvg(svg, \"ml_pipeline_5.svg\")","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7239_mapred\n","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"<p align = \"center\">\n<img src=\"../assets/ml_pipeline_5.svg\" alt=\"\" title=\"ml training tutorial\"/>\n</p>\n<p align = \"center\">\nFigure 5 - Doubly Batching in Training and Inference\n</p>","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The corresponding AUC score from the doubly batched pipeline is similar:","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"RuleDSL.getdata(gs5, mrscore, 1)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"0.9771066540540865","category":"page"},{"location":"pages/t004_bagging.html#.-Distributed-ML-Pipeline-1","page":"4 Distributed Machine Learning Pipeline","title":"3. Distributed ML Pipeline","text":"","category":"section"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"We have now adapted the simple ML pipeline to support doubly data batching in both training and inference. However, the real benefits of batching only comes from distributing the data and computation to multiple computers, so that we can process large volume of data and computation in parallel.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Using Julius, it is effortless to distribute the batched pipeline to multiple computers and run it in parallel. Let's use the doubly batched ML pipeline as an example to show how easy it is to distribute. We first connect to a remote cluster with 3 worker instances, and import necessary packages on the remote cluster:","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"using GraphEngine: RuleDSL, GraphVM\n\nconfig = RuleDSL.newconfig(RuleDSL.Config(), :project => \"MapReduce\")\nbalancer = GraphVM.GlobalUnique()\nmy_domain = GraphVM.mydomain()\n\n# draw a port number to start the local cluster esrvice\nremoteport = GraphVM.drawdataport()","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"7710","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"# start a local master service at the given port, which mimic the effects of a remote cluster\n\ngs0 = GraphVM.RemoteGraphProxy(my_domain => 7225)\nGraphVM.rpccall(gs0, :startlocalmasterservice, remoteport, 3)\ngs = GraphVM.RemoteGraphProxy(config, my_domain => remoteport, balancer, GraphVM.GenericData())\nGraphVM.wait4clusterinit(gs)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Dict{UInt64, Pair{Float64, GraphEngine.GraphVM.WorkerStatus}} with 3 entries:\n  0x5b7cf1e95a1440b4 => 1.64847e9=>Ready\n  0x6ed3384700c094c3 => 1.64847e9=>Ready\n  0x860c4a99af328894 => 1.64847e9=>Ready","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"GraphVM.@remote_eval gs begin\n    using GraphEngine: RuleDSL, GraphVM\n    using DataScience, Random, AtomExt, GraphIO\n    using StatsBase, DataFrames\nend\n\nGraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"We now load the entire doubly batched ML pipeline to the remote cluster, by sending the entire code we have written so far to the remote cluster. The following is the full list of code to replicate the Dask blog in Julius. There are only 8 rules, and about 50 lines of code in total.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"GraphVM.@remote_eval gs  begin\n    function downsample(ycol::Symbol, frac::Float64, df::DataFrame)\n        positive = DataFrames.filter(row -> isequal(row[ycol], true), df)\n        negative =  DataFrames.filter(row -> isequal(row[ycol], false), df)\n        dspositive = positive[sample(1:nrow(positive), round(Int, frac * nrow(positive)), replace=false), :]\n        dsnegative = negative[sample(1:nrow(negative), round(Int, frac * nrow(negative)), replace=false), :]\n        merged = vcat(dspositive, dsnegative)\n        return merged[shuffle(1:nrow(merged)), :]\n    end\n\n    function dfmean(dfs::DataFrame...)\n        df = reduce(.+, dfs)\n        return df ./ (length(dfs))\n    end\n\n    function valcat(xs::Vector...)\n        agg = DataFrame()\n        for (_, v) in vcat(xs...)\n            agg = vcat(agg, v)\n        end\n        return agg\n    end\nend\n\nGraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\n\nGraphVM.@addrules gs ml begin\n    select(ref::RuleDSL.NodeRef, cols::Any; label=\"$(isa(cols, InvertedIndex) ? \"col != $(cols.skip)\" : \"col == $(cols)\")\") = DataScience.ApplyFn[x::DataFrame->DataFrames.select(x, cols; copycols=false)](ref...)\n    classifiertrain(model::Val{:ExtraTreesClassifier}, options::Dict, trainxs::RuleDSL.NodeRef, trainy::RuleDSL.NodeRef; label=\"$model train\") = DataScience.PyTrain[\"sklearn.ensemble.ExtraTreesClassifier\", options](trainxs..., trainy...)\n    classify(train_data::RuleDSL.NodeRef, target::Symbol, model::Val, options::Dict, testx::RuleDSL.NodeRef; label=\"$model inference\") = begin\n        train_data_X = RuleDSL.@ref ml.select(train_data, Not(target))\n        train_data_y = RuleDSL.@ref ml.select(train_data, target)\n        trained = RuleDSL.@ref ml.classifiertrain(model, options,  train_data_X, train_data_y )\n        DataScience.PyPredict(trained..., testx...)\n    end\n    classifyprob(train_data::RuleDSL.NodeRef, target::Symbol, model::Val, options::Dict, test_data::RuleDSL.NodeRef; label=\"prob\") = begin\n        testx = RuleDSL.@ref ml.select(test_data, Not(target))\n        DataScience.ApplyFn[x::DataFrame->DataFrames.select(x, :proba; copycols=false)](classify(train_data, target, model, options, testx))\n    end\n    score(realized::RuleDSL.NodeRef, probs::RuleDSL.NodeRef)=DataScience.PyScore(realized..., probs...)\n    downsample(raw::RuleDSL.NodeRef, ycol::Symbol, frac::Float64)=DataScience.ApplyFn[Main.downsample, ycol, frac](raw...)\n    bagpred(test::RuleDSL.NodeRef, model::Val, options::Dict, train_batches::Vector{RuleDSL.NodeRef}, target::Symbol) = DataScience.ApplyFn[Main.dfmean](RuleDSL.@ref((ml.classifyprob(b, target, model, options, test) for b = train_batches))...)\n    batchpred(test::RuleDSL.NodeRef, model::Val, options::Dict, train_batches::Vector{RuleDSL.NodeRef}, target::Symbol) = DataScience.ApplyFn[(ind, prob)->[hash(test) => hcat(ind, prob)]](select(test, target), bagpred(test, model, options, train_batches, target))\nend\n\nGraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Afterwards, we can create and run the doubly batched pipeline on the cluster.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"mrpred = RuleDSL.@ref mr.mapreduce(test_batches, mapper, shuffler, reducer, Main.valcat)\nmrscore = RuleDSL.@ref ml.score(RuleDSL.@ref(ml.select(mrpred, :isFraud)), RuleDSL.@ref(ml.select(mrpred, :proba)))\n\n# select all the nodes with rule name classifiertrain, splitbykey and reducer in alljobs\nkeyjobs, ds = RuleDSL.jobdeps(config, [mrscore], Set([:classifiertrain, :splitbykey, :reducer]));\nGraphVM.initgraph!(gs)\n\n# distribute the nodes in alljobs to workers\nGraphVM.dispatchjobs!(gs, keyjobs, 1)\nGraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"In the code block above, we first find the keyjobs, which is a vector of NodeRef that holds all the nodes in the graph that are associated with rule name classifertrain, splitbykey and reducer. These nodes are the main points of computation and data aggregations. A developer can use his domain knowledge about the specific workload in selecting the best set of rule names for the key jobs. The last key job is always the final node that user want to compute, which is mrscore in the cell above. Once the key jobs are determined, we send them to the workers by calling GraphVM.dispatchjobs!, whose 3rd parameter specifies the number of threads worker shall run to process these jobs concurrently.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The way Julius distribute the jobs to workers is fundamentally different from Dask or Dagger.jl distribution. In Dask or Dagger.jl, every node in their graph represents a separate task that must be sent to a worker for execution individually. In Julius, since every worker holds the entire graph logic as specified by the set of rules in RuleDSL, the dispatcher does not need to send every node to the worker, instead only few key jobs are sent in the format of NodeRef object. Once a worker receives a job definition in NodeRef, it can create any dependent nodes from the common set of rules shared by all workers and the dispatcher. As a result, Julius distribution requires much less communication between the dispathcer and the workers, thus incurring much less overhead.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The following cell shows that only 15 nodes need to be sent to the workers instead of all 125 nodes in the graph.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"gstats = GraphVM.rpccall(gs, GraphIO.graphstats, UInt(1), UInt(1))\nprintln(\"length of keyjobs = \", length(keyjobs))\nprintln(\"graph node cnt = \", gstats[:cnt])","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"length of keyjobs = 15\ngraph node cnt = 125\n","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"By creating dependent nodes at worker, Julius also achieves much better locality for graph execution, as all the dependent nodes created by the worker are local. Therefore Julius graph distribution and execution are much more efficient than Dask or Dagger.jl. Julius can easily distribute graphs as large as hundreds of millions of nodes, and even in these cases, the number of keyjobs to distribute is rarely more than a few thousands. In comparison, Dask or Dagger.jl suffer from huge overhead when dealing with large graphs because of the need to distribute every node. As a result, developers are advised to \"avoid large graphs\" when using Dask, Julius does not have such limitations on large graphs.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"svg = GraphIO.postremotegraph(gs, remoteport);\nGraphIO.postsvg(svg, \"ml_pipeline_6.svg\")","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"<p align = \"center\">\n<img src=\"../assets/ml_pipeline_6.svg\" alt=\"\" title=\"ml training tutorial\"/>\n</p>\n<p align = \"center\">\nFigure 6 - Distributed ML Pipeline.\n</p>","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Data from the remote cluster are easily accessible using Julius' remote RPC interface.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"GraphVM.rpccall(gs, :onnode, :getdata, UInt[0], hash(mrscore), 1)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"0.9697909078884458","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The resulting graph uses different colors to indicate the placement of nodes to individual workers instance, where a single color represent a given physical worker instance. There is a network data transfer for every arrow connecting two nodes of different colors. The entire graph distribution is handled by Julius automatically without the need for the developer to change a single line of code.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Upon close examination, we observe that the resulting MapReduce distribution is optimal in that the work load is evenly distributed amongst 3 workers, and there is no unnecessary data transfer between different physical computers (represented by different colors) at all in the resulting graph distribution.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Neither training nor inference input data were ever aggregated onto a single computer, so that we can stay within individual worker's memory limit. Only the realization and inference outputs were aggregated to a single machine, which are only two columns of data, a tiny fraction comparing to the entire inference input data set.","category":"page"},{"location":"pages/t004_bagging.html#.-Streaming-1","page":"4 Distributed Machine Learning Pipeline","title":"4. Streaming","text":"","category":"section"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Besides batching, streaming is another effective strategy to minimize memory usage. Instead of processing the entire data set at once, we could break it into multiple batches and process them sequentially in time. Streaming was not implemented in the original Dask blog, as the DAG created by Dask does not support streaming use case.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"In contrast, any pipeline created in Julius can be easily run in streaming mode with one line of code change. In the streaming mode, the RuleDSL.fwddata! method will be called multiple times with different streaming values. Therefore, we can easily implement a few Atom types that act as the the source, running average and cumulator, so that we can express rich logic and behaviors in stream processing. These atoms are generic, they can be readily re-used in other streaming use cases.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"# records the streaming value x\nRuleDSL.@datom Record begin\n    values::Vector = []\n\n    function fwddata!(x::Any)\n        push!(values, x)\n    end\nend\n\n# computes the running average of all the value being streamed\nRuleDSL.@datom RunningAverage begin\n    sum::DataFrame = DataFrame()\n    cnt::Vector = [0]\n\n    function fwddata!(x::DataFrame)\n        if cnt[1] == 0\n            append!(sum, x)\n        else\n            sum .+= x\n        end\n\n        cnt[1] += 1\n        [ sum ./ cnt[1] ]\n    end\nend\n\n# sequentially return values as represented in batchsrc, for each fwddata! call\n# this only work for a source node, i.e., NodeRef without any further dependencies\nRuleDSL.@datom StreamSrc begin\n    config::RuleDSL.Config\n    batchsrc::Vector{RuleDSL.NodeRef}\n    idx::Vector = [0]\n\n    function fwddata!()\n        thissrc = batchsrc[idx[1] % length(batchsrc) + 1]\n        atom = RuleDSL.calcop(config, thissrc)\n        idx[1] += 1\n        RuleDSL.fwddata!(atom)\n    end\nend","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"fwddata! (generic function with 93 methods)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"We then add a few generic high level rules to connect these Atoms for streaming source, running average and cumulator:","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"RuleDSL.@addrules ml begin\n    streamsrc(refs::Vector{RuleDSL.NodeRef}) = StreamSrc[RuleDSL.@config, refs]()\n    runningaverage(ref::RuleDSL.NodeRef) = RunningAverage(ref...)\n    record(ref::RuleDSL.NodeRef) = Record(ref...)\nend","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"You might be curious of how the ML performance improves as more training data is added in the bagging process. The following is a streaming pipeline that can answer this kind of questions. The streaming ML pipeline receives individual training data: for each of which a new ML model is trained, then its inference is used to compute a running average of model inferences. The ML scores computed from the running average inference are then recorded, which shows how AUC score improves with more training data.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"stream_ddf = DataScience.DDataFrame(train_data_file, blocksize=\"2 MB\")\nstream_batches = stream_ddf.chunks\n\nstream_src = RuleDSL.@ref ml.streamsrc(stream_batches)\ndown_stream = RuleDSL.@ref ml.downsample(stream_src, target, sampleratio)\n\n# change the mapper to use the streaming data source for training\nstreammapper = RuleDSL.@ref ml.batchpred(model, options, [down_stream], target)\n\n# the shuffler/reducer remains the same as before\nshuffler = RuleDSL.@ref mr.shuffler(first, 3)\nreducer = RuleDSL.@ref mr.reducer(vcat)\n\nstreampred = RuleDSL.@ref mr.mapreduce(test_batches, streammapper, shuffler, reducer, valcat)\n\n# we use the running average to compute the ML score\nstreamprob = RuleDSL.@ref ml.select(streampred, :proba)\nstreamprobavg = RuleDSL.@ref ml.runningaverage(streamprob)\nstreamscore = RuleDSL.@ref ml.score(RuleDSL.@ref(ml.select(streampred, :isFraud)), streamprobavg)\n\n# finally we record all the ML score history\nstreamrecord = RuleDSL.@ref ml.record(streamscore)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"ml:record/ml:score/ml:select/mr:mapreduce/NodeRef[3]","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"# create a local graph with the default pipeline\ngs7 = RuleDSL.createlocalgraph(config, RuleDSL.GenericData(), Set([streamrecord]));\n\n# this single line of code turns the regular batch pipeline into a streaming pipeline,\n# by specifying the source and sink of the stream processing\nRuleDSL.initstream!(gs7, Set(hash(stream_src)), Set(hash(streamrecord)));","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"svg = GraphIO.postlocalgraph(gss, gs7, port, true; key=\"stream\");\nGraphIO.postsvg(svg, \"ml_pipeline_7.svg\")","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7239_stream\n","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"<p align = \"center\">\n<img src=\"../assets/ml_pipeline_7.svg\" alt=\"\" title=\"ml training tutorial\"/>\n</p>\n<p align = \"center\">\nFigure 7 - Local Streaming.\n</p>","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"# stream all the training batches data through\nRuleDSL.pushpullcalc!(gs7, length(stream_batches))\n\n# stop any further streaming, and persist the state\nRuleDSL.stopstream!(gs7);","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The recorded history of ML score clearly shows the improvements in model inference, it is quite interesting to see how much the quality of inference improves with more training data.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"GraphVM.getdata(gs7, hash(streamrecord))","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"20-element Vector{Any}:\n 0.7968585598052131\n 0.9593462085819503\n 0.9691530658012474\n 0.9657251446737141\n 0.9660233866688851\n 0.9707457740736911\n 0.9690062984212916\n 0.979226478999267\n 0.981011528183084\n 0.9811345486150143\n 0.982567000116908\n 0.9808796319194953\n 0.9818525542161091\n 0.9833131086150741\n 0.9824233708937922\n 0.9820369560590595\n 0.9841064533994013\n 0.9830938591797551\n 0.9839590771233424\n 0.9846265209287896","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Julius streaming is fully pipelined, in that each node in the graph processes a different input data batch simultaneously, which is a lot faster than the mini-batching approach in Spark. Julius streaming also works for distributed graphs across multiple computers, again without any code changes following a similar API as the local streaming case.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"gs = GraphVM.RemoteGraphProxy(config, my_domain => remoteport, balancer, GraphVM.GenericData())\nGraphVM.rpccall(gs, GraphVM.workerstatus)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Dict{UInt64, Pair{Float64, GraphEngine.GraphVM.WorkerStatus}} with 3 entries:\n  0x5b7cf1e95a1440b4 => 1.64847e9=>Ready\n  0x6ed3384700c094c3 => 1.64847e9=>Ready\n  0x860c4a99af328894 => 1.64847e9=>Ready","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"GraphVM.@remote_eval gs begin\n\n    RuleDSL.@datom Record begin\n        values::Vector = []\n\n        function fwddata!(x::Any)\n            push!(values, x)\n        end\n    end\n\n    RuleDSL.@datom RunningAverage begin\n        sum::DataFrame = DataFrame()\n        cnt::Vector = [0]\n\n        function fwddata!(x::DataFrame)\n            if cnt[1] == 0\n                append!(sum, x)\n            else\n                sum .+= x\n            end\n\n            cnt[1] += 1\n            [ sum ./ cnt[1] ]\n        end\n    end\n\n    RuleDSL.@datom StreamSrc begin\n        config::RuleDSL.Config\n        batchsrc::Vector{RuleDSL.NodeRef}\n        idx::Vector = [0]\n\n        function fwddata!()\n            thissrc = batchsrc[idx[1] % length(batchsrc) + 1]\n            atom = RuleDSL.calcop(config, thissrc)\n            idx[1] += 1\n            RuleDSL.fwddata!(atom)\n        end\n    end\nend\n\nGraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\n\nGraphVM.@addrules gs ml begin\n    streamsrc(refs::Vector{RuleDSL.NodeRef})=StreamSrc[@config, refs]()\n    runningaverage(ref::RuleDSL.NodeRef)=RunningAverage(ref...)\n    record(ref::RuleDSL.NodeRef)=Record(ref...)\nend","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"GraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\n\nstreampred = RuleDSL.@ref mr.mapreduce(test_batches, streammapper, shuffler, reducer, Main.valcat)\nstreamprob = RuleDSL.@ref ml.select(streampred, :proba)\nstreamprobavg = RuleDSL.@ref ml.runningaverage(streamprob)\nstreamscore = RuleDSL.@ref ml.score(RuleDSL.@ref(ml.select(streampred, :isFraud)), streamprobavg)\nstreamrecord = RuleDSL.@ref ml.record(streamscore)\n\n# create a regular batch piepline\nGraphVM.createremotegraph(gs, Set([streamrecord]), Set([:bagpred, :splitby, :reducer]))\n\n# turns it into streaming mode by specifying data source and sink\nGraphVM.initstream!(gs, UInt(0), Set(hash(stream_src)), Set(hash(streamrecord)))\n\n# stream data through\nRuleDSL.pushpullcalc!(gs, Set(UInt(0)), length(stream_batches))\nGraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\n\n# finalize, no longer accept future streaming data\nRuleDSL.stopstream!(gs);\n\nsvg = GraphIO.postremotegraph(gs, remoteport, true);\nGraphIO.postsvg(svg, \"ml_pipeline_8.svg\")","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"<p align = \"center\">\n<img src=\"../assets/ml_pipeline_8.svg\" alt=\"\" title=\"ml training tutorial\"/>\n</p>\n<p align = \"center\">\nFigure 6 - Distributed Streaming.\n</p>","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"We can retrieve the distributed streaming results:","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"GraphVM.rpccall(gs, :onnode, :getdata, UInt[0], hash(streamrecord))","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"20-element Vector{Any}:\n 0.744555251045053\n 0.8233723083045184\n 0.9252395256755561\n 0.9387466210950088\n 0.9484878814687249\n 0.9554575872950923\n 0.9637295579526703\n 0.9672698204112465\n 0.9687484075024992\n 0.9670127023221238\n 0.972477474591234\n 0.968418596586285\n 0.9747206712545583\n 0.9737553367401539\n 0.9778291795377934\n 0.9761153477789719\n 0.9778822940132587\n 0.9757316729767038\n 0.9758555130764653\n 0.9745267612647652","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"GraphVM.rpccall(gs, :endcluster)","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"0","category":"page"},{"location":"pages/t004_bagging.html#.-Conclusions-1","page":"4 Distributed Machine Learning Pipeline","title":"5. Conclusions","text":"","category":"section"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"This tutorial shows how to adapt a simple ML pipeline for batching and distribution using Julius step by step. It only takes two additional rules ml.bagpred, ml.batchpred and one additional function valcat to turn a simple ML pipeline into a doubly batched and fully distributed ML pipeline. This is astonishing, if you consider the fact the resulting doubly batched pipeline is quite complex with 125 nodes, a big increase from the 13 nodes in the original simple ML pipeline.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"We have explained in section 3 that Julius graph distribution and execution is much more efficient than Dask or Dagger.jl, as Julius only needs to communicate a few key jobs to the worker, and the resulting graph distribution has much better locality. Julius can achieve such efficiency in distribution thanks to the use of RuleDSL, which is a low-code representation of the entire graph logic shared among both the dispather and the workers, allowing workers to create any necessary dependent nodes from the key jobs.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"The low-code RuleDSL is a huge advantage of Julius. The original solution in the Dask blog requires a significant amout of coding. Low code does not mean less power or flexiblity. The high order rules in Julius is extremely powerful and expressive. For example, the doubly batched pipeline can be quite easily constructed using the existing generic mr.mapreduce rule.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Furthermore, Julius' web UI offers much easier and more intuitive visualization and navigation of data, logic and distribution in the distributed graph, with every intermediate results full visible to the user. In comparison, it is quite difficult to access intermediate data and distribution results from Dask, as individual tasks in Dask are transient, their states are not persisted. Yes, one can manually record and persist intermediate results from Dask, but that requires additional coding and efforts.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Julius is also flexible in running the ML pipeline in batch, streaming or distributed modes. Distributed streaming is also supported without code changes. Dask, on the other hand, only support batch processing, but not streaming use cases.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Last but not the least, Julius' auto-scaling capability fully automates the productionization process of ML models, making it effortless to move a model from development to production. This tutorial showed that Julius can distribute the execution of any application written in Julius RuleDSL automatically and optimally over multiple computers without any code changes. In comparison, to move a non-trivial Python application to Dask distribution, developers have to modify the code base heavily and manually using Dask API, then they have to go through extensive testing and performance tuning, as shown in the original Dask blog.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"Thinking of migrating your python application to Dask? You will get better return on your time and efforts by learning Julius instead.","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"","category":"page"},{"location":"pages/t004_bagging.html#","page":"4 Distributed Machine Learning Pipeline","title":"4 Distributed Machine Learning Pipeline","text":"This page was generated using Literate.jl.","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"EditURL = \"https://github.com/JuliusTechCo/Tutorials/blob/main/src/persist.jl\"","category":"page"},{"location":"pages/t007_persist.html#Tutorial-7:-MLOps:-ML-Experiment-Tracking-and-Persiting-1","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"Tutorial 7: MLOps: ML Experiment Tracking and Persiting","text":"","category":"section"},{"location":"pages/t007_persist.html#How-to-use-this-tutorial-1","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"How to use this tutorial","text":"","category":"section"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Select \"run all cells\" on this notebook from the Run menu in Jupyter notebook or Jupyter","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"lab. This step will produce intermediate data output and charts.","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Some cells print out a url, which you can click on and bring up an interactive web UI to visualize the graph data.\nIn the unlikely event that the notebook becomes irresponsive, you can try \"Restart Kernel\" from the Kernel menu, then run individual cells one by one using Shift+Enter.\nSome tutorials use local clusters consisting of multiple processes to mimic the effects","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"of graph distribution over a remote clusters. By default, these local clusters   automatically stop after idling for 15min to conserve CPU and memory resources. You will   need to rerun the entire notebook if your local cluster stopped due to inactivity.","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Additional resources (video demos & blogs) are available at http://juliustech.co\nTo report any issues, get help or request features, please raise an issue at:","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"https://github.com/JuliusTechCo/JuliusGraph/issues","category":"page"},{"location":"pages/t007_persist.html#Introduction-1","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"Introduction","text":"","category":"section"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"ML model experiment tracking is a common challenge for datas scientists and engineers. Once in a while, we hear the following kind of story:","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"”My team spent months to train a massive ML model, we got exellent results at some point. But unfortunately we can't reproduce it any more, a number of things have changed, including data, underlying python library versions and hyperparameters, we are just not sure what combination might have worked ...\".","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Such story highlights the challenge in ML experment tracking, in order to reproduce a past ML run exactly, three things has to be persisted and recovered,","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"runtime environment, including hadware, OS, software libraries etc\ninput data\nthe entire code, parameters and configurations, to be able to re-build the entire","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"data/analytical pipeline","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Experiment tracking becomes much more challenging if the model runs on a distributed environment with many computers.  To guarantee reproducibility, each ML experiment should run from a fresh environment, otherwise the data, setting or environment might change between runs. For example, some data files could be added or modified as part of the runs. However, a complete refrehs of a complex distributed data and analytical pipeline is often out of the question in pracitice, as it consists many software components, parameters and configurations. This is why most existing experiment tracking solutions only persist part of the pipeline that are most relevant for the ML models. The downside of this approach is that the stored ML runs might fail to recover the exact results.","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Leveraging its distributed graph computing engine, Julius offer an experiment tracking solution that can persist and recover an entire distributed data and analytical pipeline, as well as the full runtime data and environment. We belive Julius is the only solution on the market with such capabilities.","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Julius persists model experiment with its entire data & analytical pipeline in the following simple steps:","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"spin up a fresh virtual distributed environment, this only takes a few seconds\nrun the ML experiment and then record the entire session on the Julius server side, and","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"persist the recorded session onto long term storage. The recorded session contains the step by step instruction to recreate the entire runtime environment, including the entire data and distributed pipeline to recover the exact state of the experiment.","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"the recorded ML experiement can be easily recovered by replaying it on another","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"fresh environment.","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"In this notebook, we follow a typical work flow of a data scientist to show Julius' experiment traking capabilities. We use a ML fraud detection model from a previous tutorial as an example. Readers are referred to the \"bagging\" tutorial for more details on the model itself.","category":"page"},{"location":"pages/t007_persist.html#Model-Development-and-Experiment-1","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"Model Development & Experiment","text":"","category":"section"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Data scientists usually develop ML models by running experiments interactively in a Jupyter notebook. This section shows the definition and pipeline of a distributed ML model.","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"using GraphEngine: RuleDSL, GraphVM\nusing AtomExt\nusing DataFrames, DataScience, StatsBase, Random\n\nnewfunctions = quote\n    function downsample(ycol::Symbol, frac::Float64, df::DataFrame)\n        positive = DataFrames.filter(row -> isequal(row[ycol], true), df)\n        negative =  DataFrames.filter(row -> isequal(row[ycol], false), df)\n        dspositive = positive[sample(1:nrow(positive), round(Int, frac * nrow(positive)), replace=false), :]\n        dsnegative = negative[sample(1:nrow(negative), round(Int, frac * nrow(negative)), replace=false), :]\n        merged = vcat(dspositive, dsnegative)\n        merged[shuffle(1:nrow(merged)), :]\n    end\n\n    function valcat(xs::Vector...)\n        agg = DataFrame()\n        for (k, v) in vcat(xs...)\n            agg = vcat(agg, v)\n        end\n        agg\n    end\n\n    function dfmean(dfs::DataFrame...)\n        df = reduce(.+, dfs)\n        df ./ (length(dfs))\n    end\nend\n\nnewrules = quote\n    select(ref::RuleDSL.NodeRef, cols::Any; label=\"$(isa(cols, InvertedIndex) ? \"col != $(cols.skip)\" : \"col == $(cols)\")\") =\n        DataScience.ApplyFn[x::DataFrame->DataFrames.select(x, cols; copycols=false)](ref...)\n\n    classifiertrain(model::Val{:ExtraTreesClassifier}, options::Dict, trainxs::RuleDSL.NodeRef, trainy::RuleDSL.NodeRef; label=\"$model train\")=DataScience.PyTrain[\"sklearn.ensemble.ExtraTreesClassifier\", options](trainxs..., trainy...)\n    classify(train_data::RuleDSL.NodeRef, target::Symbol, model::Val, options::Dict, testx::RuleDSL.NodeRef; label=\"$model inference\")=begin\n        train_data_X = RuleDSL.@ref ml.select(train_data, Not(target))\n        train_data_y = RuleDSL.@ref ml.select(train_data, target)\n        trained = RuleDSL.@ref ml.classifiertrain(model, options,  train_data_X, train_data_y )\n        DataScience.PyPredict(trained..., testx...)\n    end\n\n    classifyprob(train_data::RuleDSL.NodeRef, target::Symbol, model::Val, options::Dict, test_data::RuleDSL.NodeRef; label=\"prob\")=begin\n        testx = RuleDSL.@ref ml.select(test_data, Not(target))\n        DataScience.ApplyFn[x::DataFrame->DataFrames.select(x, :proba; copycols=false)](classify(train_data, target, model, options, testx))\n    end\n\n    score(realized::RuleDSL.NodeRef, probs::RuleDSL.NodeRef)=DataScience.PyScore(realized..., probs...)\n\n    downsample(raw::RuleDSL.NodeRef, ycol::Symbol, frac::Float64)=DataScience.ApplyFn[Main.downsample, ycol, frac](raw...)\n\n    bagpred(test::RuleDSL.NodeRef, model::Val, options::Dict, train_batches::Vector{RuleDSL.NodeRef}, target::Symbol) =\n        DataScience.ApplyFn[dfmean](RuleDSL.@ref((ml.classifyprob(b, target, model, options, test) for b = train_batches))...)\n\n    batchpred(test::RuleDSL.NodeRef, model::Val, options::Dict, train_batches::Vector{RuleDSL.NodeRef}, target::Symbol) =\n        DataScience.ApplyFn[(ind, prob)->[hash(test) => hcat(ind, prob)]](select(test, target), bagpred(test, model, options, train_batches, target))\nend;","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"we use existing rules in ds namespace to read CSV files from a shared drive","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"train_data_file = joinpath(@__DIR__, \"../data/train_fraud.csv\")\ntest_data_file = joinpath(@__DIR__, \"../data/test_fraud.csv\")\ntrain_data = RuleDSL.@ref ds.csvsrc(train_data_file, true; label=\"train data\")\ntest_data  = RuleDSL.@ref ds.csvsrc(test_data_file, true; label=\"test data\")\n\ntarget = :isFraud\nmodel = Val(:ExtraTreesClassifier)\noptions = Dict(:n_estimators => 10, :min_samples_leaf => 10)\n\ntest_data_y = RuleDSL.@ref ml.select(test_data, target)\n\nsampleratio = 0.05\ntrain_ddf = DataScience.DDataFrame(train_data_file, blocksize=\"5 MB\")\ntrain_batches = train_ddf.chunks\ndown_batches = RuleDSL.@ref(ml.downsample(b, target, sampleratio) for b in train_batches)\n\ntest_ddf = DataScience.DDataFrame(test_data_file, blocksize=\"3.5 MB\")\ntest_batches = test_ddf.chunks\n\nmapper = RuleDSL.@ref ml.batchpred(model, options, down_batches, target)\nshuffler = RuleDSL.@ref mr.shuffler(first, 3)\nreducer = RuleDSL.@ref mr.reducer(vcat)","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"mr:reducer/typeof(vcat):7555","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"The model now runs with good results on a cluster for model development, as shown below:","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"using GraphEngine: RuleDSL, GraphVM\n\nconfig = RuleDSL.newconfig(RuleDSL.Config(), :project => \"MapReduce\")\nbalancer = GraphVM.GlobalUnique()\nmy_domain = GraphVM.mydomain()\nremoteport = GraphVM.drawdataport();","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"gs0 = GraphVM.RemoteGraphProxy(my_domain => 7225)\nGraphVM.rpccall(gs0, :startlocalmasterservice, remoteport, 4)\ngs = GraphVM.RemoteGraphProxy(config, my_domain => remoteport, balancer, GraphVM.GenericData())\nGraphVM.wait4clusterinit(gs)","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Dict{UInt64, Pair{Float64, GraphEngine.GraphVM.WorkerStatus}} with 4 entries:\n  0x0f2847bdc16ab03e => 1.64847e9=>Ready\n  0xcfc6b616c2a782f5 => 1.64847e9=>Ready\n  0x312a9f14056ee53a => 1.64847e9=>Ready\n  0x0821bef1b35d62f2 => 1.64847e9=>Ready","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"GraphVM.@remote_eval gs begin\n    using GraphEngine: RuleDSL, GraphVM\n    using AtomExt, GraphIO\n    using DataFrames, DataScience, StatsBase, Random\nend\n\nGraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\n\nGraphVM.@remote_eval gs $newfunctions\nGraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\n\nGraphVM.@addrules gs ml $newrules\n\nmrpred = RuleDSL.@ref mr.mapreduce(test_batches, mapper, shuffler, reducer, Main.valcat)\nmrscore = RuleDSL.@ref ml.score(RuleDSL.@ref(ml.select(mrpred, :isFraud)), RuleDSL.@ref(ml.select(mrpred, :proba)))\n\nalljobs, ds = RuleDSL.jobdeps(config, [mrscore], Set([:classifiertrain, :splitbykey, :reducer]));\n\nGraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\nGraphVM.initgraph!(gs)\nGraphVM.dispatchjobs!(gs, alljobs, 2);","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"using GraphIO\n\nGraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\nsvg = GraphIO.postremotegraph(gs, remoteport);\nGraphIO.postsvg(svg, \"ml_persist_1.svg\")\nGraphVM.rpccall(gs, :endcluster);","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"<p align = \"center\">\n<img src=\"../assets/ml_persist_1.svg\" alt=\"\" title=\"ml persist\"/>\n</p>\n<p align = \"center\">\nFigure 1 - Original Distributed ML Pipeline.\n</p>","category":"page"},{"location":"pages/t007_persist.html#Record-a-Model-Experiment-1","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"Record a Model Experiment","text":"","category":"section"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Now the data scientists is happy with the results, and want to persist the experiment so that it can be reproduced later. The data scientits have made a number of choices in this ML model run, including data sources, configurations, choice of model, and hyper parameters etc. Some experiment tracking tools are based on saving notebooks, however that is not an adequate and reliable solution, as some data or variables were not captured by the code in the notebook. For example, the developer might have read data from a local file, or rely upon the state or data of a remote server. Under those circumstances, just saving the notebook is not adequate to recover the ML Run.","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Julius took a different approach, instead of saving the notebook on the client side, we persist the entire state on the server side. This server side persisting process is easy and seamless. We first start a fresh virtual cluster at a new port, using the same docker image used by the development environment.","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"remoteport2 = GraphVM.drawdataport()\n\nGraphVM.rpccall(gs0, :startlocalmasterservice, remoteport2, 4)\ngs2 = GraphVM.RemoteGraphProxy(config, my_domain => remoteport2, balancer, GraphVM.GenericData())\nGraphVM.wait4clusterinit(gs2)","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Dict{UInt64, Pair{Float64, GraphEngine.GraphVM.WorkerStatus}} with 4 entries:\n  0xfa09eaae972e0ff8 => 1.64847e9=>Ready\n  0xe7973ecc7248f7ac => 1.64847e9=>Ready\n  0x6be430dbfae2a741 => 1.64847e9=>Ready\n  0x42da11d8a8ce8d6b => 1.64847e9=>Ready","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"The following line enables recording on this new cluster, all the subsequent actions will be recorded on the serverside.","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"GraphVM.rpccall(gs2, :clearrecording!)\nGraphVM.rpccall(gs2, :setrecording!, true);","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"We now re-run the same ML model on this fresh server, existing local variables can be re-used without change to recreate the same data/analytica pipeline on the server. Only a few lines of codes are needed for server side recording, as shown below:","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"GraphVM.@remote_eval gs2 begin\n    using GraphEngine: RuleDSL, GraphVM\n    using AtomExt, GraphIO\n    using DataFrames, DataScience, StatsBase, Random\nend\n\nGraphVM.waitcheckstatus(gs2, RuleDSL.getconfig(config, :project));\n\nGraphVM.@remote_eval gs2 $newfunctions\nGraphVM.waitcheckstatus(gs2, RuleDSL.getconfig(config, :project));\n\nGraphVM.@addrules gs2 ml $newrules\n\nGraphVM.waitcheckstatus(gs2, RuleDSL.getconfig(config, :project));\nGraphVM.initgraph!(gs2)\nGraphVM.dispatchjobs!(gs2, alljobs, 2);","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Now we can retrieve the recordeing saved on the server side for this ML run, which is an extremely compact representation of the entire run, including all the data and analytical logic to recreate the distributed pipeline. This recording can be persisted on long term storage like AWS S3. The version of docker container being used can also be persisted along with the recording. The docker container captures the exact and complete run time environment.","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"GraphVM.waitcheckstatus(gs2, RuleDSL.getconfig(config, :project));\nrecords = GraphVM.rpccall(gs2, :getrecording);\n\n# terminate the recording cluster\nGraphVM.rpccall(gs2, :endcluster);","category":"page"},{"location":"pages/t007_persist.html#Reproduce-the-Model-Experiment-1","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"Reproduce the Model Experiment","text":"","category":"section"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"From the recording, the entire distributed pipeline can be easily recreated at a later time. To do so, we first spin up a fresh cluster using the same version of docker container, we then replay the recording on this new server. It only take a single line of code to recover the stored pipeline:","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"remoteport3 = GraphVM.drawdataport()\nGraphVM.rpccall(gs0, :startlocalmasterservice, remoteport3, 4)\ngs3 = GraphVM.RemoteGraphProxy(config, my_domain => remoteport3, balancer, GraphVM.GenericData())\nGraphVM.wait4clusterinit(gs3)","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Dict{UInt64, Pair{Float64, GraphEngine.GraphVM.WorkerStatus}} with 4 entries:\n  0x8ecd021fc0b3ca34 => 1.64847e9=>Ready\n  0xc2c51f6128a445ee => 1.64847e9=>Ready\n  0x1e7096185ffb0a6f => 1.64847e9=>Ready\n  0xa5a331e6ee6039aa => 1.64847e9=>Ready","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"GraphVM.rpccall(gs3, :replayrecording, records)","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"11","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"Now the results are ready to be inspected:","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"GraphVM.waitcheckstatus(gs3, RuleDSL.getconfig(config, :project));\nsvg = GraphIO.postremotegraph(gs3, remoteport3);\nGraphVM.rpccall(gs3, :endcluster)\nGraphIO.postsvg(svg, \"ml_persist_2.svg\")","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"<p align = \"center\">\n<img src=\"../assets/ml_persist_2.svg\" alt=\"\" title=\"ml persist\"/>\n</p>\n<p align = \"center\">\nFigure 2 - Recreate a Distributed ML Pipeline.\n</p>","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"","category":"page"},{"location":"pages/t007_persist.html#","page":"7 MLOps: ML Experiment Tracking and Persiting","title":"7 MLOps: ML Experiment Tracking and Persiting","text":"This page was generated using Literate.jl.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"EditURL = \"https://github.com/JuliusTechCo/Tutorials/blob/main/src/aad.jl\"","category":"page"},{"location":"pages/t005_aad.html#Tutorial-5:-Adjoint-Algorithmic-Differentiation-(AAD)-1","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"Tutorial 5: Adjoint Algorithmic Differentiation (AAD)","text":"","category":"section"},{"location":"pages/t005_aad.html#How-to-use-this-tutorial-1","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"How to use this tutorial","text":"","category":"section"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"Select \"run all cells\" on this notebook from the Run menu in Jupyter notebook or Jupyter","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"lab. This step will produce intermediate data output and charts.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"Some cells print out a url, which you can click on and bring up an interactive web UI to visualize the graph data.\nIn the unlikely event that the notebook becomes irresponsive, you can try \"Restart Kernel\" from the Kernel menu, then run individual cells one by one using Shift+Enter.\nSome tutorials use local clusters consisting of multiple processes to mimic the effects","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"of graph distribution over a remote clusters. By default, these local clusters   automatically stop after idling for 15min to conserve CPU and memory resources. You will   need to rerun the entire notebook if your local cluster stopped due to inactivity.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"Additional resources (video demos & blogs) are available at http://juliustech.co\nTo report any issues, get help or request features, please raise an issue at:","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"https://github.com/JuliusTechCo/JuliusGraph/issues","category":"page"},{"location":"pages/t005_aad.html#Introduction-1","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"Introduction","text":"","category":"section"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"The main topic of this tutorial is adjoint algorithmic differentiation (AAD), it is a powerful technique to compute 1st order derivative quickly and exactly using chain rules. AAD offers a significant performance gain, sometime thousands of times, comparing to the traditional finite difference method (i.e. bump and recalculation) for computing first order derivatives. AAD is particularly relevant for quantitative finance applications, as the 1st order derivatives are widely used for hedging and risk management.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"The traditional approach to implementing AAD requires a tape to record the forward calculations, then the tape is run in reverse for the backward AD. This approach is memory intensive and does not scale well to large applications or systems. A large system consists of many software components running concurently on multiple computers, it is not feasible to record a consistent tape across multiple computers.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"Julius offers an easy and efficient way to implement AAD for large distributed systems. Julius use the computational DAG to cache the value and keep track of the dependency of the primal calculations, then the entire DAG is run in reverse for the AAD calculation. Both primal and backward AD run can be fully distributed by Julius Graph Engine for high performance and scalability, all of this is achieved without using the memory intensive tape recordings.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"AAD is a rich and complex topic, this tutorial is only a very high level introduction to Julius AAD capabilities. Please reach out to us at (info@juliustech.co) for a more in depth demo if you are interested in learning the full capabilities of Julius AAD.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"Similar to the quickstart, we start with a simple Fibonacci sequence as the example.","category":"page"},{"location":"pages/t005_aad.html#Quantom-1","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"Quantom","text":"","category":"section"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"We have introduced the type Datom in the quickstart tutorial. Quantom is another important subtype of Atom, it stands for quantitative atom. Quantum is the main work horse for numerical computations with AAD. Unlike Dataom that can take any data types as inputs and output, the inputs and outputs of Quantoms must be vectors or matrices of Float64 (double precision floating point numbers). Non-numerical datatypes would not make sense for AAD, which is the primary reason to use a Quantom type.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"In this tutorial, we will not go into the details of the Quantom interface or how to implement new Quantom types. Instead, we will use existing Quantom implementations provied in Julius distribution to illustrate the AAD capabilities.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"Julius provides a rich set of Quantom  libraries for the most common numerical algorithms, including root searching, interpolation, and common stochastic processes etc. All the Julius Quantom implementations come with full AAD support and have been extensively tested.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"# disable the display of information logging\nusing Base.CoreLogging\ndisable_logging(CoreLogging.Info)\n\nusing GraphEngine: RuleDSL, GraphVM\nusing GraphEngine.RuleDSL\nusing GraphIO\n\n# start data server for web UI\ngss = Dict{String,RuleDSL.AbstractGraphState}()\nport = GraphVM.drawdataport()\n@async GraphVM.startresponder(gss, port);","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"The following few rules defines the Fibonacci sequence using the rule syntax. These rules shows the type and value based polymorphism. Multiple rules of different types can be defined for the same rule name, and at run time, the best matching rule is invoked.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"These definitions are very similar to those we have seen in the quick start tutorials. The only difference here is that the RuleDSL.WegithedSum quantum is used.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"@addrules series begin\n    fib(x::Float64) = Alias(fib(Int(floor(x))))\n    fib(n::Int) = RuleDSL.Alias(fib(n, Val(n <= 1)))\n    fib(n::Int, isend::Val{false}) = begin\n        RuleDSL.WeightedSum[[1.0; 1.0]](\n            fib(n - 1, Val(n <= 2)), fib(n - 2, Val(n <= 3))\n        )\n    end\n    fib(n::Int, isend::Val{true}) = RuleDSL.Constant[[fill(Float64(n), 1)]]()\nend\n\nconfig = RuleDSL.Config();","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"The following two functions override the nodelabel function for the customized display of graph nodes. Users can freely override them to customize the text label display of the computation graph.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"import GraphEngine.RuleDSL: nodelabel\n\n# override displays\nfunction nodelabel(::RuleDSL.AbstractGraphState, r::RuleDSL.RuleNode)\n    hdr = \"$(r.ns).$(r.op[1])\"\n    typestr(x) = x.args[2]\n    typ = join(typestr.(r.op[2]), \", \")\n\n    return hdr * \"($typ)\"\nend\n\nfunction nodelabel(::RuleDSL.AbstractGraphState, ref::RuleDSL.NodeRef)\n    hdr = \"$(ref.ns).$(ref.name)\"\n    ps = join(simplerepr.(ref.params), \", \")\n\n    return \"$hdr($ps)\"\nend","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"nodelabel (generic function with 4 methods)","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"RuleDSL.NumericalData is a sub type of GraphData type that provides run time support to the adjoint algorithm differentiation (AAD). The second parameter to NumericalData specifies the default vec x in the AAD output of fracpartialvec ypartial vec x. Here vec y is is specified by the unique has id of hash(fib5):","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"fib5 = @ref series.fib(5.2)\nfib0 = @ref series.fib(0, Val(true))\nfib1 = @ref series.fib(1, Val(true))\n\ncs = RuleDSL.NumericalData(config, Set([fib0, fib1]));\ngs = RuleDSL.createlocalgraph(config, cs);\n\n# primal calculation\nRuleDSL.calcfwd!(gs, Set([fib5]));\n# backward AD calculation\nRuleDSL.calcback!(gs, Set([hash(fib5)]));","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"We can retrieve the results of vec y and the 1st order derivatives from AAD.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"y = RuleDSL.getys(gs, hash(fib5))\ndydx0 = RuleDSL.getyds(gs, hash(fib0), hash(fib5))\ndydx1 = RuleDSL.getyds(gs, hash(fib1), hash(fib5))\n\nprintln(\"fib5 =\", y[1])\nprintln(\"dfib5_dfib0 =\", dydx0[1])\nprintln(\"dfib5_dfib1 =\", dydx1[1])","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"fib5 =[5.0]\ndfib5_dfib0 =[3.0]\ndfib5_dfib1 =[5.0]\n","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"The corresponding computation graph is shown below, and you can click the link below to see it in an interactive web UI.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"svg = GraphIO.postlocalgraph(gss, deepcopy(gs), port; key=\"fib5\");\nGraphIO.postsvg(svg, \"aad_1.svg\")","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7011_fib5\n","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"<p align = \"center\">\n<img src=\"../assets/aad_1.svg\" alt=\"\" title=\"Fib 5\"/>\n</p>\n<p align = \"center\">\nFigure 1 - Fibonacci with AAD\n</p>","category":"page"},{"location":"pages/t005_aad.html#Caching-1","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"Caching","text":"","category":"section"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"One of the main challenges in AAD implementation is its memory consumption. The reverse AD calculation in AAD requires the primal calculation results to be cached. In the traditional tape based approach, the memory required for caching the primal calculation results can grow beyond the size of available physical memory, causing AAD execution to fail for large problems. Advanced AAD techniques, such as checkpointing, are needed to limit the memory consumption for large problems, but these advanced techniques requires additional coding efforts thus further complicates the AAD implementation.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"Julius Graph Engine automatically caches all the intermediate results in the computational graph. For very large problems, Julius can automatically distribute the computation graph across multiple computers, and leverage all of their physical memories. Therefore, Julius can access practically an unlimited amount of memory when running in distributed mode, therefore it is no longer subjected to the the physical memory limit of any single computer.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"In addition, Julius only caches the primal results at the node level, as opposed to the individual arithmetic operator level as in the traditional AAD taping implementation. As a result, Julius caching is much more memory efficient for complex problems. Julius effectively implemented automatic checkpointing for every individual Quantum.  An Quantom object in each individual node can perform a heavy and complex calculation with AAD, and the primal results within individual quantom dp not need to be cached.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"With Julius automatic caching of all intermediate computation results in the graph, any incremental computation will automatically re-use existing values in the cache, instead of being recomputing them from scatch. The following cells shows that when computing fib(10) all the nodes up to fib(5) from previous step is re-used.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"fib10 = @ref series.fib(10)\n# primal calculation\nGraphVM.calcfwd!(gs, Set([fib10]));\n# backward AD calculation\nRuleDSL.calcback!(gs, Set([hash(fib10)]));\n\ny = RuleDSL.getys(gs, hash(fib10))\ndf10df0 = RuleDSL.getyds(gs, hash(fib0), hash(fib10))\ndf10df1 = RuleDSL.getyds(gs, hash(fib1), hash(fib10))\n\nprintln(\"fib10 =\", y[1])\nprintln(\"dfib10_dfib0 =\", df10df0[1])\nprintln(\"dfib10_dfib1 =\", df10df1[1])","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"fib10 =[55.0]\ndfib10_dfib0 =[34.0]\ndfib10_dfib1 =[55.0]\n","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"The corresponding computation graph is shown below:","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"svg = GraphIO.postlocalgraph(gss, deepcopy(gs), port; key=\"fib10\");\nGraphIO.postsvg(svg, \"aad_2.svg\")","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7011_fib10\n","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"<p align = \"center\">\n<img src=\"../assets/aad_2.svg\" alt=\"\" title=\"Fib 10\"/>\n</p>\n<p align = \"center\">\nFigure 2 - Caching\n</p>","category":"page"},{"location":"pages/t005_aad.html#Namespace-Clone-and-Override-1","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"Namespace Clone and Override","text":"","category":"section"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"Rules are organized within individual namespaces in Julius RuleDSL, for example the series is a namespace in the rules declaration above. One important feature of Julius is that the rules can be cloned to different namespace and overridden. This facilitates comparisons between the old and new versions of rules, making change management and impact analysis much easier.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"For example, if we update the above Fibonacci sequence definition to take random vectors as fib(0) and fib(1) instead of 0 and 1, we can create a clone of the namespace \"series\" and override the corresponding rules.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"@clone series => vecs\n\n@addrules vecs begin\n    fib(n::Int, isend::Val{true}) = RuleDSL.Constant[[randn(10)]]()\nend","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"vfib10 = @ref vecs.fib(10)\n# primal calculation\n@time GraphVM.calcfwd!(gs, Set([vfib10]));\n\ny = RuleDSL.getys(gs, hash(vfib10))\nprintln(\"vfib10 =\", y[1])","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"  0.360310 seconds (626.52 k allocations: 33.190 MiB, 99.65% compilation time)\nvfib10 =[8.914324687980567, -65.52299973588603, -18.367082824015686, -22.743879128382186, -71.39347410591957, -132.12187823944362, 16.932726176947277, -29.683814816612497, 34.41225334844379, -19.147869292190606]\n","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"We can see an interactive side by side comparison of the two versions of the calculation, before and after changing the initial values to random vectors, by clicking the URL below to bring up Julius' interactive web UI.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"svg = GraphIO.postlocalgraph(gss, deepcopy(gs), port; key=\"vecs\");\nGraphIO.postsvg(svg, \"aad_3.svg\")","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7011_vecs\n","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"<p align = \"center\">\n<img src=\"../assets/aad_3.svg\" alt=\"\" title=\"Comparisons\"/>\n</p>\n<p align = \"center\">\nFigure 3 - Override & Compare\n</p>","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"Julius AAD implementation supoorts multiple sensitivity views from the same primal calculation. A sensitivity view is a Jacobian matrix fracpartial vec ypartial vec x where vec y and vec x can be any connected node in the graph.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"The following few cells shows the computation of different sensitivity views witout repeating the primal calculation. Please note that the AAD output of the vectorized version of Fibonacci sequence is a full Jacobian matrix.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"v10 = @ref vecs.fib(10)\nv0 = @ref vecs.fib(0, Val(true))\nv1 = @ref vecs.fib(1, Val(true))\n\n# backward AD\nRuleDSL.calcback!(gs, Set(hash.([v10])), Set([v0; v1]));\n\ndv10_dv0 = RuleDSL.getyds(gs, hash(v0), hash(v10))\ndv10_dv1 = RuleDSL.getyds(gs, hash(v1), hash(v10))\n\nprintln(\"fib_v10 = \", RuleDSL.getys(gs, hash(v10))[1])\nprintln(\"dv10_dv0 = \", dv10_dv0[1])\nprintln(\"dv10_dv1 = \", dv10_dv1[1])","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"fib_v10 = [8.914324687980567, -65.52299973588603, -18.367082824015686, -22.743879128382186, -71.39347410591957, -132.12187823944362, 16.932726176947277, -29.683814816612497, 34.41225334844379, -19.147869292190606]\ndv10_dv0 = [34.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 34.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 34.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 34.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 34.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 34.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 34.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 34.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 34.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 34.0]\ndv10_dv1 = [55.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 55.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 55.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 55.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 55.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 55.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 55.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 55.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 55.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 55.0]\n","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"v8 = @ref vecs.fib(8, Val(false))\nv2 = @ref vecs.fib(2, Val(false))\nv3 = @ref vecs.fib(3, Val(false))\n\n# backward AD with a different sensitivity view\nRuleDSL.calcback!(gs, Set(hash.([v8])), Set([v2; v3]));\n\ndv8_dv2 = RuleDSL.getyds(gs, hash(v2), hash(v8))\ndv8_dv3 = RuleDSL.getyds(gs, hash(v3), hash(v8))\n\nprintln(\"fib_v8 =\", RuleDSL.getys(gs, hash(v8))[1])\nprintln(\"dv8_dv0 =\", dv8_dv2[1])\nprintln(\"dv8_dv1 =\", dv8_dv3[1])","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"fib_v8 =[3.428159597899083, -25.034657507715472, -7.0178285259235675, -8.69560813158948, -27.272525338265226, -50.48574854980008, 6.4814691040201415, -11.33016360060797, 13.139076286292262, -7.311178893241819]\ndv8_dv0 =[5.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 5.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 5.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 5.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 5.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 5.0]\ndv8_dv1 =[8.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 8.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 8.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 8.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 8.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 8.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 8.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 8.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 8.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 8.0]\n","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"A warning is generated if the vec x specification does not capture the sensitivities to all the factors that affects vec y. In the following example, knowing term fib(2) is not adequate to uniquely determine fib(8), therefore a warning is produced.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"RuleDSL.calcback!(gs, Set(hash.([v8])), Set([v2]))","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"0","category":"page"},{"location":"pages/t005_aad.html#Distributed-AAD-1","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"Distributed AAD","text":"","category":"section"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"With Quantum and NumericalData, Julius allows AAD to be easily implemented for large and complex problems. In this section, we show a real world AAD use case of pricing a portfolio of derivatives with distributed graph.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"We first start a local cluster consisting of 3 worker processes to mimic a physical cluster.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"using JuliusApps: QFin\n\n# date grid for pricing the portfolio\ndgrid = QFin.dategrid(80; nmonth=3)\nconfig = RuleDSL.newconfig(QFin.QFinConfig(dgrid), :project=>\"PV/AAD\");\n\n# the balancer defines different strategies to distribute the graph computation\n# CopyRVs is the most efficient strategy for AAD\nbalancer = GraphVM.CopyRVs();\nmy_domain = GraphVM.mydomain()\n\n# draw a port number to start the local cluster esrvice\nclusterport = GraphVM.drawdataport();","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"# start a local master service at the given port\n\ngs0 = GraphVM.RemoteGraphProxy(my_domain => 7225)\nGraphVM.rpccall(gs0, :startlocalmasterservice, clusterport, 3)","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"0","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"We then create a portfolio of 1000 trades, with 10 desks, each consisting of 10 trading book with 10 trades of Swap, Swaptions, CDS or cross currency swaps etc.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"ndesk, nbook, ntrade = 10, 10, 10\nnd = RuleDSL.getconfig(config, :nd)\nasofs = collect(0:4:nd-1)\nnodes, apv, aads = QFin.createbook(config, asofs, ndesk, nbook, ntrade);\nbook = apv.params[1];\n\n# risk view, defining the sensitivities to compute, ie, the x in dy/dx\nrvs = Set([RuleDSL.@ref fac.riskview(book)]);","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"cs = RuleDSL.NumericalData(config, rvs)\ngs = GraphVM.RemoteGraphProxy(config, my_domain => clusterport, balancer, cs, true)\nGraphVM.wait4clusterinit(gs)\nGraphVM.rpccall(gs.rpc, :workerstatus)","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"Dict{UInt64, Pair{Float64, GraphEngine.GraphVM.WorkerStatus}} with 3 entries:\n  0xed937c2d7e40d816 => 1.64847e9=>Ready\n  0xad4153de7d9d21b5 => 1.64847e9=>Ready\n  0x6b22fe4479602c22 => 1.64847e9=>Ready","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"GraphVM.@remote_eval gs begin\n    using JuliusApps, GraphIO\n    using GraphEngine: RuleDSL, GraphVM\nend\n\nGraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"jobs = Set{Vector{RuleDSL.NodeRef}}([k.first] for k in nodes);\nGraphVM.createremotegraph(gs, jobs, Set{Symbol}());","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"cid = UInt(0)\neid = hash(apv)\nGraphVM.calcfwd!(gs, cid, Set(eid))\nGraphVM.calcback!(gs, eid, asofs)\n\nGraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\n\n# show the stats of resulting graph\nGraphVM.rpccall(gs, GraphIO.graphstats, UInt(1), UInt(1))","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"Dict{Symbol, Any} with 6 entries:\n  :errcnt => 0\n  :errids => String[]\n  :aadeids => Dict(\"13515166291778932265\"=>\"inst:apv/Bottomup:8065\")\n  :eidcnt => 1\n  :cnt => 28448\n  :nworkers => 3","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"The resulting graph has about 29,000 nodes and cannot be displayed on a single chart, we only show the top portion instead. The full AAD results can be visualized by clicking the URL below to enter the interactive web UI, then select the AAD link on the right panel.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"svg = GraphIO.postremotegraph(gs, port, true; maxnode=UInt(120));\nGraphIO.postsvg(svg, \"aad_4.svg\")","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"<p align = \"center\">\n<img src=\"../assets/aad_4.svg\" alt=\"\" title=\"Pricing\"/>\n</p>\n<p align = \"center\">\nFigure 4 - Pricing a Portfolio\n</p>","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"GraphVM.rpccall(gs, :endcluster)","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"0","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"The following call shows the computation time for each stage of pricing the 1,000 derivative portfolio. The computational time is reported in seconds for graph creation, primal calculation, AAD calculation and final clean up.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"In this pricing example, there are about 800 different risk factors, and the vec y is an pricing vector for 20 annual time steps under forcasted market evolution for the next 20 years. Each of the risk factor has 80 quarterly sample interval, therefore the total number of individual sensitivities are roughly 800 x 20 x 80 = 1.28MM, all of which are computed via AAD in about 15 seconds (depending on the hardware), which is extremely fast.","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"GraphVM.rpccall(gs, :displaychecks)","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"4-element Vector{Pair}:\n   (:addjobs, 1089) => 22.91556692123413\n (:channelrun!, 10) => 16.82551407814026\n  (:channelrun!, 6) => 14.563302993774414\n  (:channelrun!, 6) => 3.2901763916015625e-5","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"","category":"page"},{"location":"pages/t005_aad.html#","page":"5 Adjoint Algorithmic Differentiation (AAD)","title":"5 Adjoint Algorithmic Differentiation (AAD)","text":"This page was generated using Literate.jl.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"EditURL = \"https://github.com/JuliusTechCo/Tutorials/blob/main/src/titanic.jl\"","category":"page"},{"location":"pages/t002_titanic.html#Tutorial-2:-Machine-Learning-1","page":"2 Machine Learning","title":"Tutorial 2: Machine Learning","text":"","category":"section"},{"location":"pages/t002_titanic.html#How-to-use-this-tutorial-1","page":"2 Machine Learning","title":"How to use this tutorial","text":"","category":"section"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"Select \"run all cells\" on this notebook from the Run menu in Jupyter notebook or Jupyter","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"lab. This step will produce intermediate data output and charts.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"Some cells print out a url, which you can click on and bring up an interactive web UI to visualize the graph data.\nIn the unlikely event that the notebook becomes irresponsive, you can try \"Restart Kernel\" from the Kernel menu, then run individual cells one by one using Shift+Enter.\nSome tutorials use local clusters consisting of multiple processes to mimic the effects","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"of graph distribution over a remote clusters. By default, these local clusters   automatically stop after idling for 15min to conserve CPU and memory resources. You will   need to rerun the entire notebook if your local cluster stopped due to inactivity.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"Additional resources (video demos & blogs) are available at http://juliustech.co\nTo report any issues, get help or request features, please raise an issue at:","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"https://github.com/JuliusTechCo/JuliusGraph/issues","category":"page"},{"location":"pages/t002_titanic.html#Introduction-1","page":"2 Machine Learning","title":"Introduction","text":"","category":"section"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"This Tutorial shows how to use Julius Graph Engine to set up the training and validation of a machine learning model. We implement the classic example of using several different ML models to predict (or postdict) the survival of Titanic passengers by using the well-known Titanic dataset.","category":"page"},{"location":"pages/t002_titanic.html#Data-Exploration,-Visualization-and-Cleaning-1","page":"2 Machine Learning","title":"Data Exploration, Visualization and Cleaning","text":"","category":"section"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"Data scientits can use Julius Graph Engine to quickly explore and visualize data from different sources. Julius provides connections to many data sources and formats, such as CSV, web url, relational Databases, various NoSQL Databases, etc.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"DataScience package is part of Julius distribution, it provides a rich set of rules and atoms for data sourcing, cleansing, and machine learning. In this notebook, we will show how the rules and atoms defined in DataScience to quickly build the ML pipeline for the Titanic data set.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"The relevant rules from DataScience package for this tutorial are listed below for your reference.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"@addrules ds begin\n    dfsrc(df::DataFrame) = DFSrc[df]()\n    colsel(r::NodeRef, idx::Vector{Int}) = Index[idx](r...)\n    csvsrc(filen::String, hashdr::Bool) = Alias(dfsrc(CSV.read(filen, DataFrame, header = hashdr)))\n    colsplit(ref::NodeRef, idx::Int, yhdr::Set{Symbol}, ex::Set{Symbol}) = ColSplit[idx, yhdr, ex](ref...)\n    trainvalsplit(ref::NodeRef, pctval::Float64) = RandRowSplit[pctval](ref...)\n    fillmissing(ref::NodeRef, methods::Dict{Symbol,Symbol}) = FillMissing[methods](ref...)\n    numerize(ref::NodeRef) = Numerize(ref...)\nend","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"We first include the dependent Julia and Julius packages and set up some basic configurations.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"using GraphEngine: RuleDSL, GraphVM\nusing Base.CoreLogging\nusing DataScience, AtomExt, GraphIO\nusing DataFrames\n\n# turn off informational logging output\ndisable_logging(CoreLogging.Info)\n\n# extend the number of displayed columns in Jupyter notebooks\nENV[\"COLUMNS\"] = 100","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"100","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"# the project is used for web UI display\nconfig = RuleDSL.Config(:project => \"Titanic\");\n\n# start data server for web UI\ngss = Dict{String,RuleDSL.AbstractGraphState}()\nport = GraphVM.drawdataport()\n@async GraphVM.startresponder(gss, port)","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"Task (runnable) @0x00007f8e63e70d30","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"The dataset can be loaded by either directly using a url or by providing a CSV source file via rules defined in the ds namespace, which are defined in the DataScience package. The line commented out is a rule to load the same data from a URL.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"rawsrc = RuleDSL.@ref ds.csvsrc(\"../data/titanic.csv\", true; label=\"raw csv\")\n# rawsrc = RuleDSL.@ref ds.urlsrc(\"https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv\", true; label=\"raw url\")","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"ds:csvsrc/raw csv","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"The very first thing a data scientits may want to do is to get a summary of the dataset. The follow cell shows how it can be done using the ds.datasummary rule in the DataScience package.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"rawsummary = RuleDSL.@ref ds.datasummary(rawsrc; label=\"data summary\")\n\ngs = GraphVM.createlocalgraph(config, RuleDSL.GenericData());\nGraphVM.calcfwd!(gs, Set([rawsummary]))","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"0","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"The data summary results can be retrieved using the GraphVM.getdata method. The data cached in individual graph nodes are all vectors, the last argument 1 just refers to the first and only element of the data summary. Some nodes will have multiple entries in the data vector.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"RuleDSL.getdata(gs, rawsummary, 1)","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"<div class=\"data-frame\"><p>12 rows × 7 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th title=\"Symbol\">Symbol</th><th title=\"Union{Nothing, Float64}\">Union…</th><th title=\"Any\">Any</th><th title=\"Union{Nothing, Float64}\">Union…</th><th title=\"Any\">Any</th><th title=\"Int64\">Int64</th><th title=\"Type\">Type</th></tr></thead><tbody><tr><th>1</th><td>PassengerId</td><td>446.0</td><td>1</td><td>446.0</td><td>891</td><td>0</td><td>Int64</td></tr><tr><th>2</th><td>Survived</td><td>0.383838</td><td>0</td><td>0.0</td><td>1</td><td>0</td><td>Int64</td></tr><tr><th>3</th><td>Pclass</td><td>2.30864</td><td>1</td><td>3.0</td><td>3</td><td>0</td><td>Int64</td></tr><tr><th>4</th><td>Name</td><td></td><td>Abbing, Mr. Anthony</td><td></td><td>van Melkebeke, Mr. Philemon</td><td>0</td><td>String</td></tr><tr><th>5</th><td>Sex</td><td></td><td>female</td><td></td><td>male</td><td>0</td><td>String7</td></tr><tr><th>6</th><td>Age</td><td>29.6991</td><td>0.42</td><td>28.0</td><td>80.0</td><td>177</td><td>Union{Missing, Float64}</td></tr><tr><th>7</th><td>SibSp</td><td>0.523008</td><td>0</td><td>0.0</td><td>8</td><td>0</td><td>Int64</td></tr><tr><th>8</th><td>Parch</td><td>0.381594</td><td>0</td><td>0.0</td><td>6</td><td>0</td><td>Int64</td></tr><tr><th>9</th><td>Ticket</td><td></td><td>110152</td><td></td><td>WE/P 5735</td><td>0</td><td>String31</td></tr><tr><th>10</th><td>Fare</td><td>32.2042</td><td>0.0</td><td>14.4542</td><td>512.329</td><td>0</td><td>Float64</td></tr><tr><th>11</th><td>Cabin</td><td></td><td>A10</td><td></td><td>T</td><td>687</td><td>Union{Missing, String15}</td></tr><tr><th>12</th><td>Embarked</td><td></td><td>C</td><td></td><td>S</td><td>2</td><td>Union{Missing, String1}</td></tr></tbody></table></div>","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"We observe that some columns in the raw data set have missing values. Data imputation and cleansing is a common task for building ML models. Julius' DataScience library has provided data imputation methods, which can be easily used by calling the fillmissing rule with the desired imputation method for a each field, i.e., we use median value of Age of all passenger for any missing Age, and use the mode value (which is true) for any missing Embarked.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"cleansrc = RuleDSL.@ref ds.fillmissing(\n    rawsrc, Dict(:Age => :median, :Embarked => :mode); label=\"impute missing\"\n)","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"ds:fillmissing/impute missing","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"After data imputation, we recompute the data summary, showing all the the missing values for both Age and Embarked features have been populated:","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"cleansummary = RuleDSL.@ref ds.datasummary(cleansrc; label=\"clean summary\")\nGraphVM.calcfwd!(gs, Set([cleansummary]))\nRuleDSL.getdata(gs, cleansummary, 1)","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"<div class=\"data-frame\"><p>12 rows × 7 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th title=\"Symbol\">Symbol</th><th title=\"Union{Nothing, Float64}\">Union…</th><th title=\"Any\">Any</th><th title=\"Union{Nothing, Float64}\">Union…</th><th title=\"Any\">Any</th><th title=\"Int64\">Int64</th><th title=\"Type\">Type</th></tr></thead><tbody><tr><th>1</th><td>PassengerId</td><td>446.0</td><td>1</td><td>446.0</td><td>891</td><td>0</td><td>Int64</td></tr><tr><th>2</th><td>Survived</td><td>0.383838</td><td>0</td><td>0.0</td><td>1</td><td>0</td><td>Int64</td></tr><tr><th>3</th><td>Pclass</td><td>2.30864</td><td>1</td><td>3.0</td><td>3</td><td>0</td><td>Int64</td></tr><tr><th>4</th><td>Name</td><td></td><td>Abbing, Mr. Anthony</td><td></td><td>van Melkebeke, Mr. Philemon</td><td>0</td><td>String</td></tr><tr><th>5</th><td>Sex</td><td></td><td>female</td><td></td><td>male</td><td>0</td><td>String7</td></tr><tr><th>6</th><td>Age</td><td>29.3616</td><td>0.42</td><td>28.0</td><td>80.0</td><td>0</td><td>Float64</td></tr><tr><th>7</th><td>SibSp</td><td>0.523008</td><td>0</td><td>0.0</td><td>8</td><td>0</td><td>Int64</td></tr><tr><th>8</th><td>Parch</td><td>0.381594</td><td>0</td><td>0.0</td><td>6</td><td>0</td><td>Int64</td></tr><tr><th>9</th><td>Ticket</td><td></td><td>110152</td><td></td><td>WE/P 5735</td><td>0</td><td>String31</td></tr><tr><th>10</th><td>Fare</td><td>32.2042</td><td>0.0</td><td>14.4542</td><td>512.329</td><td>0</td><td>Float64</td></tr><tr><th>11</th><td>Cabin</td><td></td><td>A10</td><td></td><td>T</td><td>687</td><td>Union{Missing, String15}</td></tr><tr><th>12</th><td>Embarked</td><td></td><td>C</td><td></td><td>S</td><td>0</td><td>String1</td></tr></tbody></table></div>","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"The entire data sourcing and cleansing can be visualized interactively in Julius convenient web UI by clicking the link below.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"svg = GraphIO.postlocalgraph(gss, gs, port; key=\"data\");\nGraphIO.postsvg(svg, \"titanic_1.svg\")","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7577_data\n","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"<p align = \"center\">\n<img src=\"../assets/titanic_1.svg\" alt=\"\" title=\"Data Cleansing\"/>\n</p>\n<p align = \"center\">\nFigure 1 - Data Cleansing\n</p>","category":"page"},{"location":"pages/t002_titanic.html#.-Experiment-with-multiple-Machine-Learning-models-1","page":"2 Machine Learning","title":"2. Experiment with multiple Machine Learning models","text":"","category":"section"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"Julius Graph Engine can easily interop with existing Python, Java, C++ and R libraries via the generic Atom interface","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"For example, the following rules show how easy it is to access Python ML libraries, such as sklearn, by using the PyTrain atom provided in the DataScience package. The first parameter of the PyTrain atom is the full name of the Python ML class to use. The second parameter is a Dictionary with the corresponding parameters/options/arguments of that ML class.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"@addrules ds begin\n    classifiertrain(model::Val{:SVC}, options::Dict, traindat::NodeRef) = PyTrain[\"sklearn.svm.SVC\", options](traindat...)\n    classifiertrain(model::Val{:DecisionTree}, options::Dict, traindat::NodeRef) = PyTrain[\"sklearn.tree.DecisionTreeClassifier\", options](traindat...)\n    classifiertrain(model::Val{:RandomForest}, options::Dict, traindat::NodeRef) = PyTrain[\"sklearn.ensemble.RandomForestClassifier\", options](traindat...)\n    classifiertrain(model::Val{:AdaBoost}, options::Dict, traindat::NodeRef) = PyTrain[\"sklearn.ensemble.AdaBoostClassifier\", options](traindat...)\n    classifiertrain(model::Val{:MLPC}, options::Dict, traindat::NodeRef) = PyTrain[\"sklearn.neural_network.MLPClassifier\", options](traindat...)\n    classifiertrain(model::Val{:GaussianNB}, options::Dict, traindat::NodeRef) = PyTrain[\"sklearn.naive_bayes.GaussianNB\", options](traindat...)\n    classifiertrain(model::Val{:XGBoost}, options::Dict, traindat::NodeRef) = PyTrain[\"xgboost.XGBClassifier\", options](traindat...)\n    classifiertrain(model::Symbol, options::Dict, traindat::NodeRef; label = \"$model-train\") = Alias(classifiertrain(val(model), options, traindat))\nend","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"We now proceed to train multiple ML models and compare their in-sample and out-sample performance using metrics, such as Gini. The ML models are trained to predict the survival probability of Titanic passengers. We first define the list of models we want to compare and their hyperparameters.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"models = [\n    :DecisionTree => Dict(:min_samples_leaf => 0.1),\n    :LogisticRegression => Dict(:solver => \"saga\", :max_iter => 200),\n    :AdaBoost => Dict(),\n    :XGBoost => Dict(),\n    :GradientBoost => Dict(:min_samples_leaf => 0.1),\n    :RandomForest => Dict(:min_samples_leaf => 0.1),\n    :GaussianNB => Dict(),\n];","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"The target variable name for ML prediction is given below.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"yname = :Survived;","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"To divide the input dataset for training and validation, we use the randrowsel rule from the DataScience package. The resulting node valind contains a DataFrame with a validation index column of Vector{Bool} type that randomly indicates wether a row is used for training or validation. The 1/3 is the percentage of rows that will be reserved for validation.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"valind = RuleDSL.@ref ds.randrowsel(cleansrc, 1 / 3);","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"Feature engineering is also supported generically by a rule in DataScience package. A feature set is defined by a 3-element Tuple, including the name of the feature set, a Julia Expr providing the transformations for additional features and lastly, the columns to be dropped  from the feature set. In this particular case, we only drop some columns that should have  no association with a passenger's suvival probability such as Ticket Id and passenger' name  and Ids. The Cabin is dropped from the feature set because it has too many missing values.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"# definition of feature engineering: (name, transformations, drop columns)\nfeatures = (\n    :Original,\n    quote end,\n    [:Cabin, :Ticket, :PassengerId, :Name],\n);","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"Note that quote end is just an empty Expr that does not create additional features from the original data set.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"DataScience.ClassifierSpec is a struct that contains all the information required for training and validating multiple binary classifiers, it includes the key configurations we have defined so far. It is more convenient and readable to pass a single DataScience.ClassifierSpec object than five separate parameters. The DataScience.ClassifierSpec is generic, it can be used for any binary classifier problems and data sets.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"cspec = DataScience.ClassifierSpec(models, cleansrc, yname, valind, features);","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"Now we can proceed and use the classifiermetrics rule to compute in-sample and out-of-sample metrics for each model. Internally, this rule calls many other rules for each model and metric, eventually invoking the classifiertrain rules mentioned at the beginning of the section:","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"metrics = [:gini, :roc, :accuracyrate, :accuracygraph]\nbasem = RuleDSL.@ref ds.classifiermetrics(cspec, metrics)\ngs2 = GraphVM.createlocalgraph(config, RuleDSL.GenericData())\n@time GraphVM.calcfwd!(gs2, Set([basem]));","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":" 27.997593 seconds (40.23 M allocations: 2.295 GiB, 2.82% gc time, 27.62% compilation time)\n","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"We can retrieve in-sample and out-sample performance metrics, for example, the GINIs:","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"giniref = RuleDSL.@ref ds.classifiermetric(cspec, :gini)\ngini = GraphVM.getdata(gs2, hash(giniref), 1)\nginidf = DataFrame(model=gini[:InSample][!, :Model], InSample_GINI=gini[:InSample][!, 2], OutSample_GINI=gini[:OutSample][!, 2])","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"<div class=\"data-frame\"><p>7 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>model</th><th>InSample_GINI</th><th>OutSample_GINI</th></tr><tr><th></th><th title=\"String\">String</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>DecisionTree</td><td>0.726202</td><td>0.636718</td></tr><tr><th>2</th><td>LogisticRegression</td><td>0.488286</td><td>0.480253</td></tr><tr><th>3</th><td>AdaBoost</td><td>0.828838</td><td>0.682299</td></tr><tr><th>4</th><td>XGBoost</td><td>0.99447</td><td>0.665693</td></tr><tr><th>5</th><td>GradientBoost</td><td>0.838257</td><td>0.691454</td></tr><tr><th>6</th><td>RandomForest</td><td>0.699895</td><td>0.667981</td></tr><tr><th>7</th><td>GaussianNB</td><td>0.689239</td><td>0.633114</td></tr></tbody></table></div>","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"The entire data and logic from can be visualized by clicking on the URL below.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"svg = GraphIO.postlocalgraph(gss, gs2, port; key=\"ml\");\nGraphIO.postsvg(svg, \"titanic_2.svg\")","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7577_ml\n","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"<p align = \"center\">\n<img src=\"../assets/titanic_2.svg\" alt=\"\" title=\"ML\"/>\n</p>\n<p align = \"center\">\nFigure 2 - Machine Learning\n</p>","category":"page"},{"location":"pages/t002_titanic.html#Hyperparameter-Tuning-1","page":"2 Machine Learning","title":"Hyperparameter Tuning","text":"","category":"section"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"Our Julius Graph Engine also provides a generic rule hypertune for hyperparameter tuning of any ML model. This illustrates the power of rule composition, where a single hypertune rule can leverage existing rules to search for hyperparmeters of any ML model.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"For example, for a given machine learning model, we can select a range for a set of hyperparameters and easily perform a grid search with respect to a metric:","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"ht_1 = RuleDSL.@ref ds.hypertune(cspec, :XGBoost,       Dict(), :gini, :n_estimators => 50:50:200, :learning_rate    => .05:.05:.2);\nht_2 = RuleDSL.@ref ds.hypertune(cspec, :AdaBoost,      Dict(), :gini, :n_estimators => 50:50:200, :learning_rate    => .05:.05:.2);\nht_3 = RuleDSL.@ref ds.hypertune(cspec, :GradientBoost, Dict(), :gini, :n_estimators => 50:50:200, :min_samples_leaf => .05:.05:.2);\nht_4 = RuleDSL.@ref ds.hypertune(cspec, :RandomForest,  Dict(), :gini, :n_estimators => 50:50:200, :min_samples_leaf => .05:.05:.2);","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"Additional search dimensions can be added to the ds.hypertune rule by appending additioanl pairs of hyperparameter => searchgrid to the end of rule parameter. We can then wrap the previous nodes in a single node for convenience by means of the alias rule wich uses the Alias atom:","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"tunings = RuleDSL.@ref ds.alias([ht_1, ht_2, ht_3, ht_4]; label=\"Hyperparameter Tuning\")","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"ds:alias/Hyperparameter Tuning","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"Now proceed with the computation of all the defined hyperparameter tunings:","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"gs3 = GraphVM.createlocalgraph(config, RuleDSL.GenericData());\n@time GraphVM.calcfwd!(gs3, Set([tunings]));","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":" 21.444195 seconds (11.79 M allocations: 802.595 MiB, 1.25% gc time, 18.49% compilation time)\n","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"The following cell shows the resulting insample and outsample GINI from the different hyperparametrs for GradientBoost:","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"dat = GraphVM.getdata(gs3, hash(ht_3))\ndf = deepcopy(dat[1][:, 1:2])\ndf[!, :InSampleGINI] = dat[1][!, 3]\ndf[!, :OutSampleGINI] = dat[2][!, 3]\ndf","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"<div class=\"data-frame\"><p>16 rows × 4 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>n_estimators</th><th>min_samples_leaf</th><th>InSampleGINI</th><th>OutSampleGINI</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>50</td><td>0.05</td><td>0.830292</td><td>0.708162</td></tr><tr><th>2</th><td>50</td><td>0.1</td><td>0.791017</td><td>0.713298</td></tr><tr><th>3</th><td>50</td><td>0.15</td><td>0.755973</td><td>0.709992</td></tr><tr><th>4</th><td>50</td><td>0.2</td><td>0.705137</td><td>0.729621</td></tr><tr><th>5</th><td>200</td><td>0.05</td><td>0.916393</td><td>0.699364</td></tr><tr><th>6</th><td>200</td><td>0.1</td><td>0.869205</td><td>0.709535</td></tr><tr><th>7</th><td>200</td><td>0.15</td><td>0.838939</td><td>0.714874</td></tr><tr><th>8</th><td>200</td><td>0.2</td><td>0.775377</td><td>0.726367</td></tr><tr><th>9</th><td>100</td><td>0.05</td><td>0.871326</td><td>0.708263</td></tr><tr><th>10</th><td>100</td><td>0.1</td><td>0.831655</td><td>0.707399</td></tr><tr><th>11</th><td>100</td><td>0.15</td><td>0.795702</td><td>0.708772</td></tr><tr><th>12</th><td>100</td><td>0.2</td><td>0.740216</td><td>0.728096</td></tr><tr><th>13</th><td>150</td><td>0.05</td><td>0.900193</td><td>0.699975</td></tr><tr><th>14</th><td>150</td><td>0.1</td><td>0.854054</td><td>0.705975</td></tr><tr><th>15</th><td>150</td><td>0.15</td><td>0.823299</td><td>0.720773</td></tr><tr><th>16</th><td>150</td><td>0.2</td><td>0.761951</td><td>0.724333</td></tr></tbody></table></div>","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"Please note that the developer is in charge of selecting the optimal hyperparameter set, as this may involve multiple objectives, the parameter set producing the maximum out-sample gini may not be the best choice. Often, it is better to choose the parameter set with similar in-sample and out-of-sample gini to minimize the chance of overfitting.","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"svg = GraphIO.postlocalgraph(gss, gs3, port; key=\"hyper\");\nGraphIO.postsvg(svg, \"titanic_3.svg\")","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7577_hyper\n","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"<p align = \"center\">\n<img src=\"../assets/titanic_3.svg\" alt=\"\" title=\"ML\"/>\n</p>\n<p align = \"center\">\nFigure 2 - Machine Learning\n</p>","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"","category":"page"},{"location":"pages/t002_titanic.html#","page":"2 Machine Learning","title":"2 Machine Learning","text":"This page was generated using Literate.jl.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"EditURL = \"https://github.com/JuliusTechCo/Tutorials/blob/main/src/mapreduce.jl\"","category":"page"},{"location":"pages/t003_mapreduce.html#Tutorial-3:-MapReduce-1","page":"3 MapReduce","title":"Tutorial 3: MapReduce","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#How-to-use-this-tutorial-1","page":"3 MapReduce","title":"How to use this tutorial","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Select \"run all cells\" on this notebook from the Run menu in Jupyter notebook or Jupyter","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"lab. This step will produce intermediate data output and charts.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Some cells print out a url, which you can click on and bring up an interactive web UI to visualize the graph data.\nIn the unlikely event that the notebook becomes irresponsive, you can try \"Restart Kernel\" from the Kernel menu, then run individual cells one by one using Shift+Enter.\nSome tutorials use local clusters consisting of multiple processes to mimic the effects","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"of graph distribution over a remote clusters. By default, these local clusters   automatically stop after idling for 15min to conserve CPU and memory resources. You will   need to rerun the entire notebook if your local cluster stopped due to inactivity.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Additional resources (video demos & blogs) are available at http://juliustech.co\nTo report any issues, get help or request features, please raise an issue at:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"https://github.com/JuliusTechCo/JuliusGraph/issues","category":"page"},{"location":"pages/t003_mapreduce.html#.-Introduction-1","page":"3 MapReduce","title":"0. Introduction","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"In this tutorial, we use Julius RuleDSL to build a generic MapReduce pipeline, and illustrate the benefits of Julius' high order rules.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"MapReduce is a common pipeline pattern which is often used for processing big data sets in parallel with multiple computers/workers. The MapReduce pipeline is a defining feature in many popular data platforms, such as Hadoop.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"In this tutorial, we explain how to build a generic and re-usable MapReduce pipeline using a few simple rules in Julius' low-code declarative RuleDSL, as oppose to writing tons of code as in traditional programming languages.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The MapReduce pipeline is composed of three main steps:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"map: a common map function is applied to every input data batch.\nshuffle: workers redistribute the map output based on certain key values such that all data with the same key value is shipped to the same worker. After the shuffle, each worker has the complete mapping results for its sub set of keys.\nreduce: each worker then process all the mapping results for a subset of keys by applying a reduce function. These reduced results are then collated as the final result.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The following image shows the generic MapReduce steps for the problem of counting the number of occurrences of each word in a large collection of documents, which is given in the original paper of Hadoop. This word count example is often used to illustrate the MapReduce pipeline. We will try to replicate this example while building a generic MapReduce pipeline in Julius RuleDSL from scratch.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"(Image: )","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The MapReduce input data is a collection of data batches. The creation of the data batches has to be done before the MapReduce pipeline (as in the Splitting stage in the diagram above). For example, if the original data is a single large data file, it has to be split into multiple batches of smaller files before feeding into the MapReduce process.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The goal of the tutorial is to construct a generic mapreduce rule whose mapper, shuffler and reducer operators can be customized by the user. Even though the word count problem itself is trivial, we will implement the pipeline in a generic fashion so that it can be re-used without change for any MapReduce problems.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The readers are referred to the quick start tutorial for basic concepts and syntax of RuleDSL and Atom. But for completeness, we give a brief explanations of the rule syntax and graph execution here.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"A rule in RuleDSL has the following syntax:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"RuleDSL.@addrules namespace begin\n    rulename(rulearg1::Type1, rulearg2::Type2, ...) = begin\n        # additional code here transforming ruleargs to atom args and dependent args\n        AtomName[atomarg1, atomarg2...](deprule1(depargs1...), deprule2(depargs2...), ...)\n    end\nend","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The RuleDSL.@addrules is a macro used for processing RuleDSL, it takes a namespace parameter and a set of rule declarations.  The rule namespace helps organize the rules into related groups, and avoid name clashes. A rule in RuleDSL is an instruction to create certain nodes in the computational graph. When Julius GraphEngine process a rule, it creates a node with name rulenamein the graph. The AtomName[atomarg1, atomarg2...] syntax defines an Atom object, which is is used to process the data from the node's dependency. The dependent nodes are captured by the deprules1, deprules etc, they are added recursively to the graph, if they do not already exist.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"As you can appreciate, graph programming is quite different from traditional programming. Instead of writing imperative functions, we declare the logic and dependencies using rules, then let the Graph Engine to create the graph and application for us. The benefit of graph programming will become more aparent when we go through this tutorial.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The generic mapreduce rule should include three stages, mapper, shuffler and reducer, therefore it should look like:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"RuleDSL.@addrules mr begin\n    mapreduce(\n        batches::Vector{RuleDSL.NodeRef},\n        mapper::RuleDSL.NodeRef,\n        shuffler::RuleDSL.NodeRef,\n        reducer::RuleDSL.NodeRef\n    ) = begin\n        # ... rule definition goes here ...\n    end\nend","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The RuleDSL.NodeRef is a data structure that refers to another rule. A rule with a RuleDSL.NodeRef parameter, like the mapreduce rule above, is called a high order rule, as it defines a generic pattern whose behavior depends on other rules. Each RuleDSL.NodeRef parameter can be a rule that represents a complex graph, thus the high order rule is extremely powerful in defining complex logic and behaviors. Furthermore, a high order rule can be passed as parameter to another rule, creating even higher order rules. The ability to nest high order rules is one of the reasons why the RuleDSL is both low-code and expressive. The high order rule is similar in spirit to the high order functions in functional programming, which we will compare to at the end of this tutorial.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"We now proceed to the implementation of the MapReduce pipeline as depicted in the diagram above using Julius RuleDSL.","category":"page"},{"location":"pages/t003_mapreduce.html#.-Generic-Map/Reduce-1","page":"3 MapReduce","title":"2. Generic Map/Reduce","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#.1-Mapping-1","page":"3 MapReduce","title":"2.1 Mapping","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"In the mapping step of the word count example, a batch of data is just a String such as \"Mary has a lamb\", which is converted into a Vector of Pairs: [\"Mary\" => 1, \"has\" => 1, \"a\" => 1, \"lamb\" => 1], where each entry represents one occurrence of a given word. At the shuffle stage, the vector is split by a key value, which is the word itself in the above diagram; then all the pairs for the same key word are sent to a single node; where they are concatenated to form a single vector. Finally at the reducer stage, the total occurrence of each key word is deduced by simply counting their occurrences in the vector.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Given that the logic in the word count example is simple, we use a generic ApplyFn atom that is provided as part of the DataScience package, which can take any Julia function as argument, so that we don't have to define many Atom types for every stage of the MapReduce process. ApplyFn source code is listed below, which inherits from the abstract base type Datom and implements a generic method fwddata!, which will be called by Julius Graph Engine at run time to process data at individual node.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"import GraphEngine.RuleDSL: fwddata!\n\nstruct ApplyFn <: RuleDSL.Datom\n    fn::Any # can be a function or any object with a callable method defined\n    params::Tuple # the first few arguments of `fn`\n\n    ## this inner constructor captures `params` as a Tuple\n    ApplyFn(fn::Any, params::Any...) = new(fn, params)\nend\n\nfwddata!(self::ApplyFn, xs::Any...) = [self.fn(self.params..., xs...)]","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Using the generic DataScience.ApplyFn Atom, the mapper rule for word count example can be written as:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"using GraphEngine: RuleDSL, GraphVM\nusing DataScience: ApplyFn\nusing AtomExt\n\nwordmap(words::String) = [k => 1 for k in split(words)]\n\nRuleDSL.@addrules mr begin\n    mapper(batch::RuleDSL.NodeRef, mapfun::Function) = ApplyFn[mapfun](batch...)\nend","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The GraphEngine.RuleDSL and GraphEngine.GraphVM modules has to be included in order to use the RuleDSL to create and run computational graphs.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The dependency of this rule is simply given as batch..., which specifies that the node represented by the batch parameter is a dependency. The three dot syntax ... is used to signal dynamic dependencies from a NodeRef parameter or variable. At run time, Julius GraphEngine first converts the ApplyFn[mapfun] specification to a call to the constructor of ApplyAtom(mapfun). Then, the generic fwddata! method of the ApplyFn atom object is used to process the data from its input node specified by the batch parameter.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The mapper rule above takes a single RuleDSL.NodeRef as input, as it only applies to an individual batch input. However, the mapreduce rule needs to process all the mapper results from all batches. So, how do we make that information available to the mapreduce rule? We could create a collection of mapper rules as Vector{NodeRef} then pass it into the mapreduce rule:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"mappers = RuleDSL.@ref(mr.mapper(batch, mapfun) for batch in batches)\nmr = RuleDSL.@ref mr.mapreduce(batches, mappers, shufflers, reducers)","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"where the batches is a Vector{RuleDSL.NodeRef} representing the collection of input batches. However, this approach would require us to also create vectors of shufflers and reducers, thus putting too much burden on the user to ensure their consistencies. By observing that the first argument of the mapper rule is its input data batch, and the same mapper rule should be applied to all batch inputs, we instead choose to drop the first argument in the mapper rule before passing it as an argument to the mapreduce rule, such that:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"mapper = RuleDSL.@ref mr.mapper(mapfun)\nmr = RuleDSL.@ref mr.mapreduce(batches, mapper, shuffler, reducer)","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Inside the mapreduce rule, the first argument is added back for every data batch using the following prepend function, to recover the full form of the mapper rule:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"prepend(ref::RuleDSL.NodeRef, firstarg::Any) = RuleDSL.NodeRef(ref.ns, ref.name, (firstarg, ref.params...), ref.meta)","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"prepend (generic function with 1 method)","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The advantages of dynamically inserting the first parameter in the mapreduce rule are the following:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"First it is more readable and clear in that we only need the overall rule logic, but not its first argument that specifies its batch input.\nSecondly it is less error prone, as the mappers are created inside the mapreduce rule to be fully consistent with the batches. We will do the same for shuffler and reducer later.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Let's test our mapping rule to see how it works. We have to define the input data batches first. For this word count example, we can simply use the ApplyFn atom with the identity function to return a rule argument, such that:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"@addrules mr begin\n    batch(s::Any) = ApplyFn[identity, s]()\nend\n\n# some input data\n_sentences = (\"Deer Bear River\", \"Car Car River\", \"Deer Car Bear\")\n_batches   = RuleDSL.@ref(mr.batch(s) for s in _sentences)\n_mapper    = RuleDSL.@ref mr.mapper(wordmap)\n\n# prepend returns a new `NodeRef` such that `mappers` is of `Vector{NodeRef}` type\n_mappers = [prepend(_mapper, batch) for batch in _batches]\n\n# create a local graph, provide the node references and calculate\nconfig = RuleDSL.Config()\ngs1 = GraphVM.createlocalgraph(config, RuleDSL.GenericData())\nGraphVM.calcfwd!(gs1, Set(_mappers))","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"0","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"We have now created a computational graph for the mapper and executed it. How do we see the results? Julius provides an easy-to-use web UI for users to navigate and visualize the resulting data and logic in the graph. The following code block starts a local server so that the web UI can retrieve the resulting graph data, it also overrides the RuleDSL.nodelabel method to customize the information displayed on the graph node.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"using GraphIO\n\n# a container of graphs\ngss = Dict{String,RuleDSL.AbstractGraphState}()\n\n# used for WebUI display purposes\nport = GraphVM.drawdataport()\n@async GraphVM.startresponder(gss, port);\n\n# override node label display\nimport GraphEngine.RuleDSL: nodelabel\nfunction nodelabel(gs::RuleDSL.AbstractGraphState, ref::RuleDSL.NodeRef)\n    shortrepr(x::Vector; sep=\", \") = \"[\"*join(shortrepr.(x), sep)*\"]\"\n    shortrepr(p::Pair; sep=\"=>\") = shortrepr(p.first) * sep * shortrepr(p.second)\n    shortrepr(p::Dict; sep=\", \") = \"{\" * join(shortrepr.(collect(p)), sep) * \"}\"\n    shortrepr(x::Any; sep=\"\") = repr(x)\n\n    label = haskey(ref.meta, :label) ? ref.meta[:label] : \"$(ref.ns).$(ref.name)\"\n\n    try\n        data = RuleDSL.getdata(gs, ref)\n        if isone(length(data))\n            data = first(data)\n        end\n        label *= \"\\n\" * shortrepr(data; sep = \"\\n\")\n    catch\n        label *= \": n/a\"\n    end\n\n    return label\nend","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"nodelabel (generic function with 4 methods)","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"User can view the resulting data from exeucting the graph interactively by clicking on the url below to bring up the full web UI. As expected, the output of mapper is a vector of entries like \"word\" => 1.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"svg = GraphIO.postlocalgraph(gss, gs1, port; key=\"map\");\nGraphIO.postsvg(svg, \"mapreduce_1.svg\")","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7015_map\n","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"<p align = \"center\">\n<img src=\"../assets/mapreduce_1.svg\" alt=\"\" title=\"mappers\"/>\n</p>\n<p align = \"center\">\nFigure 1 - Mapping step.\n</p>","category":"page"},{"location":"pages/t003_mapreduce.html#.2-Shuffling-1","page":"3 MapReduce","title":"2.2 Shuffling","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The shuffling step consists of three sub steps:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"take the outputs from the mappers and split them into multiple chunks by certain key values computed from the mapped data.\nmove these chunks around so that all data with the same key value is shipped to the same node.\nconcatenate all the chunks associated with a given key at the containing node to recover the full collection of data for the key.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"To implement the first sub step of the shuffling, we define a generic split function that takes a key function:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"given a collection of elements xs and a key function that computes the key of each of these elements, return a Dictionary with key => [element_1, ..., element_n]","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"function splitbykey(keyfunc::Function, xs::Any)\n    splits = Dict()\n    for x in xs\n        key = keyfunc(x)\n        splits[key] = push!(get(splits, key, []), x)\n    end\n    return splits\nend","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"splitbykey (generic function with 1 method)","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"With this split function, we define three rules that corresponds to the three sub steps of shuffling, then combine them together in the generic shuffler rule:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"@addrules mr begin\n\n    # use `splitbykey` function defined above\n    splitbykey(mapper::RuleDSL.NodeRef, keyfunc::Function) = ApplyFn[splitbykey, keyfunc](mapper...)\n\n    # select an element of a dictionary ir exists or return an empty `Vector{Any}`\n    selectkey(dict::RuleDSL.NodeRef, key::Any; label=\"selectby $(key)\") = ApplyFn[dict -> get(dict, key, [])](dict...)\n\n    # merge\n    mergebykey(vecs::Vector{RuleDSL.NodeRef}) = ApplyFn[vcat](vecs...)\n\n\n    shuffler(mappers::Vector{RuleDSL.NodeRef}, keyfunc::Function, keys::Set) = begin\n\n        splits = RuleDSL.@ref(splitbykey(mapper, keyfunc) for mapper in mappers)\n\n        shuffled = Vector{NodeRef}()\n        for key in keys\n            # a `Vector{NodeRef}` that encompasses nodes with a given key\n            selected = RuleDSL.@ref(selectkey(s, key) for s in splits)\n\n            # merge the previously selected nodes outputs\n            merged = RuleDSL.@ref mergebykey(selected; label=\"mergeby $key\")\n\n            # add merged element to the shuffled `Vector`\n            push!(shuffled, merged)\n        end\n\n        Alias(shuffled...)\n    end\nend","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"These rules are quite self explanatory as all of them use the generic atom ApplyFn. It is worth mentioning that the selectkey rule uses a function closure when constructing the ApplyFn atom; and in the mergebykey rule, the  ... follows a Vector{NodeRef} to specify dynamic dependency on multiple rules in the vector. The label keyword in the  selectkey rule is to customize the display information of individual nodes in the graph  web UI, please refer to the nodelabel function defined at the beginning.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"We can test the shuffler using the words in the text as the split key, the first in the shuffler rule is a function that returns the first element of the \"word\"=>1 pair, which is the word itself.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"# _mappers were created before\n_shuffler = RuleDSL.@ref mr.shuffler(_mappers, first, Set([\"Bear\", \"Car\", \"Deer\", \"River\"]))\n\ngs2 = GraphVM.createlocalgraph(config, RuleDSL.GenericData())\nGraphVM.calcfwd!(gs2, Set([_shuffler]))","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"0","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"svg = GraphIO.postlocalgraph(gss, gs2, port; key=\"mappers\");\nGraphIO.postsvg(svg, \"mapreduce_2.svg\")","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7015_mappers\n","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"<p align = \"center\">\n<img src=\"../assets/mapreduce_2.svg\" alt=\"\" title=\"mappers\"/>\n</p>\n<p align = \"center\">\nFigure 2 - Shuffling step.\n</p>","category":"page"},{"location":"pages/t003_mapreduce.html#.3-Reducing-1","page":"3 MapReduce","title":"2.3 Reducing","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Finally, we get to the reduce part of the MapReduce pipeline. In the word count example, the reducer simply counts the occurrences of word. The reducer rule is applied to the result of mergebykey, i.e. a vector of entries like \"word\" => 1, which are all associated with the same key value from shuffling stage.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"RuleDSL.@addrules mr begin\n    reducer(shuffled::RuleDSL.NodeRef, reducefun::Function) = ApplyFn[reducefun](shuffled...)\nend\n\n# the reducer function\nfunction wordreduce(xs::Vector)\n    count = Dict()\n    for (key, _) in xs\n        count[key] = get(count, key, 0) + 1\n    end\n    return count\nend","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"wordreduce (generic function with 1 method)","category":"page"},{"location":"pages/t003_mapreduce.html#.4-Map/Reduce-Rule-1","page":"3 MapReduce","title":"2.4 Map/Reduce Rule","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"We now put everything together and write a generic mapreduce rule. Note that we will use the same prepend function to dynamically insert the first argument the for shuffler and mapper rules:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"RuleDSL.@addrules mr begin\n    mapreduce(\n        batches::Vector{RuleDSL.NodeRef},\n        mapper::RuleDSL.NodeRef,\n        shuffler::RuleDSL.NodeRef,\n        reducer::RuleDSL.NodeRef\n    ) = begin\n\n        # create one mapper node per batch\n        mappers = [prepend(mapper, batch) for batch in batches]\n\n        # create the shuffler\n        shuffler = prepend(shuffler, mappers)\n\n        # this gives the inputs to the shuffled nodes, which is where reducer must be applied\n        shuffled = RuleDSL.calcdeps(RuleDSL.@config, shuffler)\n        reducers = [prepend(reducer, m) for m in shuffled]\n\n        # finally the results (i.e. a Dict per reducer) are merged to a single Dictionary\n        ApplyFn[merge](reducers...)\n    end\nend","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Let's test the MapReduce rule using our word count example:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"# no need for the first argument as it will be populated at `mapreduce`\n_shuffler = RuleDSL.@ref mr.shuffler(first, Set([\"Bear\", \"Car\", \"Deer\", \"River\"]))\n\n_mapper  = RuleDSL.@ref mr.mapper(wordmap)\n_reducer = RuleDSL.@ref mr.reducer(wordreduce)\n\n_mapreduce = RuleDSL.@ref mr.mapreduce(_batches, _mapper, _shuffler, _reducer)\n\ngs3 = GraphVM.createlocalgraph(config, RuleDSL.GenericData())\nGraphVM.calcfwd!(gs3, Set([_mapreduce]))","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"0","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"svg = GraphIO.postlocalgraph(gss, gs3, port; key=\"mapred\");\nGraphIO.postsvg(svg, \"mapreduce_3.svg\")","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7015_mapred\n","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"<p align = \"center\">\n<img src=\"../assets/mapreduce_3.svg\" alt=\"\" title=\"mappers\"/>\n</p>\n<p align = \"center\">\nFigure 3 - MapReduce pipeline.\n</p>","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The resulting diagram from Julius web UI is quite self explanatory, it matches exactly the diagram provided by the Hadoop paper. A side benefit of Julius is that it frees developers from the pain of having to manually draw system diagram or UMLs ever again. The graph diagram above is an output from the Julius Graph Engine, which shows great details of both the data and logic. Julius' convenient Web UI allows users to easily navigate and access the entire graph data and logic, which can be accessed by clicking the link above if you are running this example in Jupyter.","category":"page"},{"location":"pages/t003_mapreduce.html#.5-Split-by-Hashed-Keys-1","page":"3 MapReduce","title":"2.5 Split by Hashed Keys","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"So far, our MapReduce implementation works as expected. However, there is a serious shortcoming in that we have to specify all the possible words in the shuffler, which is not known before we process all the input batches. In practice, we don't want to scan all the input batches just to find out all the possible words, which can be very time consuming when the inputs are large. Also, in live streaming applications, such pre-scan is not possible at all.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"It would be much more convenient if we don't have to specify all the possible words in the shuffler. We can easily achieve this by supplying a different key function whose number of possible outputs are known, for example, by making use of the hash and the remainder % functions:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"_shuffler = RuleDSL.@ref mr.shuffler(x -> Int(hash(first(x)) % 3), Set(collect(0:2)))\n\n# reuse the same _mapper and _reducer declared earlier\n_mapreduce = RuleDSL.@ref mr.mapreduce(_batches, _mapper, _shuffler, _reducer)\n\ngs4 = GraphVM.createlocalgraph(config, RuleDSL.GenericData())\nGraphVM.calcfwd!(gs4, Set([_mapreduce]))","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"0","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"svg = GraphIO.postlocalgraph(gss, gs4, port; key=\"hash\");\nGraphIO.postsvg(svg, \"mapreduce_4.svg\")","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7015_hash\n","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"<p align = \"center\">\n<img src=\"../assets/mapreduce_4.svg\" alt=\"\" title=\"mappers\"/>\n</p>\n<p align = \"center\">\nFigure 4 - MapReduce pipeline with a shuffling step using hashed keys.\n</p>","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Now the shuffler splits the mapper data into 3 pipes, each of which is identified by an index number. In this implementation, multiple words can go to the same pipe. This implementation removes the need of pre-scans for obtaining all the words; it also works for live streaming use cases. Since the splitting by hash key is a much better implementation, we declare a couple convenience rules to encourage its use:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"@addrules mr begin\n\n    splitbykey(mapper::RuleDSL.NodeRef, keyfunc::Function, N::Int) = begin\n        ApplyFn[splitbykey, x -> Int(hash(keyfunc(x)) % N)](mapper...)\n    end\n\n    shuffler(mappers::Vector{RuleDSL.NodeRef}, keyfunc::Function, N::Int) = begin\n\n        splits = RuleDSL.@ref(splitbykey(mapper, keyfunc, N) for mapper in mappers)\n\n        shuffled = Vector{NodeRef}()\n        for key in 0:N-1\n\n            # a `Vector{NodeRef}` that encompasses nodes with a given key\n            selected = RuleDSL.@ref(selectkey(s, key) for s in splits)\n\n            # merge the previously selected nodes outputs\n            merged = RuleDSL.@ref mergebykey(selected; label=\"mergeby $key\")\n\n            # add merged element to the shuffled `Vector`\n            push!(shuffled, merged)\n        end\n\n        Alias(shuffled...)\n    end\nend","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Now, the shuffler declaration can be simply given as:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"_shuffler = RuleDSL.@ref mr.shuffler(first, 3)","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"mr:shuffler/typeof(first):6553","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"which becomes much easier to read and define than its equivalent earlier version of _shuffler. Note that since rules support polymorphism, the hash version of splitbykey rule will be used if an interger is supplied as its 3rd argument.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"So far we have demonstrated the MapReduce pipeline can be implemented using RuleDSL by simply declaring a few high order rules. The resulting MapReduce rule is generic, powerful and reusable. Next, we will use it to solve a few common MapReduce problems.","category":"page"},{"location":"pages/t003_mapreduce.html#.-Examples-of-MapReduce-1","page":"3 MapReduce","title":"3. Examples of MapReduce","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#.1-Finding-Friends-1","page":"3 MapReduce","title":"3.1 Finding Friends","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"We can use the MapReduce pipeline to compute the common friends among hundred of millions or more users in a social network. This feature can be used to populate the You and Joe have N friends in common displayed in many social networks. Given the list of friends for each user, we proceed to define both a mapper and a reducer functions and make use of our previously defined mapreduce rule to compute common friends for every user pair left( u_i u_j right):","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"function friends_mapfun(batch::String)\n    dict = Dict{NTuple{2,Char},Vector}()\n    handler = strip.(split(batch, \"=>\"))\n\n    # no friends\n    if isone(length(handler))\n        return [dict]\n    elseif length(handler) > 2\n        return error(\"Unexpected data format.\")\n    end\n\n    user, friends = handler\n\n    # no friends\n    if isempty(friends)\n        return dict\n    end\n\n    uid = only(user)\n    fids = only.(split(friends, ','))\n    for fid in fids\n        if isequal(uid, fid)\n            continue\n        end\n\n        key = tuple(sort!([uid, fid])...)\n        push!(dict, key => fids)\n    end\n\n    return dict\nend\n\nfunction friends_reducefun(shuffler::Vector)\n    out = Dict{NTuple{2,Char},Vector{Char}}()\n    for (k, v) in shuffler\n        if !haskey(out, k)\n            out[k] = v\n        else\n            out[k] = intersect(out[k], v)\n        end\n    end\n    return out\nend\n\n# each user is represented by a `Char`\n_friends = IOBuffer(\"\n    A => B,C,D\n    B => A,C,D,E\n    C => A,B,D,E\n    D => A,B,C,E\n    E => B,C,D\n\")\n\n_batches = RuleDSL.@ref(mr.batch(line) for line in eachline(_friends) if !isempty(line))\n\n_mapreduce = RuleDSL.@ref mr.mapreduce(\n    _batches,\n    RuleDSL.@ref(mr.mapper(friends_mapfun)),\n    RuleDSL.@ref(mr.shuffler(first, 4)),\n    RuleDSL.@ref(mr.reducer(friends_reducefun))\n)","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"mr:mapreduce/NodeRef[5]","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"gs5 = GraphVM.createlocalgraph(config, RuleDSL.GenericData())\nGraphVM.calcfwd!(gs5, Set([_mapreduce]))","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"0","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"svg = GraphIO.postlocalgraph(gss, gs5, port; key=\"ff\");\nGraphIO.postsvg(svg, \"mapreduce_5.svg\")","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7015_ff\n","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"<p align = \"center\">\n<img src=\"../assets/mapreduce_5.svg\" alt=\"\" title=\"mappers\"/>\n</p>\n<p align = \"center\">\nFigure 5 - Finding common friends (open image in new tab for full resolution).\n</p>","category":"page"},{"location":"pages/t003_mapreduce.html#.2-GroupBy-1","page":"3 MapReduce","title":"3.2 GroupBy","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"When dealing with large data set, we often need to split it to smaller batches, then apply the MapReduce pipeline to perform certain operations on individual batches then group them together. In this section, we will show how to implement the groupby operation on a large data set using the MapReduce pipeline.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"In order to split the data in multiple batches, we make use of our DDataFrame (which stands for Distributed DataFrames) provided in the DataScience package. The following mapper and reducer rules implements the group by using any number of features within the MapReduce pipeline:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"using DataFrames\nusing DataScience: DDataFrame\n\n# `cols` can be anything accepted by `DataFrames.groupby` method\nfunction groupby_mapfun(batch::AbstractDataFrame, cols)\n    dict = Dict()\n    gdf = groupby(batch, cols)\n    for (key, df) in zip(keys(gdf), gdf)\n        push!(dict, NamedTuple(key) => DataFrame(df; copycols=false))\n    end\n    return dict\nend\n\nfunction groupby_reducefun(shuffler::Vector)\n    out = Dict()\n    for (k, v) in shuffler\n        out[k] = append!(get(out, k, DataFrame()), v)\n    end\n    return out\nend\n\nfilepath = joinpath(@__DIR__, \"../data/iris.csv\")\nddf = DDataFrame(filepath, nrows=25)\n_batches = ddf.chunks\n\n# use 3 reducing nodes for the reducing step\n_mapreduce = RuleDSL.@ref mr.mapreduce(\n    _batches,\n    RuleDSL.@ref(mr.mapper(x -> groupby_mapfun(x, [:Species]))),\n    RuleDSL.@ref(mr.shuffler(first, 3)),\n    RuleDSL.@ref(mr.reducer(groupby_reducefun))\n)","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"mr:mapreduce/NodeRef[6]","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"gs6 = GraphVM.createlocalgraph(config, RuleDSL.GenericData())\nGraphVM.calcfwd!(gs6, Set([_mapreduce]))","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"0","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"nodelabel(::AbstractGraphState, ref::NodeRef) = haskey(ref.meta, :label) ? ref.meta[:label] : \"$(ref.ns).$(ref.name)\"\nsvg = GraphIO.postlocalgraph(gss, gs6, port; key=\"groupby\");\nGraphIO.postsvg(svg, \"mapreduce_6.svg\")","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7015_groupby\n","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"<p align = \"center\">\n<img src=\"../assets/mapreduce_6.svg\" alt=\"\" title=\"mappers\"/>\n</p>\n<p align = \"center\">\nFigure 6 - GroupBy.\n</p>","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The result is a DataFrame per group, such that, the first 10 rows look like:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"_reducers = calcdeps(config, _mapreduce)\nfor reducer in _reducers\n    dict = RuleDSL.getdata(gs6, reducer)[]\n    for (k, v) in dict\n      println(\"$k => $(first(v, 10))\")\n    end\nend","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"(Species = \"Iris-setosa\",) => 10×5 DataFrame\n Row │ SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n     │ Float64      Float64     Float64      Float64     String15\n─────┼───────────────────────────────────────────────────────────────\n   1 │         4.3         3.0          1.1         0.1  Iris-setosa\n   2 │         4.4         2.9          1.4         0.2  Iris-setosa\n   3 │         4.4         3.0          1.3         0.2  Iris-setosa\n   4 │         4.4         3.2          1.3         0.2  Iris-setosa\n   5 │         4.5         2.3          1.3         0.3  Iris-setosa\n   6 │         4.6         3.1          1.5         0.2  Iris-setosa\n   7 │         4.6         3.4          1.4         0.3  Iris-setosa\n   8 │         4.6         3.6          1.0         0.2  Iris-setosa\n   9 │         4.6         3.2          1.4         0.2  Iris-setosa\n  10 │         4.7         3.2          1.3         0.2  Iris-setosa\n(Species = \"Iris-versicolor\",) => 10×5 DataFrame\n Row │ SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n     │ Float64      Float64     Float64      Float64     String15\n─────┼───────────────────────────────────────────────────────────────────\n   1 │         4.9         2.4          3.3         1.0  Iris-versicolor\n   2 │         5.0         2.0          3.5         1.0  Iris-versicolor\n   3 │         5.0         2.3          3.3         1.0  Iris-versicolor\n   4 │         5.1         2.5          3.0         1.1  Iris-versicolor\n   5 │         5.2         2.7          3.9         1.4  Iris-versicolor\n   6 │         5.4         3.0          4.5         1.5  Iris-versicolor\n   7 │         5.5         2.3          4.0         1.3  Iris-versicolor\n   8 │         5.5         2.4          3.8         1.1  Iris-versicolor\n   9 │         5.5         2.4          3.7         1.0  Iris-versicolor\n  10 │         5.5         2.5          4.0         1.3  Iris-versicolor\n(Species = \"Iris-virginica\",) => 10×5 DataFrame\n Row │ SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n     │ Float64      Float64     Float64      Float64     String15\n─────┼──────────────────────────────────────────────────────────────────\n   1 │         4.9         2.5          4.5         1.7  Iris-virginica\n   2 │         5.6         2.8          4.9         2.0  Iris-virginica\n   3 │         5.7         2.5          5.0         2.0  Iris-virginica\n   4 │         5.8         2.7          5.1         1.9  Iris-virginica\n   5 │         5.8         2.8          5.1         2.4  Iris-virginica\n   6 │         5.8         2.7          5.1         1.9  Iris-virginica\n   7 │         5.9         3.0          5.1         1.8  Iris-virginica\n   8 │         6.0         2.2          5.0         1.5  Iris-virginica\n   9 │         6.0         3.0          4.8         1.8  Iris-virginica\n  10 │         6.1         3.0          4.9         1.8  Iris-virginica\n","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"These previous examples are relatively straight forward in their logic. However, the mapper and reducer rules can encapsulate complicated logic, both of them can be an entire graph of great complexity. For example, the mapper can be the training and validation of an entire ML model, and the reducer can be a bagging algorithm that joins multiple models trained on different batches of data. We will show an example of a more complex use case in the next tutorial.","category":"page"},{"location":"pages/t003_mapreduce.html#.-Advantages-of-Julius-Graph-1","page":"3 MapReduce","title":"4. Advantages of Julius Graph","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#.1-Graph-Composition-vs-Function-Composition-1","page":"3 MapReduce","title":"4.1 Graph Composition vs Function Composition","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"You may find the high level rules in RuleDSL have a lot similarity to high order functions in functional languages like Haskell, where a function can take another function as parameter. So what are the main benefits of high order rule over the high order functions in a functional language?","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The key difference is that high level rules are for composing graphs, while high level functions are for composing functions. The graph composition has a number of advantages over function composition:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"It does not create deep call stacks, the results of graph composition is nothing but another graph. Therefore, it is much easier for a developer to visualize and debug. With function composition, one has to use a debugger to access the intermediate results and call sequences, deep among the call stack of a program's runtime.\nThe resulting graph composition can be automatically distributed without code change. A generic graph distributor can analyze any graph and distribute it effectively to multiple worker computers. In contrast, the traditional functional code is permeated with loops and branches, making their runtime behavior unpredictable, thus cannot be distributed automatically and efficiently.\nThe graph composition is much more flexible. Once the graph is constructed, it can run in different mode. For example, the same graph can support both batch and streaming use cases without code changes, which is not possible in traditional functional programming.\nLastly, graph composition can mimic function composition, but the reverse is not true. The mapreduce rule is a good example how function composition can be replicated using graph composition. However, it is almost impossible to create the equivalent graph composition from function composition in traditional functional languages.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"You have seen some of the benefits graph composition in this and previous tutorials. Next, we will illustrate the 2nd benefit of automatically distributing the MapReduce pipeline to multiple computers.","category":"page"},{"location":"pages/t003_mapreduce.html#.2-Distributed-Map/Reduce-1","page":"3 MapReduce","title":"4.2 Distributed Map/Reduce","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"In order to show the automatic distribution, we set up a local cluster with 3 worker processes managed by a master process running at a port of the local computer, which mimic a remote master and worker processes running on multiple physical computers. Please note that the local cluster automatically terminates after 15min of inactivity, so if you noticed the local cluster no longer accessible after 15min, please re-run this entire tutorial notebook.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The following few lines of code starts the local cluster then connects to the master process, through which we gain control to all the worker processes:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"using GraphEngine: RuleDSL, GraphVM\n\nconfig = RuleDSL.newconfig(RuleDSL.Config(), :project => \"MapReduce\")\nbalancer = GraphVM.GlobalUnique()\nmy_domain = GraphVM.mydomain()\n\n# draw a port number to start the local cluster esrvice\nremoteport = GraphVM.drawdataport()","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"7812","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"# start a local master service at the given port\n\ngs0 = GraphVM.RemoteGraphProxy(my_domain => 7225)\nGraphVM.rpccall(gs0, :startlocalmasterservice, remoteport, 3)\n\ngs = GraphVM.RemoteGraphProxy(config, my_domain => remoteport, balancer, GraphVM.GenericData())\nGraphVM.wait4clusterinit(gs)","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Dict{UInt64, Pair{Float64, GraphEngine.GraphVM.WorkerStatus}} with 3 entries:\n  0x31c0caf4869bdc87 => 1.64847e9=>Ready\n  0x9922a7c4d55f1e2e => 1.64847e9=>Ready\n  0xcdfb226bbf108f63 => 1.64847e9=>Ready","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The following is the complete definition of the generic mapreduce rule and corresponding functions for the word count example. Now we instantiate them in the remote cluster so that we can run the distributed word count with distribution.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"GraphVM.@remote_eval gs begin\n    using GraphEngine: RuleDSL, GraphVM\n    using DataScience: ApplyFn\n    using AtomExt, GraphIO\nend\n\n# wait for the server to complete the task before proceeding\nGraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\n\nGraphVM.@addrules gs mr begin\n    echo(x::Any) = ApplyFn[identity, x]()\n\n    mapper(batch::RuleDSL.NodeRef, mapfun::Function) = ApplyFn[mapfun](batch...)\n\n    reducer(shuffled::RuleDSL.NodeRef, reducefun::Function) = ApplyFn[reducefun](shuffled...)\n\n    splitbykey(mapper::RuleDSL.NodeRef, keyfunc::Function) = ApplyFn[splitbykey, keyfunc](mapper...)\n\n    selectkey(dict::RuleDSL.NodeRef, key::Any; label=\"selectby $(key)\") = ApplyFn[dict -> get(dict, key, [])](dict...)\n\n    mergebykey(vecs::Vector{RuleDSL.NodeRef}) = ApplyFn[vcat](vecs...)\n\n    shuffler(mappers::Vector{RuleDSL.NodeRef}, keyfunc::Function, keys::Set) = begin\n        merged = Vector{NodeRef}()\n        splits = RuleDSL.@ref(splitbykey(mapper, keyfunc) for mapper in mappers)\n        for key in keys\n            values = RuleDSL.@ref(selectkey(s, key) for s in splits)\n            mergebykey = RuleDSL.@ref mergebykey(values; label=\"mergeby $key\")\n            push!(merged, mergebykey)\n        end\n        Alias(merged...)\n    end\n\n    mapreduce(\n        batches::Vector{RuleDSL.NodeRef},\n        mapper::RuleDSL.NodeRef,\n        shuffler::RuleDSL.NodeRef,\n        reducer::RuleDSL.NodeRef\n    ) = begin\n        mappers = [prepend(mapper, batch) for batch in batches]\n        shuffler = prepend(shuffler, mappers)\n        shuffled = RuleDSL.calcdeps(RuleDSL.@config, shuffler)\n        reducers = [prepend(reducer, m) for m in shuffled]\n        ApplyFn[merge](reducers...)\n    end\n\n    splitbykey(mapper::RuleDSL.NodeRef, keyfunc::Function, N::Int) = begin\n        ApplyFn[splitbykey, x -> Int(hash(keyfunc(x)) % N)](mapper...)\n    end\n\n    shuffler(mappers::Vector{RuleDSL.NodeRef}, keyfunc::Function, N::Int) = begin\n        splits = RuleDSL.@ref(splitbykey(mapper, keyfunc, N) for mapper in mappers)\n        shuffled = Vector{NodeRef}()\n        for key in 0:N-1\n            selected = RuleDSL.@ref(selectkey(s, key) for s in splits)\n            merged = RuleDSL.@ref mergebykey(selected; label=\"mergeby $key\")\n            push!(shuffled, merged)\n        end\n        Alias(shuffled...)\n    end\nend\n\nGraphVM.@remote_eval gs begin\n    import GraphEngine.RuleDSL: fwddata!\n\n    prepend(ref::RuleDSL.NodeRef, firstarg::Any) = RuleDSL.NodeRef(ref.ns, ref.name, (firstarg, ref.params...), ref.meta)\n\n    function splitbykey(keyfunc::Function, xs::Any)\n        splits = Dict()\n        for x in xs\n            key = keyfunc(x)\n            splits[key] = push!(get(splits, key, []), x)\n        end\n        return splits\n    end\n\n    wordmap(words::String) = [k => 1 for k in split(words)]\n\n    function wordreduce(xs::Vector)\n        count = Dict()\n        for (key, _) in xs\n            count[key] = get(count, key, 0) + 1\n        end\n        return count\n    end\n\n    import GraphEngine.RuleDSL: nodelabel\n    function nodelabel(gs::RuleDSL.AbstractGraphState, ref::RuleDSL.NodeRef)\n        shortrepr(x::Vector; sep=\", \") = \"[\"*join(shortrepr.(x), sep)*\"]\"\n        shortrepr(p::Pair; sep=\"=>\") = shortrepr(p.first) * sep * shortrepr(p.second)\n        shortrepr(p::Dict; sep=\", \") = \"{\" * join(shortrepr.(collect(p)), sep) * \"}\"\n        shortrepr(x::Any; sep=\"\") = repr(x)\n\n        label = haskey(ref.meta, :label) ? ref.meta[:label] : \"$(ref.ns).$(ref.name)\"\n\n        try\n            data = RuleDSL.getdata(gs, ref)\n            if isone(length(data))\n                data = first(data)\n            end\n            label *= \"\\n\" * shortrepr(data; sep = \"\\n\")\n        catch\n            label *= \": n/a\"\n        end\n\n        return label\n    end\nend","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"nodelabel (generic function with 4 methods)","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"As you can see, there is no change in the RuleDSL and Julia functions at all, we simply sent them to the remote cluster to instantiate. Afterwards, we can execute the MapReduce pipeline with distribution. The distribution API, RuleDSL.jobdeps and GraphVM.dispatchjobs! are explained in more detail in the next tutorial on Distributed ML pipeline, we won't repeat them here.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"_sentences = (\"Deer Bear River\", \"Car Car River\", \"Deer Car Bear\")\n_batches   = RuleDSL.@ref(mr.echo(s) for s in _sentences)\n\nN = 3\n_mapreduce = RuleDSL.@ref mr.mapreduce(\n    _batches,\n    RuleDSL.@ref(mr.mapper(Main.wordmap)),\n    RuleDSL.@ref(mr.shuffler(first, N)),\n    RuleDSL.@ref(mr.reducer(Main.wordreduce))\n)\n\nalljobs, ds = RuleDSL.jobdeps(config, [_mapreduce], Set([:splitbykey, :reducer]));\n\nGraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\nGraphVM.initgraph!(gs)\nGraphVM.dispatchjobs!(gs, alljobs, 1)","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"0","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"GraphVM.waitcheckstatus(gs, RuleDSL.getconfig(config, :project));\nsvg = GraphIO.postremotegraph(gs, port);\n\nGraphIO.postsvg(svg, \"mapreduce_7.svg\")","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"<p align = \"center\">\n<img src=\"../assets/mapreduce_7.svg\" alt=\"\" title=\"mappers\"/>\n</p>\n<p align = \"center\">\nFigure 7 - Distributed computation mode, where each node color represents a different worker.\n</p>","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"GraphVM.rpccall(gs, :endcluster)\n\n# reverting back nodelabel\nnodelabel(gs::RuleDSL.AbstractGraphState, ref::RuleDSL.NodeRef)=haskey(ref.meta, :label) ? ref.meta[:label] : \"$(ref.ns).$(ref.name)\"","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"nodelabel (generic function with 4 methods)","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The resulting graph use different colors to highlight the placement of nodes to individual remote workers. Nodes with the same color are placed and computed on the same worker computer.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Upon close examination, we observe that the resulting graph distribution is optimal in that the work load is evenly distributed amongst 3 workers, and the only shipment of data happens during the shuffling stage, and the collation of final reducer results, when an arrow connects two nodes with different colors. There is no unnecessary data transfer at all in the resulting graph distribution.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The ability to automatically and optimally distribute graph without code change is a powerful feature. Julius can handle the distribute of graphs as large as hundreds millions nodes across hundreds of computers. Using Julius, the same code run efficiently on one worker instance or hundreds of worker instances, without the need for any manual tweaking and optimizations. Auto-scaling allows developers to quickly build and test their rules and functions on the local computer, then immediately scale it up to run large jobs and heavy workload in parallel without the need for any code changes. Julius' autoscaling automates away one of the most time-consuming and expensive aspect in enterprise systems, which is the constant needs for manual tweaking and optimization of the system for better performance and scalability.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"In a next toturial Distributed ML pipeline, we will dive into Julius distribution and auto-scaling capability in much more depth, and compare to existing tools like Dask and Dagger.jl.","category":"page"},{"location":"pages/t003_mapreduce.html#.-Conclusion-1","page":"3 MapReduce","title":"5. Conclusion","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The result speaks for itself: we built a generic MapReduce pipeline from scratch using 10 rules in RuleDSL and 20 lines of additional Julia code. The resulting MapReduce pipeline implementation is generic, transparent and auto-scaling. Every intermediate calculation result is fully visible to the user in our web UI, it automatically distributes to multiple computers without any code changes for extreme scalability and performance.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Intrigued? If you are a developer, you should. To hear more about Julius Graph Engine, contact us at info@juliustech.co, or go to our website to schedule a demo or sign up for free access for developers.","category":"page"},{"location":"pages/t003_mapreduce.html#Appendix:-Additional-Technical-Tips-and-Notes-1","page":"3 MapReduce","title":"Appendix: Additional Technical Tips & Notes","text":"","category":"section"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"Here we explain some additional technical tips and points. We refer to the general structure of a rule in RuleDSL as:","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"rulename(ruleargs::Any...) = Atom[atomargs...](dependentrule(depargs...))","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"The ApplyFn atom is used extensively in this tutorial. Though it is convenient, it was only intended for simple analytical logic. For complex analytical algorithms, it is better to define individual Atoms for reusability and readability.\nThere is an important difference between the ruleargs and atomargs in the rule syntax. The ruleargs is serialized and sent to remote worker during distribution, while atomargs are only created and used locally by individual workers. Therefore to enable distribution, every ruleargs has to be serializable with a stable hash, i.e. same object shall retrieve the same hash regardless which worker runs it. This requirement does not apply to atomargs. Julius use a customized hash function RuleDSL.hashparam for rule parameters, that support stable hashes for a wide variety of object types. However, the following are some instances where the serialization can fail or the hash becomes unstable:\nIf a rule parameter is a function closure with reference to any local variable, the serialization will fail.  A workaround is to move the function closure inside the body of the rule. For example, the first hash key shuffler will fail:\n# fail to serialize: local variable used in function closure\nN = 3\n_shuffler = RuleDSL.@ref mr.shuffler(x -> Int(hash(first(x)) % N), Set(collect(0:N-1)))\nbut the second version of the shuffler will work fine:\n# closure moved inside the rule declaration\n_shuffler = RuleDSL.@ref mr.shuffle(first, N)\nA complex struct is more likely to have unstable hashes, you can either make it inherit from RuleDSL.ValueType thus using the more stable RuleDSL.hashparam, or you can provide your own stable hash function by overriding the RuleDSL.hashparam method for the type in question. To help detect the potential serialization and hash stability issues in rules, we provide a convenient macro RuleDSL.@isdistributable, which will flag any node in a graph that cannot be safely distributed.\nYou may be tempted to define a mapreduce rule that takes a mapper function and a reducer function, and create the RuleDSL.@ref mr.mapper(func) and RuleDSL.@ref mr.reducer(func) inside the mapreduce rule. As discussed before, this is less generic as the mapper and reducer rule shall not be restricted to simple wrappers like RuleDSL.@ref mr.mapper(func). Instead, any rule can be used as the mapper and reducer, for example it could  represent a complex graph with sophisticated logic. As a matter of fact, they could very well be high order rules themselves.","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"","category":"page"},{"location":"pages/t003_mapreduce.html#","page":"3 MapReduce","title":"3 MapReduce","text":"This page was generated using Literate.jl.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"EditURL = \"https://github.com/JuliusTechCo/Tutorials/blob/main/src/quickstart.jl\"","category":"page"},{"location":"pages/t001_quickstart.html#Tutorial-1:-Quick-Start-1","page":"1 Quick Start","title":"Tutorial 1: Quick Start","text":"","category":"section"},{"location":"pages/t001_quickstart.html#How-to-use-this-tutorial-1","page":"1 Quick Start","title":"How to use this tutorial","text":"","category":"section"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Select \"run all cells\" on this notebook from the Run menu in Jupyter notebook or Jupyter","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"lab. This step will produce intermediate data output and charts.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Some cells print out a url, which you can click on and bring up an interactive web UI to visualize the graph data.\nIn the unlikely event that the notebook becomes irresponsive, you can try \"Restart Kernel\" from the Kernel menu, then run individual cells one by one using Shift+Enter.\nSome tutorials use local clusters consisting of multiple processes to mimic the effects","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"of graph distribution over a remote clusters. By default, these local clusters   automatically stop after idling for 15min to conserve CPU and memory resources. You will   need to rerun the entire notebook if your local cluster stopped due to inactivity.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Additional resources (video demos & blogs) are available at http://juliustech.co\nTo report any issues, get help or request features, please raise an issue at:","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"https://github.com/JuliusTechCo/JuliusGraph/issues","category":"page"},{"location":"pages/t001_quickstart.html#.-Introduction-1","page":"1 Quick Start","title":"0. Introduction","text":"","category":"section"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Julius is an auto-scaling, low-code, and visual graph computing solution, that can build sophisticated data and analytical pipelines with very little code. This tutorial is a quick start guide on the basic concepts and programming API of Julius Graph Engine. You can find introductory videos and blogs on graph computing at http://juliustech.co if you are new to the subject.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Julius Graph Engine is implemented in Julia. Prior knowledge in Julia is not required to follow this tutorial, as developer mainly interact with Julius GraphEngine through a domain specific language (DSL): the Julius RulesDSL, which only uses a very limited set of Julia syntax.  If you have programming expperiences in Python or Matlab, you can follow this guide without much difficulties. We will highlight and explain some key Julia specific syntax in this tutorial for Python/Matlab developers.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"This tutorial is organized around three key concept in Julius Graph Engine: Atoms, Rules and Runtime.","category":"page"},{"location":"pages/t001_quickstart.html#.-Atoms-1","page":"1 Quick Start","title":"1. Atoms","text":"","category":"section"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Atom is an abstract Julia type, it is the most fundamental building block of Julius Graph Engine, it stands for atomic operations. The name Atom is chosen because they are the minimal unit of distribution and caching in Julius Graph Engine, atoms cannot be broken apart further for those purposes. Atom interface enables Julius Graph Engine to access functionalities implemented in existing software libraries. Atom can be implemented in all major programming languages, such as Python, C/C++, Java, .Net, R and Julia etc. Existing functions written in these languages can be easily wrapped up as an atom and be used in Julius Graph.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"There are several different sub types of Atoms for different use cases. We first introduce Datom, which is the most generic Atom type that encapsulates any numerical or data operation. The Datom interface only has a single method, the ... syntax in the function signature is a Julia specific syntax for catching varying number of arguments.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"fwddata!(self::Datom, xs...)","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"The fwddata! method can take any number of input data object in xs and must return a vector of output objects. The return type of vector is chosen to be explicit that the output could contain multiple objects.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"The follow code snippets creates a Datom that computes the weighted sum of an input vector of DataFrame objects. DataFrame is the popular choice for representing tabular data in data science applications. Julia's DataFrame provides similar functionalities as the Python's pandas Dataframe. A developer is free to choose other input/output types for writing their own Datoms, the xs in the fwddata! can be any data type.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"The following cells contain a complete implementation of the weighted sum Datom.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"using DataFrames, Base.CoreLogging\nusing GraphEngine: RuleDSL, GraphVM # RuleDSL package has all the APIs and type definitions of Julius Graph Engine\nusing GraphIO\n\n# turn off information logging output, only show errors and warning\ndisable_logging(CoreLogging.Info)\n\n# start a data server for the web UI\ngss = Dict{String,RuleDSL.AbstractGraphState}()\nport = GraphVM.drawdataport()\n@async GraphVM.startresponder(gss, port)","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Task (runnable) @0x00007f8e6293af50","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"# this method needs to be extended when declaring new datoms\nimport GraphEngine.RuleDSL: fwddata!\n\nstruct WSumDF <: RuleDSL.Datom\n    weights::Vector{Float64}\nend\n\nfunction fwddata!(self::WSumDF, dfs::DataFrame...)\n    @assert length(dfs) == length(self.weights) && length(dfs) > 0 \"invalid input size\"\n    sum = self.weights[1] .* dfs[1]\n\n    for i=2:length(self.weights)\n        sum .+= (self.weights[i] .* dfs[i])\n    end\n\n    return [sum] # must return a vector\nend","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"fwddata! (generic function with 24 methods)","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Next, we show how to use Datom to compute the weighted sum of DataFrames.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"using Random\n\nws = [1.0; 2.0; 3.0]\nxlen = 10\nxs = [rand(xlen), rand(xlen), rand(xlen)]\n\nwsumd = WSumDF(ws)\ndfs = [DataFrame(v=x) for x in xs] # create 3 data frames\nysd = RuleDSL.fwddata!(wsumd, dfs...)\nfirst(ysd)","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"<div class=\"data-frame\"><p>10 rows × 1 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>v</th></tr><tr><th></th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>4.54355</td></tr><tr><th>2</th><td>4.36386</td></tr><tr><th>3</th><td>2.10622</td></tr><tr><th>4</th><td>2.06082</td></tr><tr><th>5</th><td>1.49617</td></tr><tr><th>6</th><td>2.50937</td></tr><tr><th>7</th><td>3.5756</td></tr><tr><th>8</th><td>3.22149</td></tr><tr><th>9</th><td>5.01948</td></tr><tr><th>10</th><td>1.55937</td></tr></tbody></table></div>","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Julius Graph Engine offers a convenient macro RuleDSL.@datom for writing new datoms, the same weighed sum datom can be implemented more compactly as below. The RuleDSL.@datom macro translate the code below to a code block similar to the WSumDF implementation above. The two versions are equivalent to each other in functionality. Besides making the code more compact and easier to read and write, RuleDSL.@datom is also future proof, in that the macro would automatically generate conversion code in case of future Julius API changes. Therefore, it is strongly recommended to use the RuleDSL.@datom macro to declare new Datom types.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"# `WSumDF2` is the name of `Datom`'s type\nRuleDSL.@datom WSumDF2 begin\n    weights::Vector{Float64} # the member of WSumDF2\n\n    function fwddata!(dfs::DataFrame...) # self::WSumDF2 is automatically inserted as the first argument\n        sum = zeros(nrow(dfs[1]))\n        for (w, df) in zip(weights, dfs) # here weights is translated to self.weights, accessing the member\n            sum .+= w .* df[!, 1]\n        end\n        return [DataFrame(; wsum=sum)] # return a vector\n    end\nend\n\nwsumd2 = WSumDF2(ws)\nysd2 = RuleDSL.fwddata!(wsumd2, dfs...)\n\n# Horizontally concatenate data frames for comparison\nhcat(ysd..., ysd2...; makeunique=true)","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"<div class=\"data-frame\"><p>10 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>v</th><th>wsum</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>4.54355</td><td>4.54355</td></tr><tr><th>2</th><td>4.36386</td><td>4.36386</td></tr><tr><th>3</th><td>2.10622</td><td>2.10622</td></tr><tr><th>4</th><td>2.06082</td><td>2.06082</td></tr><tr><th>5</th><td>1.49617</td><td>1.49617</td></tr><tr><th>6</th><td>2.50937</td><td>2.50937</td></tr><tr><th>7</th><td>3.5756</td><td>3.5756</td></tr><tr><th>8</th><td>3.22149</td><td>3.22149</td></tr><tr><th>9</th><td>5.01948</td><td>5.01948</td></tr><tr><th>10</th><td>1.55937</td><td>1.55937</td></tr></tbody></table></div>","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"We also define another Datom type RandDF that returns uniform random numbers in a Dataframe, for later use. The meanv parameter specifies the mean of the uniform random numbers.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"RuleDSL.@datom RandDF begin\n    n::Int\n    meanv::Float64\n\n    function fwddata!()\n        return [DataFrame(v=(rand(n) .- .5 .+ meanv))] # create a random vector\n    end\nend","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"fwddata! (generic function with 26 methods)","category":"page"},{"location":"pages/t001_quickstart.html#.-Rules-1","page":"1 Quick Start","title":"2. Rules","text":"","category":"section"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"The Atom and its subtype Datom are generic abstractions for atomic numerical and data processing algorithms. However, just having atoms is not enough to build a working system or application, we still need to connect these atoms in a meaningful way to create a system or application. The RuleDSL is a high level domain specific language (DSL) exactly designed for that purpose. RuleDSL specifiies precisely how atoms should be connected to one another to form a computation DAG (directed acyclic graph) for the entire system or application.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"The RuleDSL is a graph programming language, it has a very limited syntax for creating DAGs. It doesn't support most constructs in a conventional programming languages, such as variables, functions, branches or inheritance. RuleDSL only contains discreate declaration of rules, therefore it is much easier to learn and use than the full-fledged programming language. The `Atom' is an interface to traditional programming languages and libraries. The combination of Rules and Atoms are extremely powerful and expressive, they offers the best features from the traditional and graph programming. Together they can create systems of any scale and complexity with a minimal amount of code.","category":"page"},{"location":"pages/t001_quickstart.html#.1-RuleDSL-Syntax-1","page":"1 Quick Start","title":"2.1 RuleDSL Syntax","text":"","category":"section"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"We use Fibonacci sequence as an example to describe the RulesDSL syntax. The following is a Fibonacci like sequence using the WSumDF datom we just defined. This example is different from the classic Fibonacci sequence in that its two initial terms are random vectors intead of scalar 0 and 1; thus the recursive summation is applied to vectors instead of scalars.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"RuleDSL.@addrules seq begin\n    fib(n::Int) = RuleDSL.Alias(fib(n, Val(n <= 1))) # binds the 2nd parameter for convenience, Alias is an atom that passes the outputs of other rules,\n    fib(f::Float64) = RuleDSL.Alias(fib(Int(floor(f)))) # adapting rule for a floating point parameter\n    fib(n::Int, isend::Val{false}) = begin # defines the recursion of Fibonacci sequence\n        WSumDF[[1.0, 1.0]](fib(n - 1, Val(n <= 2)), fib(n - 2, Val(n <= 3)))\n    end\n    fib(n::Int, isend::Val{true}) = RandDF[10, Float64(n)]() # using the RandDF atom defined earlier, random vector of length 10.\nend","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"The RuleDSL.@addrules is a macro provided by Julius Graph Engine for writing rules using the Rules DSL. The first argument seq is a user defined namespace to help organize related rules, followed by a list of discrete rules between the begin and end. There are four rules defined in the above declarations, the basic syntax of individual rules are:","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"rulename(arg1::Type1, arg2::Type2, ...) = AtomName[a1, a2, a3...](deprule1(args1...), deprule2(args2...), ...)","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"For example, in the rule:","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"fib(n::Int, isend::Val{false}) = WSumDF[[1.0, 1.0]](fib(n - 1, Val(n <= 2)), fib(n - 2, Val(n <= 3)))","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"fib is the rule name, the full name of a rule includes its namespace, in this","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"case it is seq.fib","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"n and isend are two parameters to this rule, with type Int, Val{false}, all rule parameter must have corresponding types in the rule declarations. The Val{false} is a Julia templatized type that enables value based pattern matching (matching the value false in this case).\nWSumDF is the atom name, which was defined earlier, the outer square bracket encloses the parameter to the atom's constructor\n[1.; 1.] in the square bracket is the parameter to the Datom WSumDF's constructor, i.e., it is the weights parameter. The WSumDF[[1.; 1.]] in the rule declaration is directly translated to a call ofWSumDF([1.; 1.]) to create the WSumDF object at run time.\nthe fib(n-1, Val(n<=2)), fib(n-2, Val(n<=3)) inside the parenthesis is a list of dependent rules, they must map to existing rules, so that the Graph Engine can recursively expand the rules at run time to create a complete computational graph. A rule can refer to other rules (including itself) as dependencies. In this case, it defines the recursive sum of Fibonacci sequence.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Besides the Datom WSumDF we just defined, these seq rules also uses the Atoms defined in the GraphEngine.RuleDSL package, such as RuleDSL.Alias. Julius Graph Engine comes with a rich set of pre-built Atoms that can be used by referring to their fully qualified Atom names. The atom RuleDSL.Alias is a special atom that simply pass the results of the dependent rules, it creates an additional name to improve readability. Alias atom is often used to bind certain rule parameters to concrete values, as shown in the first seq.fib rule above.","category":"page"},{"location":"pages/t001_quickstart.html#.2-Polymorphism-and-Rule-Matching-1","page":"1 Quick Start","title":"2.2 Polymorphism and Rule Matching","text":"","category":"section"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Rules DSL supports multiple dispatch with type and value based polymorphism, as a result it can capture complex data or analytical logic. Multiple rules can have the same rule name with different argument types, for example we have four rules of seq.fib with different parameters above. At run time, the rule with the most precise match by type are invoked, this process continues recursively through rule dependencies until all the dependent rules are resolved. The final result of this rule matching and expansion process is a fully constructed computation graph (a DAG), which is ready to be executed.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"The value based polymorphism is supported using Julia's templatized type, such as Val{true} or Val{false}. For example, in the first seq.fib rule above, if n <= 1, the isend parameter of the dependent rules become an instance of the type Val{true}, which would match to the last seq.fib rule governing the initial terms.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"To fully understand this process, let's go through the creation of computational graph for seq.fib(3.2) step by step.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"# override label display on the node to show additional rule parameters\nimport GraphEngine.RuleDSL: nodelabel\nfunction nodelabel(::AbstractGraphState, ref::NodeRef)\n    hdr = \"$(ref.ns).$(ref.name)\"\n    ps = join(simplerepr.(ref.params), \", \")\n\n    return \"$hdr($ps)\"\nend\n\n# create a concrete instance to a rule\nref = RuleDSL.@ref seq.fib(3.2)\n# configuration object to pass common parameters to run time\nconfig = RuleDSL.Config()\n\n# run the computation according to the defined rules to create output in the Set\ngs = GraphVM.createlocalgraph(config, RuleDSL.GenericData());\nGraphVM.calcfwd!(gs, Set([ref]));\n\nsvg = GraphIO.postlocalgraph(gss, gs, port);\nGraphIO.postsvg(svg, \"quickstart_1.svg\")","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7833_mr\n","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"<p align = \"center\">\n<img src=\"../assets/quickstart_1.svg\" alt=\"\" title=\"Fib\"/>\n</p>\n<p align = \"center\">\nFigure 1 - Fibonacci\n</p>","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"In the above example, the steps to create the entire computation DAG includes:","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"The best matching rule for seq.fib(3.2) is fib(f::Float64)=RuleDSL.Alias(fib(Int(floor(f)))), which is aliased to seq.fib(3) because the parameter Int(floor(f)) in the depedent rule evaluates to 3.\nThe best matching rule for seq.fib(3) is fib(n::Int)=RuleDSL.Alias(fib(n, Val{n<=1}())), whose dependent rule is seq.fib(3, Val{false}()) where Val(false) is an instance of templatized type Val{false}.\nThe best matching rule for seq.fib(3, Val(false)) is  fib(n::Int, isend::Val{false})=WSumDF[[1.; 1.]](fib(n-1, Val(n<=2)), fib(n-2, Val(n<=3))), with 2 dependent rules: seq.fib(2, Val(false)) and seq.fib(1, Val(true)) .\nThe best matching rule for seq.fib(2, Val(false)) is again  fib(n::Int, isend::Val{false})=WSumDF[[1.; 1.]](fib(n-1, Val(n<=2)), fib(n-2, Val(n<=3)), with two dependent rules seq.fib(1, Val(true))  and seq.fib(0, Val(true))\nThe best matching rule for seq.fib(1, Val(true)) and seq.fib(0, Val(true)) is fib(n::Int, isend::Val{true})=RandDF[10, Float64(n)](), which is the initial term of the Fibonacci sequence that does not have any further dependencies. Now the graph exapnsion/creation is complete.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"The above cell's output contains a url to a web UI, where a user can visualize the entire calculation with all the intemediate results.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"All the data are cached in the gs object, which is of type GraphVM.GraphState, which contains all the run time state of the DAG. Data can be retrieved using the getdata method, which takes the hash value of the RuleDSL.NodeRef object. The hash value of RuleDSL.NodeRef object is often used as a unique ID of the node. The relationship between rules, NodeRef, and unique id is the following:","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Rule declaration $ \\xrightarrow{\\text{bind rule parameters by RuleDSL.@ref}} $ RuleDSL.NodeRef $ \\xrightarrow{\\text{hash}} $ Unique Node ID","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"The RuleDSL.@ref is a convenient macro to create RuleDSL.NodeRef object, which represents fully parameterized rules. For example the following cells shows two RuleDSL.NodeRef objects can be created from the same rule but with different arguments thus they have different hash IDs. Both of their values can be retrieved by getdata.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"fib2 = RuleDSL.@ref seq.fib(2, Val{false}())\nfib3 = RuleDSL.@ref seq.fib(3, Val{false}())\n\nprintln(typeof(fib2) => hash(fib2))\nprintln(typeof(fib3) => hash(fib3))\n\nv2 = RuleDSL.getdata(gs, hash(fib2))\nv3 = RuleDSL.getdata(gs, hash(fib3))\n\nhcat(v2..., v3...; makeunique=true)","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"<div class=\"data-frame\"><p>10 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>v</th><th>v_1</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>1.03068</td><td>1.88932</td></tr><tr><th>2</th><td>1.12433</td><td>1.87409</td></tr><tr><th>3</th><td>1.26719</td><td>2.1536</td></tr><tr><th>4</th><td>1.57113</td><td>2.64871</td></tr><tr><th>5</th><td>1.41512</td><td>2.61644</td></tr><tr><th>6</th><td>1.02371</td><td>2.17421</td></tr><tr><th>7</th><td>0.704202</td><td>1.87735</td></tr><tr><th>8</th><td>0.913714</td><td>1.77374</td></tr><tr><th>9</th><td>0.306599</td><td>0.996796</td></tr><tr><th>10</th><td>0.490116</td><td>1.01059</td></tr></tbody></table></div>","category":"page"},{"location":"pages/t001_quickstart.html#.3-Dynamic-Dependency-1","page":"1 Quick Start","title":"2.3 Dynamic Dependency","text":"","category":"section"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"A rule's dependency can by dynamic, i.e., the number and type of depenedencies can be different according to the rule's parameters. For example the following cell defines a sum of all the even number of terms in the Fibonacci sequence:","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"RuleDSL.@addrules seq begin\n    sumeven(n::Int) = begin\n        WSumDF[fill(1.0, length(0:2:n))](RuleDSL.@ref(fib(i) for i in 0:2:n)...)\n    end\nend","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"As shown below, the RuleDSL.@ref(fib(i) for i in 0:2:n) create a vector of RuleDSL.NodeRef object from the list comprehension inside. The ... is a special syntax in rule dependency that signals dynamic rule dependencies, it can follow any valid Julia expression or functions that returns an instance or a vector of RuleDSL.NodeRef.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"RuleDSL.@ref seq.fib(5)","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"seq:fib/5","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"RuleDSL.@ref(seq.fib(i) for i in 0:2:5)","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"3-element Vector{GraphEngine.RuleDSL.NodeRef}:\n seq:fib/0\n seq:fib/2\n seq:fib/4","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"The results of the dynamic dependency is shown below.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"# create a concrete instance to a rule\nsumeven = RuleDSL.@ref seq.sumeven(5)\n\n# run the computation according to the defined rules to create the desired output\ngs = GraphVM.createlocalgraph(config, RuleDSL.GenericData());\nGraphVM.calcfwd!(gs, Set([sumeven])); # we want to compute sumeven\n\nsvg = GraphIO.postlocalgraph(gss, gs, port);\nGraphIO.postsvg(svg, \"quickstart_2.svg\")","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7833_mr\n","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"<p align = \"center\">\n<img src=\"../assets/quickstart_2.svg\" alt=\"\" title=\"Dynamic Dependency\"/>\n</p>\n<p align = \"center\">\nFigure 2 - Dynamic Dependency\n</p>","category":"page"},{"location":"pages/t001_quickstart.html#.4-Multi-line-Rule-1","page":"1 Quick Start","title":"2.4 Multi-line Rule","text":"","category":"section"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"So far, all rules we have shown are single line declarations. Sometime it is convenient to run some simple calculations when declaring the rule, we can wrap up the declarations within begin ... end to allow multi-line declarations, for example the following is an equivalent declaration of rule seq.sumeven(n::Int). By using the local variables dep, ws, the following multi-line declaration is easier to read.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"RuleDSL.@addrules seq begin\n    sumeven2(n::Int) = begin\n        deps = RuleDSL.@ref(fib(i) for i in 0:2:n)\n        ws = fill(1.0, length(deps))\n        WSumDF[ws](deps...)\n    end\nend","category":"page"},{"location":"pages/t001_quickstart.html#.-Runtime-and-GraphData-1","page":"1 Quick Start","title":"3. Runtime and GraphData","text":"","category":"section"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"The combination of Rules and Atoms are very powerful and expressive, they can build any data and analytical pipeline as a directed acyclic graph (DAG) regardless of its complexity, usually with very few lines of code in RuleDSL. However, a system needs additional run time configurations to function properly, even with all the business logic has been fully specified. Runtime configuration is an important aspect of a running system, which is the topic of this section.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Runtime configuration usually include the following attributes:","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Distribution: whether a system is running on a local computer or a distributed computing environment\nCaching: should the intermediate results being cached, and how/where it is cached\nAdjoint Algorithmic Differentiation (AAD): whether the system execution includes AAD\nBatch or Streaming: whether the system running once in a batch mode, or running in a live mode with endless streaming data","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"In a traditional development environment, separate and duplicated codebases are created in order to support different runtimes. For example, it is common in a bank to have separate and dedicated systems for each combination of (runtime, applications), such as end of day batch system for Macro trading, live intraday system for Equity e-trading, test/UAD environment for XVA etc. These specialized and dedicated systems do not share much common software, hardware or configuration. As a results, the number of these specialized system can quick multiple and drive up the overall complexity and support cost in a bank, and at the same time hurting its consistency and reliability.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Julis GraphEngine provides a number of common runtime configurations out of box. Different runtime environment can be created on-demand from a common set of Rules and Atoms defining the business logic. This removes the needs for duplicated implementation of runtime configurations for individual sytems, leading to significant reduction in support cost and system complexity.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Julius Runtime are implemented as different GraphData types. Each GraphData type implements a specific runtime configuration. In the previous sections, we already seen the GenericData in action, which is a derived type of GraphData. The following table shows some of the most common GraphData configurations in Julius:","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"GraphData Type Caching Batch/Stream support AAD supported Atom type\nRuleDSL.GenericData yes batch no any\nRuleDSL.NumericalData yes batch yes Quantom only\nRuleDSL.StreamData no stream no any","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Any GraphData can be used in either local or distributed mode, we only work with local runtime in this notebook, but subsequent tutorials will show the distributed setup. The NumericalData is a GraphData specialized for numerical computation with AAD, which we will cover in another tutorial.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Next, we will show how streaming use cases can be easily created using the StreamData.","category":"page"},{"location":"pages/t001_quickstart.html#.1-Streaming-1","page":"1 Quick Start","title":"3.1 Streaming","text":"","category":"section"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Streaming is a common runtime use case, e.g., for live intraday pricing and risk during market open. With the RuleDSL.StreamData runtime, Julius can turn any batch system to a streaming system with few lines of code change.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"In the following few cells, we take the Fibnacci sequence as defined above, which operates in the batch mode, and turn it into a streaming processing. Its initial inputs, the fib(0)  and fib(1) terms becomes the streaming input of random vectors.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"To show the effects of streaming, we creates a new Datom that averages all the streamed input values.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"computes the running average of all the value being streamed","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"RuleDSL.@datom StreamAverage begin\n    sum::DataFrame = DataFrame()\n    cnt::Vector = [0]\n\n    function fwddata!(x::DataFrame)\n        if cnt[1] == 0\n            append!(sum, x)\n        else\n            sum .+= x\n        end\n\n        cnt[1] += 1\n        [ sum ./ cnt[1] ]\n    end\nend","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"fwddata! (generic function with 27 methods)","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Then we define a generic rule for computing stream average from any node. One of the most powerful feature of Julius Rules DSL, is the high order rule, which is a rule declaration that takes a RuleDSL.NodeRef object as parameter.  A high order rule can declare a generic pattern that is applicable to any other rules, for example map/reduce or Monte carlo simulation can be expressed as generic high order rules. We will cover high order rules in more detail in a following map/reduce tutorial.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"In the following high order rule for stream average, the ... operator in the dependency indicates dynamic dependency, which is just the input rule as defined by the NodeRef parameter. The seq.streamaverage is therefore a generic operation that can be applied to any other rule as representd in its argument ref, it has a single dependency to the node specified by the ref.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"RuleDSL.@addrules seq begin\n    streamaverage(ref::RuleDSL.NodeRef) = StreamAverage(ref...)\nend\n\n# sources of streaming inputs\nsrcs = [\n    RuleDSL.@ref(seq.fib(0, Val{true}())), RuleDSL.@ref(seq.fib(1, Val{true}()))\n]\nsd = RuleDSL.StreamData(Set(hash.(srcs)), 1) # create StreamData with que buffer length of 1\n\nref = RuleDSL.@ref seq.fib(5)\nsavg = RuleDSL.@ref seq.streamaverage(ref)\n\ngs2 = GraphVM.createlocalgraph(config, sd) # create a graph using StreamData\nGraphVM.calcfwd!(gs2, Set{NodeRef}(savg)); # set up the pipeline of streaming","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"The calcfwd! call above builts the pipeline between nodes for streaming, the connection between nodes in StreamData are message queues, and each nodes runs asynchronously to process the message from input the queue then put the results into the output que. The following cell streams 20,000 different initial inputs, which are randomly drawn by the datom RandDF. Since the final output's atom is StreamAverage, which computes the running average of all the streamed data, the net result is essentially to compute the Fibonnaci sequence using a Monte Carlo simulation of 20,000 paths, and the results are all close to 5, which is the correct value of the 5th term of the classic fibnacci sequence.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Unlike the mini-batch streaming processing in Spark, the streaming implementation in Julius is fully pipelined where different nodes are processing different streaming inputs concurrently at any given time. As a result, Julius streaming is extremely fast, it achieved more than 10,000 messages per seconds.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"@time RuleDSL.pushpullcalc!(gs2, 10000) # stream 10,000 messages, this call can be made multiple times to stream more data\n@time RuleDSL.pushpullcalc!(gs2, 10000)\navg = RuleDSL.getdata(gs2, hash(savg))[1] # [1] is because the output is a vector of 1","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"<div class=\"data-frame\"><p>10 rows × 1 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>v</th></tr><tr><th></th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>5.0059</td></tr><tr><th>2</th><td>5.01547</td></tr><tr><th>3</th><td>5.01736</td></tr><tr><th>4</th><td>4.96472</td></tr><tr><th>5</th><td>5.0114</td></tr><tr><th>6</th><td>5.0054</td></tr><tr><th>7</th><td>5.01049</td></tr><tr><th>8</th><td>4.98826</td></tr><tr><th>9</th><td>5.0112</td></tr><tr><th>10</th><td>5.00038</td></tr></tbody></table></div>","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Once we are done with streaming, we can tear down the streaming pipeline by calling stopstream! on StreamData to reclaim the resources. Once stopstream! is called, we can no longer call the pushpullcalc!.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"RuleDSL.stopstream!(sd);","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"GraphVM.servedata(gss, gs2, port; key=\"stream\");","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7833_stream\n","category":"page"},{"location":"pages/t001_quickstart.html#.-Exercise-1","page":"1 Quick Start","title":"4. Exercise","text":"","category":"section"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"Thanks for your attention and now you have learnt the basics of Julius Graph Engine, it is time to get your hands dirty and write your own rules and atoms! Here is an suggested exercise: modify the streaming use case above, to also report the calculation of Monte Carlo error, which is the standard deviation of the samples divided by the square root of the number of samples. You can take advantage of the following relationship sigma^2(x)=Ex^2 - E^2x by tracking the average of squares. Then the MC error is fracsigma(x)sqrtn where n is the number of samples streamed.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"There can be different ways of doing this:","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"create a new Datom and corresponding rule, similar to StreamAverage and datafib.streamaverage, that computes the running mean and MC error, and return them as two DataFrames in the output vector, or two columns in the same DataFrrame.\ncreate new Datoms for arithmetic operations like Square, Subtraction and Sqrt on type DataFrame, then compute the MC error by writing new rules that connects these new datoms","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"The first approach is quick and fast, while the second approach is more generic and reusable, with additional benefits of being able to see the intermediate results.","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"","category":"page"},{"location":"pages/t001_quickstart.html#","page":"1 Quick Start","title":"1 Quick Start","text":"This page was generated using Literate.jl.","category":"page"},{"location":"index.html#Introduction-1","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"Welcome to the tutorial pages for the Julius Technologies' packages.","category":"page"},{"location":"index.html#Contents-1","page":"Introduction","title":"Contents","text":"","category":"section"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"Depth = 1","category":"page"},{"location":"index.html#How-to-start-1","page":"Introduction","title":"How to start","text":"","category":"section"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"There are different ways to use the tutorials:","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"Reading the html version of the tutorials. This is the recommended way if you want rapid access to the material with no setup steps. Simply click in one of the links in the Contents section.\nRunning the Jupyter notebooks locally. A working installation of Julia in the system is required. See instructions in the How to run the notebooks locally section. This is the recommended way to follow the tutorials if you want to run the code and inspect the generated results.","category":"page"},{"location":"index.html#How-to-run-the-notebooks-locally-1","page":"Introduction","title":"How to run the notebooks locally","text":"","category":"section"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"Clone the repository","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"$ git clone git@github.com:JuliusTechCo/Tutorials.git","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"Move into the folder and open a Julius REPL setting the current folder as the project environment.","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"$ cd Tutorials\n$ julius --project=.\n               _\n   _       _ _(_)_     |  Documentation: https://docs.julialang.org\n  (_)     | (_) (_)    |\n   _ _   _| |_  __ _   |  Type \"?\" for help, \"]?\" for Pkg help.\n  | | | | | | |/ _` |  |\n  | | |_| | | | (_| |  |  Version 1.6.3 (2021-09-23)\n _/ |\\__'_|_|_|\\__'_|  |  Official https://julialang.org/ release\n|__/                   |\n\njulia>","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"Instantiate the environment. This will automatically download all required packages.","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"# Type ] to enter in pkg mode\n(Tutorials) pkg> instantiate","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"Build the notebooks by either doing","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"(Tutorials) pkg> build","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"or","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"# Type Ctrl+C to get back to command mode\njulia> include(\"deps/build.jl\")","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"Open the notebooks","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"julia> using IJulia\njulia> notebook(dir=pwd())","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"This will open a browser window. Navigate to the notebooks folder and open the tutorial you want. Enjoy!","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"EditURL = \"https://github.com/JuliusTechCo/Tutorials/blob/main/src/advanced.jl\"","category":"page"},{"location":"pages/t006_advanced.html#Tutorial-6:-Advanced-Features-1","page":"6 Advanced Features","title":"Tutorial 6: Advanced Features","text":"","category":"section"},{"location":"pages/t006_advanced.html#How-to-use-this-tutorial-1","page":"6 Advanced Features","title":"How to use this tutorial","text":"","category":"section"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"Select \"run all cells\" on this notebook from the Run menu in Jupyter notebook or Jupyter","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"lab. This step will produce intermediate data output and charts.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"Some cells print out a url, which you can click on and bring up an interactive web UI to visualize the graph data.\nIn the unlikely event that the notebook becomes irresponsive, you can try \"Restart Kernel\" from the Kernel menu, then run individual cells one by one using Shift+Enter.\nSome tutorials use local clusters consisting of multiple processes to mimic the effects","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"of graph distribution over a remote clusters. By default, these local clusters   automatically stop after idling for 15min to conserve CPU and memory resources. You will   need to rerun the entire notebook if your local cluster stopped due to inactivity.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"Additional resources (video demos & blogs) are available at http://juliustech.co\nTo report any issues, get help or request features, please raise an issue at:","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"https://github.com/JuliusTechCo/JuliusGraph/issues","category":"page"},{"location":"pages/t006_advanced.html#Introduction-1","page":"6 Advanced Features","title":"Introduction","text":"","category":"section"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"This tutorial covers some advanced features in Julius Graph Engine:","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"Caching\nCloning of namespace and Change management\nPackage rules into an atom.\nError Handling","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"We use the same Fibonacci sequence example as in the AAD tutorial to illustrate these advanced topics.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"# disable the display of information logging\nusing Base.CoreLogging\ndisable_logging(CoreLogging.Info)\n\nusing GraphEngine: RuleDSL, GraphVM\nusing GraphEngine.RuleDSL\nusing GraphIO\n\n# start data server for web UI\ngss = Dict{String,RuleDSL.AbstractGraphState}()\nport = GraphVM.drawdataport()\n@async GraphVM.startresponder(gss, port)","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"Task (runnable) @0x00007f8e0ddb4160","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"The following few rules defines the Fibonacci sequence using the rule syntax.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"@addrules series begin\n    fib(x::Float64) = Alias(fib(Int(floor(x))))\n    fib(n::Int) = RuleDSL.Alias(fib(n, Val(n <= 1)))\n    fib(n::Int, isend::Val{false}) = begin\n        RuleDSL.WeightedSum[[1.0; 1.0]](\n            fib(n - 1, Val(n <= 2)), fib(n - 2, Val(n <= 3))\n        )\n    end\n    fib(n::Int, isend::Val{true}) = RuleDSL.Constant[[fill(Float64(n), 1)]]()\nend\n\nconfig = RuleDSL.Config();","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"The following two functions override the nodelabel function for the customized display of graph nodes. Users can freely override them to customize the text label display of the computation graph.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"import GraphEngine.RuleDSL: nodelabel\n\n# override displays\nfunction nodelabel(::RuleDSL.AbstractGraphState, r::RuleDSL.RuleNode)\n    hdr = \"$(r.ns).$(r.op[1])\"\n    typestr(x) = x.args[2]\n    typ = join(typestr.(r.op[2]), \", \")\n\n    return hdr * \"($typ)\"\nend\n\nfunction nodelabel(::RuleDSL.AbstractGraphState, ref::RuleDSL.NodeRef)\n    hdr = \"$(ref.ns).$(ref.name)\"\n    ps = join(simplerepr.(ref.params), \", \")\n\n    return \"$hdr($ps)\"\nend","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"nodelabel (generic function with 4 methods)","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"We first compute the primal and AAD of a Fibonacci sequence.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"fib5 = @ref series.fib(5.2)\nfib0 = @ref series.fib(0, Val(true))\nfib1 = @ref series.fib(1, Val(true))\n\ncs = RuleDSL.NumericalData(config, Set([fib0, fib1]));\ngs = RuleDSL.createlocalgraph(config, cs);\nRuleDSL.calcfwd!(gs, Set([fib5]));\nRuleDSL.calcback!(gs, Set([hash(fib5)]));","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"We can retrieve the results of vec y and the 1st order derivatives from AAD.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"y = RuleDSL.getys(gs, hash(fib5))\ndydx0 = RuleDSL.getyds(gs, hash(fib0), hash(fib5))\ndydx1 = RuleDSL.getyds(gs, hash(fib1), hash(fib5))\n\nprintln(\"fib5 =\", y[1])\nprintln(\"dfib5_dfib0 =\", dydx0[1])\nprintln(\"dfib5_dfib1 =\", dydx1[1])","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"fib5 =[5.0]\ndfib5_dfib0 =[3.0]\ndfib5_dfib1 =[5.0]\n","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"The corresponding computation graph is shown below, and you can click the link below to see it in an interactive web UI.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"svg = GraphIO.postlocalgraph(gss, deepcopy(gs), port; key=\"fib5\");\nGraphIO.postsvg(svg, \"adv_1.svg\")","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7140_fib5\n","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"<p align = \"center\">\n<img src=\"../assets/adv_1.svg\" alt=\"\" title=\"Fib 5\"/>\n</p>\n<p align = \"center\">\nFigure 1 - Fibonacci with AAD\n</p>","category":"page"},{"location":"pages/t006_advanced.html#Caching-1","page":"6 Advanced Features","title":"Caching","text":"","category":"section"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"Julius automatic caching of all intermediate computation results in the graph, any incremental computation will re-use existing values in the cache, instead of being recomputing them from scatch. The following cells shows that when computing fib(10) all the nodes up to fib(5) from previous step is re-used.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"fib10 = @ref series.fib(10)\nGraphVM.calcfwd!(gs, Set([fib10]));\nRuleDSL.calcback!(gs, Set([hash(fib10)]));\n\ny = RuleDSL.getys(gs, hash(fib10))\ndf10df0 = RuleDSL.getyds(gs, hash(fib0), hash(fib10))\ndf10df1 = RuleDSL.getyds(gs, hash(fib1), hash(fib10))\n\nprintln(\"fib10 =\", y[1])\nprintln(\"dfib10_dfib0 =\", df10df0[1])\nprintln(\"dfib10_dfib1 =\", df10df1[1])","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"fib10 =[55.0]\ndfib10_dfib0 =[34.0]\ndfib10_dfib1 =[55.0]\n","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"The corresponding computation graph is shown below:","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"svg = GraphIO.postlocalgraph(gss, deepcopy(gs), port; key=\"fib10\");\nGraphIO.postsvg(svg, \"adv_2.svg\")","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7140_fib10\n","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"<p align = \"center\">\n<img src=\"../assets/adv_2.svg\" alt=\"\" title=\"Fib 10\"/>\n</p>\n<p align = \"center\">\nFigure 2 - Caching\n</p>","category":"page"},{"location":"pages/t006_advanced.html#Namespace-Clone-and-Override-1","page":"6 Advanced Features","title":"Namespace Clone and Override","text":"","category":"section"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"Rules are organized within individual namespaces in Julius RuleDSL, for example the series is a namespace in the rules declaration above. One important feature of Julius is that the rules can be cloned to different namespace and overridden. This facilitates comparisons between the old and new versions of rules, making change management and impact analysis much easier.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"For example, if we update the above Fibonacci sequence definition to take random vectors as fib(0) and fib(1) instead of 0 and 1, we can create a clone of the namespace \"series\" and override the corresponding rules.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"@clone series => vecs\n\n@addrules vecs begin\n    fib(n::Int, isend::Val{true}) = RuleDSL.Constant[[randn(10)]]()\nend","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"vfib10 = @ref vecs.fib(10)\n@time GraphVM.calcfwd!(gs, Set([vfib10]));\n\ny = RuleDSL.getys(gs, hash(vfib10))\nprintln(\"vfib10 =\", y[1])","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"  0.242253 seconds (358.83 k allocations: 20.063 MiB, 99.55% compilation time)\nvfib10 =[-23.5333538482251, -35.68427776083766, 21.327869626043793, -13.343090066590456, 111.6789251387013, -26.99264317807458, 4.0212659339827646, -89.26373180954528, -75.59608006280155, 36.333000604914446]\n","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"We can show a side by side comparison of the two versions of the calculation, before and after changing the initial values to random vectors. You can compare the before and afer values of individual node in the interactive web UI, by clicking the URL below.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"svg = GraphIO.postlocalgraph(gss, deepcopy(gs), port; key=\"vecs\");\nGraphIO.postsvg(svg, \"adv_3.svg\")","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7140_vecs\n","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"<p align = \"center\">\n<img src=\"../assets/adv_3.svg\" alt=\"\" title=\"Comparisons\"/>\n</p>\n<p align = \"center\">\nFigure 3 - Override & Compare\n</p>","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"Julius AAD implementation supoorts multiple sensitivity views from the same primal calculation. A sensitivity view is a Jacobian matrix fracpartial vec ypartial vec x where vec y and vec x can be any dependent node in the graph. For the same primal calculation, different sensitivity views can be computed without repeating the primal calculations.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"The following few cells shows the results of different sensitivity views. Please note that the AAD output of the vectorized version of Fibonacci sequence is a full Jacobian matrix.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"v10 = @ref vecs.fib(10)\nv0 = @ref vecs.fib(0, Val(true))\nv1 = @ref vecs.fib(1, Val(true))\n\nRuleDSL.calcback!(gs, Set(hash.([v10])), Set([v0; v1]));\n\ndv10_dv0 = RuleDSL.getyds(gs, hash(v0), hash(v10))\ndv10_dv1 = RuleDSL.getyds(gs, hash(v1), hash(v10))\n\nprintln(\"fib_v10 = \", RuleDSL.getys(gs, hash(v10))[1])\nprintln(\"dv10_dv0 = \", dv10_dv0[1])\nprintln(\"dv10_dv1 = \", dv10_dv1[1])","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"fib_v10 = [-23.5333538482251, -35.68427776083766, 21.327869626043793, -13.343090066590456, 111.6789251387013, -26.99264317807458, 4.0212659339827646, -89.26373180954528, -75.59608006280155, 36.333000604914446]\ndv10_dv0 = [34.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 34.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 34.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 34.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 34.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 34.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 34.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 34.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 34.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 34.0]\ndv10_dv1 = [55.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 55.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 55.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 55.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 55.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 55.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 55.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 55.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 55.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 55.0]\n","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"v8 = @ref vecs.fib(8, Val(false))\nv2 = @ref vecs.fib(2, Val(false))\nv3 = @ref vecs.fib(3, Val(false))\n\nRuleDSL.calcback!(gs, Set(hash.([v8])), Set([v2; v3]));\n\ndv8_dv2 = RuleDSL.getyds(gs, hash(v2), hash(v8))\ndv8_dv3 = RuleDSL.getyds(gs, hash(v3), hash(v8))\n\nprintln(\"fib_v8 =\", RuleDSL.getys(gs, hash(v8))[1])\nprintln(\"dv8_dv0 =\", dv8_dv2[1])\nprintln(\"dv8_dv1 =\", dv8_dv3[1])","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"fib_v8 =[-8.984432306499603, -13.630047254197503, 8.154917445790005, -5.102373110511255, 42.67368954607872, -10.304216997598362, 1.517052663070242, -34.12285397891905, -28.858803740288707, 13.852178285800594]\ndv8_dv0 =[5.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 5.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 5.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 5.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 5.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 5.0]\ndv8_dv1 =[8.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 8.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 8.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 8.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 8.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 8.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 8.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 8.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 8.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 8.0]\n","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"A warning is generated if the vec x specification does not capture the sensitivities to all the factors that affects vec y. In the following example, knowing term fib(2) is not adequate to uniquely determine fib(8), therefore a warning is produced.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"RuleDSL.calcback!(gs, Set(hash.([v8])), Set([v2]))","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"0","category":"page"},{"location":"pages/t006_advanced.html#Packaging-1","page":"6 Advanced Features","title":"Packaging","text":"","category":"section"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"When the computation graph becomes large, it can be difficult for a user to navigate and visualize. Julius supports packaged atoms, which is to use a set of Rules to define an atom with its internal computational graph. The packaged atom can then be subsequently referred to by other rules. The iterative layering of rules and packaged atoms allows easy composition of complicated logic and analytics.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"The following code cell shows how to create and use a pacakged atom, using the macro RuleDSL.@combonquantom. A similar RuleDSL.@combodatom is also provided to create packaged Dataom object.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"using GraphEngine.RuleDSL: Source\n\n# the first argument must be the config\n@comboquantom function Fib[config::RuleDSL.Config, m::Int](fac.xarg(0), fac.xarg(1))\n    fib(n::Int) = Alias(fib(n, Val(n <= 1)))\n    fib(n::Int, isend::Val{false}) = begin\n        RuleDSL.WeightedSum[[1.0; 1.0]](fib(n - 1, Val(n <= 2)), fib(n - 2, Val(n <= 3)))\n    end\n    fib(n::Int, isend::Val{true}) = Alias(fac.xarg(n))\n\n    return fib(m)\nend\n\n@addrules pack begin\n    randv(id::Int, d::Int) = RuleDSL.Constant[[randn(d)]]()\n    fib(n::Int, d::Int) = Fib[@config, n](randv(0, d), randv(1, d))\nend","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"d = 10\np20 = @ref pack.fib(20, d)\np0 = @ref pack.randv(0, d)\np1 = @ref pack.randv(1, d)\n\ngs = RuleDSL.createlocalgraph(config, RuleDSL.NumericalData())\nRuleDSL.calcfwd!(gs, Set([p20]));\nRuleDSL.calcback!(gs, Set(hash.(p20)), Set([p0; p1]));\n\ndp20dp0 = RuleDSL.getyds(gs, hash(p0), hash(p20))\ndp10dp1 = RuleDSL.getyds(gs, hash(p1), hash(p20))\n\nprintln(\"fib20 =\", RuleDSL.getys(gs, hash(p20)))\nprintln(\"dfib20_dfib0 =\", dp20dp0[1])\nprintln(\"dfib20_dfib1 =\", dp20dp0[1])","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"fib20 =[[14039.566061206682, 3208.2857420610962, -2240.126250064062, 12947.89354436156, 9544.061705246699, -11479.558870546469, -10919.072596558774, 729.7092202176311, 9938.660349329983, -3867.5128536919697]]\ndfib20_dfib0 =[4181.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 4181.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 4181.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 4181.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 4181.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 4181.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 4181.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 4181.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 4181.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 4181.0]\ndfib20_dfib1 =[4181.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 4181.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 4181.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 4181.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 4181.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 4181.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 4181.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 4181.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 4181.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 4181.0]\n","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"The AAD works automatically across the packaged atoms, as shown in the cell above. The follow cell shows that the top level graph is much simpler using the packaged atom. A user can drill down to the full detail of the inner graph of packaged atom from the interactive web UI by clicking on the URL below.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"svg = GraphIO.postlocalgraph(gss, deepcopy(gs), port; key=\"pack\");\nGraphIO.postsvg(svg, \"adv_4.svg\")","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7140_pack\n","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"<p align = \"center\">\n<img src=\"../assets/adv_4.svg\" alt=\"\" title=\"Packaged Atom\"/>\n</p>\n<p align = \"center\">\nFigure 4 - Packaged Atom\n</p>","category":"page"},{"location":"pages/t006_advanced.html#Error-Handling-1","page":"6 Advanced Features","title":"Error Handling","text":"","category":"section"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"The Julius Graph Engine handles errors graciously and gives users clear indications on where the errors arise. The follow code create an exception using the Error Quantom at the back AD stage.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"using Test\n\n@clone series => err\n\n@addrules err begin\n    # parameter 2 in Error create error at ad stage\n    fib(n::Int, isend::Val{false}) = RuleDSL.Error[2](series.fib(n, isend))\nend\n\nefibn = @ref err.fib(10)\nxs = Set([@ref series.fib(0); @ref series.fib(1)])\n\ngs = RuleDSL.createlocalgraph(config, RuleDSL.NumericalData())\ntry\n    RuleDSL.calcfwd!(gs, Set([efibn]))\n    RuleDSL.calcback!(gs, Set(hash(efibn)), xs)\ncatch e\n    println(\"error caught: $e\")\nend","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"0","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"The node with error are highlighed automatically in the interactive web UI under the section \"errors in graph\".","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"svg = GraphIO.postlocalgraph(gss, deepcopy(gs), port; key=\"err\");\nGraphIO.postsvg(svg, \"adv_5.svg\")","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"view graph data at http://127.0.0.1:8080/depgraph.html?dataurl=127.0.0.1:7140_err\n","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"<p align = \"center\">\n<img src=\"../assets/adv_5.svg\" alt=\"\" title=\"Error Handling\"/>\n</p>\n<p align = \"center\">\nFigure 5 - Error Handling\n</p>","category":"page"},{"location":"pages/t006_advanced.html#Manage-Rules-Upgrades-1","page":"6 Advanced Features","title":"Manage Rules Upgrades","text":"","category":"section"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"During the development process, we may need to upgrade certain rules to a newer versions, while encouraging existing users to migrate. This can be achieved through the use of warning messages. For example, if we want to retire the series.fib and migrate users to the new version of vecs.fib, a warning message can be generated for existing users on the old rules:","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"@addrules series begin\n    fib(n::Int, isend::Val{true}; warn=\"deprecated, please use vecs.fib instead\") = begin\n        RuleDSL.Constant[[fill(Float64(n), 1)]]()\n    end\nend\n\nefibn = @ref series.fib(10)\ngs = RuleDSL.createlocalgraph(config, RuleDSL.NumericalData(Set{UInt}()))\n@time RuleDSL.calcfwd!(gs, Set([efibn]));","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"┌ Warning: rule series.fib warning: deprecated, please use vecs.fib instead\n└ @ Main.##262 /home/julius/dev/Julius/GraphEngine/src/RuleDSL/rulepiler.jl:186\n┌ Warning: rule series.fib warning: deprecated, please use vecs.fib instead\n└ @ Main.##262 /home/julius/dev/Julius/GraphEngine/src/RuleDSL/rulepiler.jl:186\n  0.100709 seconds (292.76 k allocations: 16.505 MiB, 98.83% compilation time)\n","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"After the migration period has ended, we can change the old rules to throw an error and force users to upgrade.","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"@addrules series begin\n    fib(n::Int, isend::Val{true}; error=\"deprecated, please use vecs.fib instead\") = begin\n        RuleDSL.Constant[[fill(Float64(n), 1)]]()\n    end\nend\n\ngs = RuleDSL.createlocalgraph(config, RuleDSL.NumericalData())\ntry\n    RuleDSL.calcfwd!(gs, Set([efibn]))\ncatch e\n    println(\"error caught $e\")\nend","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"error caught rule series.fib: deprecated, please use vecs.fib instead\n","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"","category":"page"},{"location":"pages/t006_advanced.html#","page":"6 Advanced Features","title":"6 Advanced Features","text":"This page was generated using Literate.jl.","category":"page"}]
}
